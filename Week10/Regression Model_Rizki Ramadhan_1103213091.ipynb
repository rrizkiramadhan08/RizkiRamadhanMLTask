{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0            7.0              0.27         0.36            20.7      0.045   \n",
      "1            6.3              0.30         0.34             1.6      0.049   \n",
      "2            8.1              0.28         0.40             6.9      0.050   \n",
      "3            7.2              0.23         0.32             8.5      0.058   \n",
      "4            7.2              0.23         0.32             8.5      0.058   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
      "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
      "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
      "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
      "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
      "\n",
      "   alcohol  quality  \n",
      "0      8.8        6  \n",
      "1      9.5        6  \n",
      "2     10.1        6  \n",
      "3      9.9        6  \n",
      "4      9.9        6  \n"
     ]
    }
   ],
   "source": [
    "# Membaca dataset dengan delimiter yang benar (;)\n",
    "data = pd.read_csv('winequality-white.csv', delimiter=';')\n",
    "\n",
    "# Menampilkan beberapa baris pertama untuk memastikan data terbaca dengan benar\n",
    "print(data.head())\n",
    "\n",
    "# Menampilkan beberapa baris pertama untuk melihat data secara umum\n",
    "data.head()\n",
    "\n",
    "X = data.iloc[:, :-1].values  # Fitur (semua kolom kecuali 'quality')\n",
    "y = data.iloc[:, -1].values  # Target (kolom 'quality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize features and target\n",
    "X = (X - X.mean(axis=0)) / X.std(axis=0)  # Normalisasi fitur (mean=0, std=1)\n",
    "y = (y - y.mean()) / y.std()  # Normalisasi target untuk regresi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch Dataset class untuk menangani data\n",
    "class WineDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)  # Konversi fitur ke tensor PyTorch\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)  # Konversi target ke tensor PyTorch\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)  # Mengembalikan jumlah data\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]  # Mengembalikan pasangan fitur dan target\n",
    "    \n",
    "    \n",
    "    \n",
    "# Buat dataset PyTorch\n",
    "dataset = WineDataset(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset menjadi 80% training dan 20% testing\n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definisi model MLP (Multilayer Perceptron)\n",
    "class MLPRegressor(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layers, activation_fn):\n",
    "        super(MLPRegressor, self).__init__()\n",
    "        layers = []\n",
    "        in_features = input_size  # Input size (jumlah fitur)\n",
    "        for neurons in hidden_layers:\n",
    "            layers.append(nn.Linear(in_features, neurons))  # Tambahkan layer linear\n",
    "            layers.append(activation_fn)  # Tambahkan fungsi aktivasi\n",
    "            in_features = neurons  # Update jumlah neuron untuk layer berikutnya\n",
    "        layers.append(nn.Linear(in_features, 1))  # Output layer (satu neuron untuk regresi)\n",
    "        self.model = nn.Sequential(*layers)  # Gabungkan semua layer menjadi satu model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)  # Forward pass (prediksi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter eksperimen yang akan diuji\n",
    "hidden_layer_configs = [[4], [8], [16], [4, 8], [8, 16], [16, 32], [4, 8, 16]]  # Kombinasi jumlah neuron\n",
    "activation_functions = {'linear': nn.Identity(), 'sigmoid': nn.Sigmoid(), 'relu': nn.ReLU(), 'softmax': nn.Softmax(dim=-1), 'tanh': nn.Tanh()}  # Fungsi aktivasi\n",
    "epochs_list = [ 10, 25, 50]  # Jumlah epoch\n",
    "learning_rates = [ 0.01, 0.001, 0.0001]  # Learning rate\n",
    "batch_sizes = [16, 32, 64 ]  # Ukuran batch\n",
    "# Untuk menyimpan hasil\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gunakan GPU jika tersedia, jika tidak gunakan CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layers: [4], Activation: linear, Epochs: 10, LR: 0.01, Batch Size: 16, Test Loss: 0.7032\n",
      "Hidden Layers: [4], Activation: linear, Epochs: 10, LR: 0.01, Batch Size: 32, Test Loss: 0.6969\n",
      "Hidden Layers: [4], Activation: linear, Epochs: 10, LR: 0.01, Batch Size: 64, Test Loss: 0.7094\n",
      "Hidden Layers: [4], Activation: linear, Epochs: 10, LR: 0.001, Batch Size: 16, Test Loss: 0.6926\n",
      "Hidden Layers: [4], Activation: linear, Epochs: 10, LR: 0.001, Batch Size: 32, Test Loss: 0.6918\n",
      "Hidden Layers: [4], Activation: linear, Epochs: 10, LR: 0.001, Batch Size: 64, Test Loss: 0.7037\n",
      "Hidden Layers: [4], Activation: linear, Epochs: 10, LR: 0.0001, Batch Size: 16, Test Loss: 0.7238\n",
      "Hidden Layers: [4], Activation: linear, Epochs: 10, LR: 0.0001, Batch Size: 32, Test Loss: 0.8075\n",
      "Hidden Layers: [4], Activation: linear, Epochs: 10, LR: 0.0001, Batch Size: 64, Test Loss: 0.8777\n",
      "Hidden Layers: [4], Activation: linear, Epochs: 25, LR: 0.01, Batch Size: 16, Test Loss: 0.6969\n",
      "Hidden Layers: [4], Activation: linear, Epochs: 25, LR: 0.01, Batch Size: 32, Test Loss: 0.6928\n",
      "Hidden Layers: [4], Activation: linear, Epochs: 25, LR: 0.01, Batch Size: 64, Test Loss: 0.7064\n",
      "Hidden Layers: [4], Activation: linear, Epochs: 25, LR: 0.001, Batch Size: 16, Test Loss: 0.6907\n",
      "Hidden Layers: [4], Activation: linear, Epochs: 25, LR: 0.001, Batch Size: 32, Test Loss: 0.6970\n",
      "Hidden Layers: [4], Activation: linear, Epochs: 25, LR: 0.001, Batch Size: 64, Test Loss: 0.6973\n",
      "Hidden Layers: [4], Activation: linear, Epochs: 25, LR: 0.0001, Batch Size: 16, Test Loss: 0.6993\n",
      "Hidden Layers: [4], Activation: linear, Epochs: 25, LR: 0.0001, Batch Size: 32, Test Loss: 0.7284\n",
      "Hidden Layers: [4], Activation: linear, Epochs: 25, LR: 0.0001, Batch Size: 64, Test Loss: 0.8148\n",
      "Hidden Layers: [4], Activation: linear, Epochs: 50, LR: 0.01, Batch Size: 16, Test Loss: 0.7170\n",
      "Hidden Layers: [4], Activation: linear, Epochs: 50, LR: 0.01, Batch Size: 32, Test Loss: 0.7035\n",
      "Hidden Layers: [4], Activation: linear, Epochs: 50, LR: 0.01, Batch Size: 64, Test Loss: 0.7145\n",
      "Hidden Layers: [4], Activation: linear, Epochs: 50, LR: 0.001, Batch Size: 16, Test Loss: 0.6932\n",
      "Hidden Layers: [4], Activation: linear, Epochs: 50, LR: 0.001, Batch Size: 32, Test Loss: 0.7044\n",
      "Hidden Layers: [4], Activation: linear, Epochs: 50, LR: 0.001, Batch Size: 64, Test Loss: 0.6978\n",
      "Hidden Layers: [4], Activation: linear, Epochs: 50, LR: 0.0001, Batch Size: 16, Test Loss: 0.6915\n",
      "Hidden Layers: [4], Activation: linear, Epochs: 50, LR: 0.0001, Batch Size: 32, Test Loss: 0.6960\n",
      "Hidden Layers: [4], Activation: linear, Epochs: 50, LR: 0.0001, Batch Size: 64, Test Loss: 0.7301\n",
      "Hidden Layers: [4], Activation: sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Test Loss: 0.6501\n",
      "Hidden Layers: [4], Activation: sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Test Loss: 0.6691\n",
      "Hidden Layers: [4], Activation: sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Test Loss: 0.6919\n",
      "Hidden Layers: [4], Activation: sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Test Loss: 0.6894\n",
      "Hidden Layers: [4], Activation: sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Test Loss: 0.7371\n",
      "Hidden Layers: [4], Activation: sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Test Loss: 0.7519\n",
      "Hidden Layers: [4], Activation: sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Test Loss: 0.8727\n",
      "Hidden Layers: [4], Activation: sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Test Loss: 0.8803\n",
      "Hidden Layers: [4], Activation: sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Test Loss: 1.4149\n",
      "Hidden Layers: [4], Activation: sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Test Loss: 0.6554\n",
      "Hidden Layers: [4], Activation: sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Test Loss: 0.6541\n",
      "Hidden Layers: [4], Activation: sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Test Loss: 0.6574\n",
      "Hidden Layers: [4], Activation: sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Test Loss: 0.6811\n",
      "Hidden Layers: [4], Activation: sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Test Loss: 0.6886\n",
      "Hidden Layers: [4], Activation: sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Test Loss: 0.7752\n",
      "Hidden Layers: [4], Activation: sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Test Loss: 0.8997\n",
      "Hidden Layers: [4], Activation: sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Test Loss: 0.8680\n",
      "Hidden Layers: [4], Activation: sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Test Loss: 0.9042\n",
      "Hidden Layers: [4], Activation: sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Test Loss: 0.6540\n",
      "Hidden Layers: [4], Activation: sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Test Loss: 0.6565\n",
      "Hidden Layers: [4], Activation: sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Test Loss: 0.6550\n",
      "Hidden Layers: [4], Activation: sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Test Loss: 0.6671\n",
      "Hidden Layers: [4], Activation: sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Test Loss: 0.6723\n",
      "Hidden Layers: [4], Activation: sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Test Loss: 0.6796\n",
      "Hidden Layers: [4], Activation: sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Test Loss: 0.7122\n",
      "Hidden Layers: [4], Activation: sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Test Loss: 0.7505\n",
      "Hidden Layers: [4], Activation: sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Test Loss: 0.8073\n",
      "Hidden Layers: [4], Activation: relu, Epochs: 10, LR: 0.01, Batch Size: 16, Test Loss: 0.6626\n",
      "Hidden Layers: [4], Activation: relu, Epochs: 10, LR: 0.01, Batch Size: 32, Test Loss: 0.6472\n",
      "Hidden Layers: [4], Activation: relu, Epochs: 10, LR: 0.01, Batch Size: 64, Test Loss: 0.6776\n",
      "Hidden Layers: [4], Activation: relu, Epochs: 10, LR: 0.001, Batch Size: 16, Test Loss: 0.6720\n",
      "Hidden Layers: [4], Activation: relu, Epochs: 10, LR: 0.001, Batch Size: 32, Test Loss: 0.7450\n",
      "Hidden Layers: [4], Activation: relu, Epochs: 10, LR: 0.001, Batch Size: 64, Test Loss: 0.7099\n",
      "Hidden Layers: [4], Activation: relu, Epochs: 10, LR: 0.0001, Batch Size: 16, Test Loss: 0.8421\n",
      "Hidden Layers: [4], Activation: relu, Epochs: 10, LR: 0.0001, Batch Size: 32, Test Loss: 0.8287\n",
      "Hidden Layers: [4], Activation: relu, Epochs: 10, LR: 0.0001, Batch Size: 64, Test Loss: 1.1282\n",
      "Hidden Layers: [4], Activation: relu, Epochs: 25, LR: 0.01, Batch Size: 16, Test Loss: 0.6825\n",
      "Hidden Layers: [4], Activation: relu, Epochs: 25, LR: 0.01, Batch Size: 32, Test Loss: 0.6754\n",
      "Hidden Layers: [4], Activation: relu, Epochs: 25, LR: 0.01, Batch Size: 64, Test Loss: 0.7079\n",
      "Hidden Layers: [4], Activation: relu, Epochs: 25, LR: 0.001, Batch Size: 16, Test Loss: 0.6678\n",
      "Hidden Layers: [4], Activation: relu, Epochs: 25, LR: 0.001, Batch Size: 32, Test Loss: 0.6648\n",
      "Hidden Layers: [4], Activation: relu, Epochs: 25, LR: 0.001, Batch Size: 64, Test Loss: 0.6807\n",
      "Hidden Layers: [4], Activation: relu, Epochs: 25, LR: 0.0001, Batch Size: 16, Test Loss: 0.7447\n",
      "Hidden Layers: [4], Activation: relu, Epochs: 25, LR: 0.0001, Batch Size: 32, Test Loss: 0.8127\n",
      "Hidden Layers: [4], Activation: relu, Epochs: 25, LR: 0.0001, Batch Size: 64, Test Loss: 0.7934\n",
      "Hidden Layers: [4], Activation: relu, Epochs: 50, LR: 0.01, Batch Size: 16, Test Loss: 0.7098\n",
      "Hidden Layers: [4], Activation: relu, Epochs: 50, LR: 0.01, Batch Size: 32, Test Loss: 0.6918\n",
      "Hidden Layers: [4], Activation: relu, Epochs: 50, LR: 0.01, Batch Size: 64, Test Loss: 0.7352\n",
      "Hidden Layers: [4], Activation: relu, Epochs: 50, LR: 0.001, Batch Size: 16, Test Loss: 0.7141\n",
      "Hidden Layers: [4], Activation: relu, Epochs: 50, LR: 0.001, Batch Size: 32, Test Loss: 0.6694\n",
      "Hidden Layers: [4], Activation: relu, Epochs: 50, LR: 0.001, Batch Size: 64, Test Loss: 0.6826\n",
      "Hidden Layers: [4], Activation: relu, Epochs: 50, LR: 0.0001, Batch Size: 16, Test Loss: 0.6674\n",
      "Hidden Layers: [4], Activation: relu, Epochs: 50, LR: 0.0001, Batch Size: 32, Test Loss: 0.7188\n",
      "Hidden Layers: [4], Activation: relu, Epochs: 50, LR: 0.0001, Batch Size: 64, Test Loss: 0.7603\n",
      "Hidden Layers: [4], Activation: softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Test Loss: 0.6575\n",
      "Hidden Layers: [4], Activation: softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Test Loss: 0.6445\n",
      "Hidden Layers: [4], Activation: softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Test Loss: 0.6511\n",
      "Hidden Layers: [4], Activation: softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Test Loss: 0.6596\n",
      "Hidden Layers: [4], Activation: softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Test Loss: 0.6759\n",
      "Hidden Layers: [4], Activation: softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Test Loss: 0.7256\n",
      "Hidden Layers: [4], Activation: softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Test Loss: 0.8349\n",
      "Hidden Layers: [4], Activation: softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Test Loss: 0.9296\n",
      "Hidden Layers: [4], Activation: softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Test Loss: 0.9830\n",
      "Hidden Layers: [4], Activation: softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Test Loss: 0.6319\n",
      "Hidden Layers: [4], Activation: softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Test Loss: 0.6479\n",
      "Hidden Layers: [4], Activation: softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Test Loss: 0.6376\n",
      "Hidden Layers: [4], Activation: softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Test Loss: 0.6510\n",
      "Hidden Layers: [4], Activation: softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Test Loss: 0.6522\n",
      "Hidden Layers: [4], Activation: softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Test Loss: 0.6655\n",
      "Hidden Layers: [4], Activation: softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Test Loss: 0.7555\n",
      "Hidden Layers: [4], Activation: softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Test Loss: 0.8509\n",
      "Hidden Layers: [4], Activation: softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Test Loss: 0.8866\n",
      "Hidden Layers: [4], Activation: softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Test Loss: 0.6283\n",
      "Hidden Layers: [4], Activation: softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Test Loss: 0.6374\n",
      "Hidden Layers: [4], Activation: softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Test Loss: 0.6291\n",
      "Hidden Layers: [4], Activation: softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Test Loss: 0.6432\n",
      "Hidden Layers: [4], Activation: softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Test Loss: 0.6448\n",
      "Hidden Layers: [4], Activation: softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Test Loss: 0.6550\n",
      "Hidden Layers: [4], Activation: softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Test Loss: 0.7032\n",
      "Hidden Layers: [4], Activation: softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Test Loss: 0.7775\n",
      "Hidden Layers: [4], Activation: softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Test Loss: 0.8234\n",
      "Hidden Layers: [4], Activation: tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Test Loss: 0.6494\n",
      "Hidden Layers: [4], Activation: tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Test Loss: 0.6534\n",
      "Hidden Layers: [4], Activation: tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Test Loss: 0.6659\n",
      "Hidden Layers: [4], Activation: tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Test Loss: 0.6811\n",
      "Hidden Layers: [4], Activation: tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Test Loss: 0.6801\n",
      "Hidden Layers: [4], Activation: tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Test Loss: 0.6886\n",
      "Hidden Layers: [4], Activation: tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Test Loss: 0.7750\n",
      "Hidden Layers: [4], Activation: tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Test Loss: 0.7827\n",
      "Hidden Layers: [4], Activation: tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Test Loss: 0.8157\n",
      "Hidden Layers: [4], Activation: tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Test Loss: 0.6741\n",
      "Hidden Layers: [4], Activation: tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Test Loss: 0.6510\n",
      "Hidden Layers: [4], Activation: tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Test Loss: 0.6524\n",
      "Hidden Layers: [4], Activation: tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Test Loss: 0.6450\n",
      "Hidden Layers: [4], Activation: tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Test Loss: 0.6773\n",
      "Hidden Layers: [4], Activation: tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Test Loss: 0.6818\n",
      "Hidden Layers: [4], Activation: tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Test Loss: 0.7088\n",
      "Hidden Layers: [4], Activation: tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Test Loss: 0.7039\n",
      "Hidden Layers: [4], Activation: tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Test Loss: 0.9100\n",
      "Hidden Layers: [4], Activation: tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Test Loss: 0.6529\n",
      "Hidden Layers: [4], Activation: tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Test Loss: 0.6540\n",
      "Hidden Layers: [4], Activation: tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Test Loss: 0.6358\n",
      "Hidden Layers: [4], Activation: tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Test Loss: 0.6546\n",
      "Hidden Layers: [4], Activation: tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Test Loss: 0.6530\n",
      "Hidden Layers: [4], Activation: tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Test Loss: 0.6577\n",
      "Hidden Layers: [4], Activation: tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Test Loss: 0.6768\n",
      "Hidden Layers: [4], Activation: tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Test Loss: 0.6893\n",
      "Hidden Layers: [4], Activation: tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Test Loss: 0.7176\n",
      "Hidden Layers: [8], Activation: linear, Epochs: 10, LR: 0.01, Batch Size: 16, Test Loss: 0.6894\n",
      "Hidden Layers: [8], Activation: linear, Epochs: 10, LR: 0.01, Batch Size: 32, Test Loss: 0.6959\n",
      "Hidden Layers: [8], Activation: linear, Epochs: 10, LR: 0.01, Batch Size: 64, Test Loss: 0.6958\n",
      "Hidden Layers: [8], Activation: linear, Epochs: 10, LR: 0.001, Batch Size: 16, Test Loss: 0.6919\n",
      "Hidden Layers: [8], Activation: linear, Epochs: 10, LR: 0.001, Batch Size: 32, Test Loss: 0.6962\n",
      "Hidden Layers: [8], Activation: linear, Epochs: 10, LR: 0.001, Batch Size: 64, Test Loss: 0.6963\n",
      "Hidden Layers: [8], Activation: linear, Epochs: 10, LR: 0.0001, Batch Size: 16, Test Loss: 0.7583\n",
      "Hidden Layers: [8], Activation: linear, Epochs: 10, LR: 0.0001, Batch Size: 32, Test Loss: 0.8609\n",
      "Hidden Layers: [8], Activation: linear, Epochs: 10, LR: 0.0001, Batch Size: 64, Test Loss: 0.7981\n",
      "Hidden Layers: [8], Activation: linear, Epochs: 25, LR: 0.01, Batch Size: 16, Test Loss: 0.7092\n",
      "Hidden Layers: [8], Activation: linear, Epochs: 25, LR: 0.01, Batch Size: 32, Test Loss: 0.7038\n",
      "Hidden Layers: [8], Activation: linear, Epochs: 25, LR: 0.01, Batch Size: 64, Test Loss: 0.7047\n",
      "Hidden Layers: [8], Activation: linear, Epochs: 25, LR: 0.001, Batch Size: 16, Test Loss: 0.6988\n",
      "Hidden Layers: [8], Activation: linear, Epochs: 25, LR: 0.001, Batch Size: 32, Test Loss: 0.6958\n",
      "Hidden Layers: [8], Activation: linear, Epochs: 25, LR: 0.001, Batch Size: 64, Test Loss: 0.6986\n",
      "Hidden Layers: [8], Activation: linear, Epochs: 25, LR: 0.0001, Batch Size: 16, Test Loss: 0.6934\n",
      "Hidden Layers: [8], Activation: linear, Epochs: 25, LR: 0.0001, Batch Size: 32, Test Loss: 0.7066\n",
      "Hidden Layers: [8], Activation: linear, Epochs: 25, LR: 0.0001, Batch Size: 64, Test Loss: 0.7669\n",
      "Hidden Layers: [8], Activation: linear, Epochs: 50, LR: 0.01, Batch Size: 16, Test Loss: 0.7028\n",
      "Hidden Layers: [8], Activation: linear, Epochs: 50, LR: 0.01, Batch Size: 32, Test Loss: 0.7048\n",
      "Hidden Layers: [8], Activation: linear, Epochs: 50, LR: 0.01, Batch Size: 64, Test Loss: 0.7156\n",
      "Hidden Layers: [8], Activation: linear, Epochs: 50, LR: 0.001, Batch Size: 16, Test Loss: 0.7072\n",
      "Hidden Layers: [8], Activation: linear, Epochs: 50, LR: 0.001, Batch Size: 32, Test Loss: 0.7075\n",
      "Hidden Layers: [8], Activation: linear, Epochs: 50, LR: 0.001, Batch Size: 64, Test Loss: 0.6981\n",
      "Hidden Layers: [8], Activation: linear, Epochs: 50, LR: 0.0001, Batch Size: 16, Test Loss: 0.6928\n",
      "Hidden Layers: [8], Activation: linear, Epochs: 50, LR: 0.0001, Batch Size: 32, Test Loss: 0.6941\n",
      "Hidden Layers: [8], Activation: linear, Epochs: 50, LR: 0.0001, Batch Size: 64, Test Loss: 0.7278\n",
      "Hidden Layers: [8], Activation: sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Test Loss: 0.6476\n",
      "Hidden Layers: [8], Activation: sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Test Loss: 0.6702\n",
      "Hidden Layers: [8], Activation: sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Test Loss: 0.6712\n",
      "Hidden Layers: [8], Activation: sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Test Loss: 0.6831\n",
      "Hidden Layers: [8], Activation: sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Test Loss: 0.6959\n",
      "Hidden Layers: [8], Activation: sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Test Loss: 0.7202\n",
      "Hidden Layers: [8], Activation: sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Test Loss: 0.8507\n",
      "Hidden Layers: [8], Activation: sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Test Loss: 0.8616\n",
      "Hidden Layers: [8], Activation: sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Test Loss: 0.9176\n",
      "Hidden Layers: [8], Activation: sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Test Loss: 0.6342\n",
      "Hidden Layers: [8], Activation: sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Test Loss: 0.6373\n",
      "Hidden Layers: [8], Activation: sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Test Loss: 0.6299\n",
      "Hidden Layers: [8], Activation: sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Test Loss: 0.6721\n",
      "Hidden Layers: [8], Activation: sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Test Loss: 0.6845\n",
      "Hidden Layers: [8], Activation: sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Test Loss: 0.6911\n",
      "Hidden Layers: [8], Activation: sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Test Loss: 0.7261\n",
      "Hidden Layers: [8], Activation: sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Test Loss: 0.7878\n",
      "Hidden Layers: [8], Activation: sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Test Loss: 0.8935\n",
      "Hidden Layers: [8], Activation: sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Test Loss: 0.6301\n",
      "Hidden Layers: [8], Activation: sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Test Loss: 0.6667\n",
      "Hidden Layers: [8], Activation: sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Test Loss: 0.6512\n",
      "Hidden Layers: [8], Activation: sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Test Loss: 0.6496\n",
      "Hidden Layers: [8], Activation: sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Test Loss: 0.6582\n",
      "Hidden Layers: [8], Activation: sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Test Loss: 0.6780\n",
      "Hidden Layers: [8], Activation: sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Test Loss: 0.6964\n",
      "Hidden Layers: [8], Activation: sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Test Loss: 0.7310\n",
      "Hidden Layers: [8], Activation: sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Test Loss: 0.8034\n",
      "Hidden Layers: [8], Activation: relu, Epochs: 10, LR: 0.01, Batch Size: 16, Test Loss: 0.6586\n",
      "Hidden Layers: [8], Activation: relu, Epochs: 10, LR: 0.01, Batch Size: 32, Test Loss: 0.6769\n",
      "Hidden Layers: [8], Activation: relu, Epochs: 10, LR: 0.01, Batch Size: 64, Test Loss: 0.6709\n",
      "Hidden Layers: [8], Activation: relu, Epochs: 10, LR: 0.001, Batch Size: 16, Test Loss: 0.6594\n",
      "Hidden Layers: [8], Activation: relu, Epochs: 10, LR: 0.001, Batch Size: 32, Test Loss: 0.6669\n",
      "Hidden Layers: [8], Activation: relu, Epochs: 10, LR: 0.001, Batch Size: 64, Test Loss: 0.6779\n",
      "Hidden Layers: [8], Activation: relu, Epochs: 10, LR: 0.0001, Batch Size: 16, Test Loss: 0.7188\n",
      "Hidden Layers: [8], Activation: relu, Epochs: 10, LR: 0.0001, Batch Size: 32, Test Loss: 0.8605\n",
      "Hidden Layers: [8], Activation: relu, Epochs: 10, LR: 0.0001, Batch Size: 64, Test Loss: 0.9281\n",
      "Hidden Layers: [8], Activation: relu, Epochs: 25, LR: 0.01, Batch Size: 16, Test Loss: 0.6739\n",
      "Hidden Layers: [8], Activation: relu, Epochs: 25, LR: 0.01, Batch Size: 32, Test Loss: 0.7013\n",
      "Hidden Layers: [8], Activation: relu, Epochs: 25, LR: 0.01, Batch Size: 64, Test Loss: 0.6495\n",
      "Hidden Layers: [8], Activation: relu, Epochs: 25, LR: 0.001, Batch Size: 16, Test Loss: 0.6509\n",
      "Hidden Layers: [8], Activation: relu, Epochs: 25, LR: 0.001, Batch Size: 32, Test Loss: 0.6389\n",
      "Hidden Layers: [8], Activation: relu, Epochs: 25, LR: 0.001, Batch Size: 64, Test Loss: 0.6460\n",
      "Hidden Layers: [8], Activation: relu, Epochs: 25, LR: 0.0001, Batch Size: 16, Test Loss: 0.6704\n",
      "Hidden Layers: [8], Activation: relu, Epochs: 25, LR: 0.0001, Batch Size: 32, Test Loss: 0.7263\n",
      "Hidden Layers: [8], Activation: relu, Epochs: 25, LR: 0.0001, Batch Size: 64, Test Loss: 0.7629\n",
      "Hidden Layers: [8], Activation: relu, Epochs: 50, LR: 0.01, Batch Size: 16, Test Loss: 0.6915\n",
      "Hidden Layers: [8], Activation: relu, Epochs: 50, LR: 0.01, Batch Size: 32, Test Loss: 0.6856\n",
      "Hidden Layers: [8], Activation: relu, Epochs: 50, LR: 0.01, Batch Size: 64, Test Loss: 0.6506\n",
      "Hidden Layers: [8], Activation: relu, Epochs: 50, LR: 0.001, Batch Size: 16, Test Loss: 0.6778\n",
      "Hidden Layers: [8], Activation: relu, Epochs: 50, LR: 0.001, Batch Size: 32, Test Loss: 0.6344\n",
      "Hidden Layers: [8], Activation: relu, Epochs: 50, LR: 0.001, Batch Size: 64, Test Loss: 0.6531\n",
      "Hidden Layers: [8], Activation: relu, Epochs: 50, LR: 0.0001, Batch Size: 16, Test Loss: 0.6687\n",
      "Hidden Layers: [8], Activation: relu, Epochs: 50, LR: 0.0001, Batch Size: 32, Test Loss: 0.6681\n",
      "Hidden Layers: [8], Activation: relu, Epochs: 50, LR: 0.0001, Batch Size: 64, Test Loss: 0.6924\n",
      "Hidden Layers: [8], Activation: softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Test Loss: 0.6145\n",
      "Hidden Layers: [8], Activation: softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Test Loss: 0.6334\n",
      "Hidden Layers: [8], Activation: softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Test Loss: 0.6277\n",
      "Hidden Layers: [8], Activation: softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Test Loss: 0.6446\n",
      "Hidden Layers: [8], Activation: softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Test Loss: 0.6593\n",
      "Hidden Layers: [8], Activation: softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Test Loss: 0.7030\n",
      "Hidden Layers: [8], Activation: softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Test Loss: 0.9385\n",
      "Hidden Layers: [8], Activation: softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Test Loss: 0.8660\n",
      "Hidden Layers: [8], Activation: softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Test Loss: 0.9439\n",
      "Hidden Layers: [8], Activation: softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Test Loss: 0.6348\n",
      "Hidden Layers: [8], Activation: softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Test Loss: 0.6209\n",
      "Hidden Layers: [8], Activation: softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Test Loss: 0.6289\n",
      "Hidden Layers: [8], Activation: softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Test Loss: 0.6359\n",
      "Hidden Layers: [8], Activation: softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Test Loss: 0.6355\n",
      "Hidden Layers: [8], Activation: softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Test Loss: 0.6515\n",
      "Hidden Layers: [8], Activation: softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Test Loss: 0.7449\n",
      "Hidden Layers: [8], Activation: softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Test Loss: 0.8530\n",
      "Hidden Layers: [8], Activation: softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Test Loss: 0.8845\n",
      "Hidden Layers: [8], Activation: softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Test Loss: 0.6161\n",
      "Hidden Layers: [8], Activation: softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Test Loss: 0.6186\n",
      "Hidden Layers: [8], Activation: softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Test Loss: 0.6093\n",
      "Hidden Layers: [8], Activation: softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Test Loss: 0.6138\n",
      "Hidden Layers: [8], Activation: softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Test Loss: 0.6210\n",
      "Hidden Layers: [8], Activation: softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Test Loss: 0.6272\n",
      "Hidden Layers: [8], Activation: softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Test Loss: 0.6887\n",
      "Hidden Layers: [8], Activation: softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Test Loss: 0.7338\n",
      "Hidden Layers: [8], Activation: softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Test Loss: 0.7936\n",
      "Hidden Layers: [8], Activation: tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Test Loss: 0.6400\n",
      "Hidden Layers: [8], Activation: tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Test Loss: 0.6374\n",
      "Hidden Layers: [8], Activation: tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Test Loss: 0.6473\n",
      "Hidden Layers: [8], Activation: tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Test Loss: 0.6768\n",
      "Hidden Layers: [8], Activation: tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Test Loss: 0.6765\n",
      "Hidden Layers: [8], Activation: tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Test Loss: 0.6907\n",
      "Hidden Layers: [8], Activation: tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Test Loss: 0.7197\n",
      "Hidden Layers: [8], Activation: tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Test Loss: 0.8442\n",
      "Hidden Layers: [8], Activation: tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Test Loss: 0.9053\n",
      "Hidden Layers: [8], Activation: tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Test Loss: 0.6496\n",
      "Hidden Layers: [8], Activation: tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Test Loss: 0.6272\n",
      "Hidden Layers: [8], Activation: tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Test Loss: 0.6419\n",
      "Hidden Layers: [8], Activation: tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Test Loss: 0.6439\n",
      "Hidden Layers: [8], Activation: tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Test Loss: 0.6595\n",
      "Hidden Layers: [8], Activation: tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Test Loss: 0.6753\n",
      "Hidden Layers: [8], Activation: tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Test Loss: 0.6900\n",
      "Hidden Layers: [8], Activation: tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Test Loss: 0.6994\n",
      "Hidden Layers: [8], Activation: tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Test Loss: 0.7295\n",
      "Hidden Layers: [8], Activation: tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Test Loss: 0.6541\n",
      "Hidden Layers: [8], Activation: tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Test Loss: 0.6262\n",
      "Hidden Layers: [8], Activation: tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Test Loss: 0.6397\n",
      "Hidden Layers: [8], Activation: tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Test Loss: 0.6222\n",
      "Hidden Layers: [8], Activation: tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Test Loss: 0.6428\n",
      "Hidden Layers: [8], Activation: tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Test Loss: 0.6411\n",
      "Hidden Layers: [8], Activation: tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Test Loss: 0.6790\n",
      "Hidden Layers: [8], Activation: tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Test Loss: 0.6837\n",
      "Hidden Layers: [8], Activation: tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Test Loss: 0.7152\n",
      "Hidden Layers: [16], Activation: linear, Epochs: 10, LR: 0.01, Batch Size: 16, Test Loss: 0.6984\n",
      "Hidden Layers: [16], Activation: linear, Epochs: 10, LR: 0.01, Batch Size: 32, Test Loss: 0.6907\n",
      "Hidden Layers: [16], Activation: linear, Epochs: 10, LR: 0.01, Batch Size: 64, Test Loss: 0.7093\n",
      "Hidden Layers: [16], Activation: linear, Epochs: 10, LR: 0.001, Batch Size: 16, Test Loss: 0.6925\n",
      "Hidden Layers: [16], Activation: linear, Epochs: 10, LR: 0.001, Batch Size: 32, Test Loss: 0.6949\n",
      "Hidden Layers: [16], Activation: linear, Epochs: 10, LR: 0.001, Batch Size: 64, Test Loss: 0.6939\n",
      "Hidden Layers: [16], Activation: linear, Epochs: 10, LR: 0.0001, Batch Size: 16, Test Loss: 0.7062\n",
      "Hidden Layers: [16], Activation: linear, Epochs: 10, LR: 0.0001, Batch Size: 32, Test Loss: 0.7309\n",
      "Hidden Layers: [16], Activation: linear, Epochs: 10, LR: 0.0001, Batch Size: 64, Test Loss: 0.8190\n",
      "Hidden Layers: [16], Activation: linear, Epochs: 25, LR: 0.01, Batch Size: 16, Test Loss: 0.7112\n",
      "Hidden Layers: [16], Activation: linear, Epochs: 25, LR: 0.01, Batch Size: 32, Test Loss: 0.7358\n",
      "Hidden Layers: [16], Activation: linear, Epochs: 25, LR: 0.01, Batch Size: 64, Test Loss: 0.7201\n",
      "Hidden Layers: [16], Activation: linear, Epochs: 25, LR: 0.001, Batch Size: 16, Test Loss: 0.6904\n",
      "Hidden Layers: [16], Activation: linear, Epochs: 25, LR: 0.001, Batch Size: 32, Test Loss: 0.6919\n",
      "Hidden Layers: [16], Activation: linear, Epochs: 25, LR: 0.001, Batch Size: 64, Test Loss: 0.6974\n",
      "Hidden Layers: [16], Activation: linear, Epochs: 25, LR: 0.0001, Batch Size: 16, Test Loss: 0.6901\n",
      "Hidden Layers: [16], Activation: linear, Epochs: 25, LR: 0.0001, Batch Size: 32, Test Loss: 0.7039\n",
      "Hidden Layers: [16], Activation: linear, Epochs: 25, LR: 0.0001, Batch Size: 64, Test Loss: 0.7123\n",
      "Hidden Layers: [16], Activation: linear, Epochs: 50, LR: 0.01, Batch Size: 16, Test Loss: 0.6993\n",
      "Hidden Layers: [16], Activation: linear, Epochs: 50, LR: 0.01, Batch Size: 32, Test Loss: 0.7167\n",
      "Hidden Layers: [16], Activation: linear, Epochs: 50, LR: 0.01, Batch Size: 64, Test Loss: 0.7198\n",
      "Hidden Layers: [16], Activation: linear, Epochs: 50, LR: 0.001, Batch Size: 16, Test Loss: 0.6964\n",
      "Hidden Layers: [16], Activation: linear, Epochs: 50, LR: 0.001, Batch Size: 32, Test Loss: 0.7034\n",
      "Hidden Layers: [16], Activation: linear, Epochs: 50, LR: 0.001, Batch Size: 64, Test Loss: 0.7036\n",
      "Hidden Layers: [16], Activation: linear, Epochs: 50, LR: 0.0001, Batch Size: 16, Test Loss: 0.6908\n",
      "Hidden Layers: [16], Activation: linear, Epochs: 50, LR: 0.0001, Batch Size: 32, Test Loss: 0.6928\n",
      "Hidden Layers: [16], Activation: linear, Epochs: 50, LR: 0.0001, Batch Size: 64, Test Loss: 0.6977\n",
      "Hidden Layers: [16], Activation: sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Test Loss: 0.6444\n",
      "Hidden Layers: [16], Activation: sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Test Loss: 0.6560\n",
      "Hidden Layers: [16], Activation: sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Test Loss: 0.6541\n",
      "Hidden Layers: [16], Activation: sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Test Loss: 0.6863\n",
      "Hidden Layers: [16], Activation: sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Test Loss: 0.6866\n",
      "Hidden Layers: [16], Activation: sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Test Loss: 0.7072\n",
      "Hidden Layers: [16], Activation: sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Test Loss: 0.7855\n",
      "Hidden Layers: [16], Activation: sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Test Loss: 0.8168\n",
      "Hidden Layers: [16], Activation: sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Test Loss: 0.9020\n",
      "Hidden Layers: [16], Activation: sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Test Loss: 0.6320\n",
      "Hidden Layers: [16], Activation: sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Test Loss: 0.6305\n",
      "Hidden Layers: [16], Activation: sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Test Loss: 0.6234\n",
      "Hidden Layers: [16], Activation: sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Test Loss: 0.6606\n",
      "Hidden Layers: [16], Activation: sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Test Loss: 0.6799\n",
      "Hidden Layers: [16], Activation: sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Test Loss: 0.6878\n",
      "Hidden Layers: [16], Activation: sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Test Loss: 0.7227\n",
      "Hidden Layers: [16], Activation: sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Test Loss: 0.7578\n",
      "Hidden Layers: [16], Activation: sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Test Loss: 0.8113\n",
      "Hidden Layers: [16], Activation: sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Test Loss: 0.6425\n",
      "Hidden Layers: [16], Activation: sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Test Loss: 0.6358\n",
      "Hidden Layers: [16], Activation: sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Test Loss: 0.6221\n",
      "Hidden Layers: [16], Activation: sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Test Loss: 0.6442\n",
      "Hidden Layers: [16], Activation: sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Test Loss: 0.6598\n",
      "Hidden Layers: [16], Activation: sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Test Loss: 0.6775\n",
      "Hidden Layers: [16], Activation: sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Test Loss: 0.6925\n",
      "Hidden Layers: [16], Activation: sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Test Loss: 0.7089\n",
      "Hidden Layers: [16], Activation: sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Test Loss: 0.7561\n",
      "Hidden Layers: [16], Activation: relu, Epochs: 10, LR: 0.01, Batch Size: 16, Test Loss: 0.6240\n",
      "Hidden Layers: [16], Activation: relu, Epochs: 10, LR: 0.01, Batch Size: 32, Test Loss: 0.6553\n",
      "Hidden Layers: [16], Activation: relu, Epochs: 10, LR: 0.01, Batch Size: 64, Test Loss: 0.7015\n",
      "Hidden Layers: [16], Activation: relu, Epochs: 10, LR: 0.001, Batch Size: 16, Test Loss: 0.6251\n",
      "Hidden Layers: [16], Activation: relu, Epochs: 10, LR: 0.001, Batch Size: 32, Test Loss: 0.6406\n",
      "Hidden Layers: [16], Activation: relu, Epochs: 10, LR: 0.001, Batch Size: 64, Test Loss: 0.6630\n",
      "Hidden Layers: [16], Activation: relu, Epochs: 10, LR: 0.0001, Batch Size: 16, Test Loss: 0.7224\n",
      "Hidden Layers: [16], Activation: relu, Epochs: 10, LR: 0.0001, Batch Size: 32, Test Loss: 0.7720\n",
      "Hidden Layers: [16], Activation: relu, Epochs: 10, LR: 0.0001, Batch Size: 64, Test Loss: 0.8150\n",
      "Hidden Layers: [16], Activation: relu, Epochs: 25, LR: 0.01, Batch Size: 16, Test Loss: 0.7144\n",
      "Hidden Layers: [16], Activation: relu, Epochs: 25, LR: 0.01, Batch Size: 32, Test Loss: 0.7402\n",
      "Hidden Layers: [16], Activation: relu, Epochs: 25, LR: 0.01, Batch Size: 64, Test Loss: 0.6600\n",
      "Hidden Layers: [16], Activation: relu, Epochs: 25, LR: 0.001, Batch Size: 16, Test Loss: 0.6403\n",
      "Hidden Layers: [16], Activation: relu, Epochs: 25, LR: 0.001, Batch Size: 32, Test Loss: 0.6437\n",
      "Hidden Layers: [16], Activation: relu, Epochs: 25, LR: 0.001, Batch Size: 64, Test Loss: 0.6396\n",
      "Hidden Layers: [16], Activation: relu, Epochs: 25, LR: 0.0001, Batch Size: 16, Test Loss: 0.6694\n",
      "Hidden Layers: [16], Activation: relu, Epochs: 25, LR: 0.0001, Batch Size: 32, Test Loss: 0.6736\n",
      "Hidden Layers: [16], Activation: relu, Epochs: 25, LR: 0.0001, Batch Size: 64, Test Loss: 0.7506\n",
      "Hidden Layers: [16], Activation: relu, Epochs: 50, LR: 0.01, Batch Size: 16, Test Loss: 0.6087\n",
      "Hidden Layers: [16], Activation: relu, Epochs: 50, LR: 0.01, Batch Size: 32, Test Loss: 0.7518\n",
      "Hidden Layers: [16], Activation: relu, Epochs: 50, LR: 0.01, Batch Size: 64, Test Loss: 0.6553\n",
      "Hidden Layers: [16], Activation: relu, Epochs: 50, LR: 0.001, Batch Size: 16, Test Loss: 0.6469\n",
      "Hidden Layers: [16], Activation: relu, Epochs: 50, LR: 0.001, Batch Size: 32, Test Loss: 0.6258\n",
      "Hidden Layers: [16], Activation: relu, Epochs: 50, LR: 0.001, Batch Size: 64, Test Loss: 0.6528\n",
      "Hidden Layers: [16], Activation: relu, Epochs: 50, LR: 0.0001, Batch Size: 16, Test Loss: 0.6345\n",
      "Hidden Layers: [16], Activation: relu, Epochs: 50, LR: 0.0001, Batch Size: 32, Test Loss: 0.6626\n",
      "Hidden Layers: [16], Activation: relu, Epochs: 50, LR: 0.0001, Batch Size: 64, Test Loss: 0.6594\n",
      "Hidden Layers: [16], Activation: softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Test Loss: 0.6212\n",
      "Hidden Layers: [16], Activation: softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Test Loss: 0.6061\n",
      "Hidden Layers: [16], Activation: softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Test Loss: 0.6169\n",
      "Hidden Layers: [16], Activation: softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Test Loss: 0.6385\n",
      "Hidden Layers: [16], Activation: softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Test Loss: 0.6484\n",
      "Hidden Layers: [16], Activation: softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Test Loss: 0.6969\n",
      "Hidden Layers: [16], Activation: softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Test Loss: 0.8774\n",
      "Hidden Layers: [16], Activation: softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Test Loss: 0.8938\n",
      "Hidden Layers: [16], Activation: softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Test Loss: 0.9282\n",
      "Hidden Layers: [16], Activation: softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Test Loss: 0.6106\n",
      "Hidden Layers: [16], Activation: softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Test Loss: 0.6061\n",
      "Hidden Layers: [16], Activation: softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Test Loss: 0.6094\n",
      "Hidden Layers: [16], Activation: softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Test Loss: 0.6173\n",
      "Hidden Layers: [16], Activation: softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Test Loss: 0.6249\n",
      "Hidden Layers: [16], Activation: softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Test Loss: 0.6333\n",
      "Hidden Layers: [16], Activation: softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Test Loss: 0.7815\n",
      "Hidden Layers: [16], Activation: softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Test Loss: 0.8309\n",
      "Hidden Layers: [16], Activation: softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Test Loss: 0.9058\n",
      "Hidden Layers: [16], Activation: softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Test Loss: 0.6142\n",
      "Hidden Layers: [16], Activation: softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Test Loss: 0.6163\n",
      "Hidden Layers: [16], Activation: softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Test Loss: 0.6024\n",
      "Hidden Layers: [16], Activation: softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Test Loss: 0.6047\n",
      "Hidden Layers: [16], Activation: softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Test Loss: 0.6150\n",
      "Hidden Layers: [16], Activation: softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Test Loss: 0.6184\n",
      "Hidden Layers: [16], Activation: softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Test Loss: 0.6754\n",
      "Hidden Layers: [16], Activation: softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Test Loss: 0.7326\n",
      "Hidden Layers: [16], Activation: softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Test Loss: 0.8127\n",
      "Hidden Layers: [16], Activation: tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Test Loss: 0.6410\n",
      "Hidden Layers: [16], Activation: tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Test Loss: 0.6371\n",
      "Hidden Layers: [16], Activation: tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Test Loss: 0.6387\n",
      "Hidden Layers: [16], Activation: tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Test Loss: 0.6632\n",
      "Hidden Layers: [16], Activation: tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Test Loss: 0.6647\n",
      "Hidden Layers: [16], Activation: tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Test Loss: 0.6773\n",
      "Hidden Layers: [16], Activation: tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Test Loss: 0.7017\n",
      "Hidden Layers: [16], Activation: tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Test Loss: 0.7199\n",
      "Hidden Layers: [16], Activation: tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Test Loss: 0.8438\n",
      "Hidden Layers: [16], Activation: tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Test Loss: 0.6326\n",
      "Hidden Layers: [16], Activation: tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Test Loss: 0.6458\n",
      "Hidden Layers: [16], Activation: tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Test Loss: 0.6313\n",
      "Hidden Layers: [16], Activation: tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Test Loss: 0.6264\n",
      "Hidden Layers: [16], Activation: tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Test Loss: 0.6343\n",
      "Hidden Layers: [16], Activation: tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Test Loss: 0.6357\n",
      "Hidden Layers: [16], Activation: tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Test Loss: 0.6811\n",
      "Hidden Layers: [16], Activation: tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Test Loss: 0.6941\n",
      "Hidden Layers: [16], Activation: tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Test Loss: 0.7209\n",
      "Hidden Layers: [16], Activation: tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Test Loss: 0.6622\n",
      "Hidden Layers: [16], Activation: tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Test Loss: 0.6431\n",
      "Hidden Layers: [16], Activation: tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Test Loss: 0.6162\n",
      "Hidden Layers: [16], Activation: tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Test Loss: 0.6181\n",
      "Hidden Layers: [16], Activation: tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Test Loss: 0.6108\n",
      "Hidden Layers: [16], Activation: tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Test Loss: 0.6286\n",
      "Hidden Layers: [16], Activation: tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Test Loss: 0.6705\n",
      "Hidden Layers: [16], Activation: tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Test Loss: 0.6901\n",
      "Hidden Layers: [16], Activation: tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Test Loss: 0.6905\n",
      "Hidden Layers: [4, 8], Activation: linear, Epochs: 10, LR: 0.01, Batch Size: 16, Test Loss: 0.6932\n",
      "Hidden Layers: [4, 8], Activation: linear, Epochs: 10, LR: 0.01, Batch Size: 32, Test Loss: 0.7123\n",
      "Hidden Layers: [4, 8], Activation: linear, Epochs: 10, LR: 0.01, Batch Size: 64, Test Loss: 0.6962\n",
      "Hidden Layers: [4, 8], Activation: linear, Epochs: 10, LR: 0.001, Batch Size: 16, Test Loss: 0.6923\n",
      "Hidden Layers: [4, 8], Activation: linear, Epochs: 10, LR: 0.001, Batch Size: 32, Test Loss: 0.6944\n",
      "Hidden Layers: [4, 8], Activation: linear, Epochs: 10, LR: 0.001, Batch Size: 64, Test Loss: 0.6943\n",
      "Hidden Layers: [4, 8], Activation: linear, Epochs: 10, LR: 0.0001, Batch Size: 16, Test Loss: 0.8312\n",
      "Hidden Layers: [4, 8], Activation: linear, Epochs: 10, LR: 0.0001, Batch Size: 32, Test Loss: 0.7649\n",
      "Hidden Layers: [4, 8], Activation: linear, Epochs: 10, LR: 0.0001, Batch Size: 64, Test Loss: 0.8670\n",
      "Hidden Layers: [4, 8], Activation: linear, Epochs: 25, LR: 0.01, Batch Size: 16, Test Loss: 0.6932\n",
      "Hidden Layers: [4, 8], Activation: linear, Epochs: 25, LR: 0.01, Batch Size: 32, Test Loss: 0.7198\n",
      "Hidden Layers: [4, 8], Activation: linear, Epochs: 25, LR: 0.01, Batch Size: 64, Test Loss: 0.7014\n",
      "Hidden Layers: [4, 8], Activation: linear, Epochs: 25, LR: 0.001, Batch Size: 16, Test Loss: 0.6910\n",
      "Hidden Layers: [4, 8], Activation: linear, Epochs: 25, LR: 0.001, Batch Size: 32, Test Loss: 0.7021\n",
      "Hidden Layers: [4, 8], Activation: linear, Epochs: 25, LR: 0.001, Batch Size: 64, Test Loss: 0.7002\n",
      "Hidden Layers: [4, 8], Activation: linear, Epochs: 25, LR: 0.0001, Batch Size: 16, Test Loss: 0.7018\n",
      "Hidden Layers: [4, 8], Activation: linear, Epochs: 25, LR: 0.0001, Batch Size: 32, Test Loss: 0.7174\n",
      "Hidden Layers: [4, 8], Activation: linear, Epochs: 25, LR: 0.0001, Batch Size: 64, Test Loss: 0.7349\n",
      "Hidden Layers: [4, 8], Activation: linear, Epochs: 50, LR: 0.01, Batch Size: 16, Test Loss: 0.7034\n",
      "Hidden Layers: [4, 8], Activation: linear, Epochs: 50, LR: 0.01, Batch Size: 32, Test Loss: 0.7012\n",
      "Hidden Layers: [4, 8], Activation: linear, Epochs: 50, LR: 0.01, Batch Size: 64, Test Loss: 0.7129\n",
      "Hidden Layers: [4, 8], Activation: linear, Epochs: 50, LR: 0.001, Batch Size: 16, Test Loss: 0.6965\n",
      "Hidden Layers: [4, 8], Activation: linear, Epochs: 50, LR: 0.001, Batch Size: 32, Test Loss: 0.6982\n",
      "Hidden Layers: [4, 8], Activation: linear, Epochs: 50, LR: 0.001, Batch Size: 64, Test Loss: 0.6970\n",
      "Hidden Layers: [4, 8], Activation: linear, Epochs: 50, LR: 0.0001, Batch Size: 16, Test Loss: 0.6914\n",
      "Hidden Layers: [4, 8], Activation: linear, Epochs: 50, LR: 0.0001, Batch Size: 32, Test Loss: 0.7058\n",
      "Hidden Layers: [4, 8], Activation: linear, Epochs: 50, LR: 0.0001, Batch Size: 64, Test Loss: 0.6983\n",
      "Hidden Layers: [4, 8], Activation: sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Test Loss: 0.6613\n",
      "Hidden Layers: [4, 8], Activation: sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Test Loss: 0.6648\n",
      "Hidden Layers: [4, 8], Activation: sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Test Loss: 0.6739\n",
      "Hidden Layers: [4, 8], Activation: sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Test Loss: 0.6933\n",
      "Hidden Layers: [4, 8], Activation: sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Test Loss: 0.7131\n",
      "Hidden Layers: [4, 8], Activation: sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Test Loss: 0.7670\n",
      "Hidden Layers: [4, 8], Activation: sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Test Loss: 0.9309\n",
      "Hidden Layers: [4, 8], Activation: sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Test Loss: 0.9392\n",
      "Hidden Layers: [4, 8], Activation: sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Test Loss: 0.9506\n",
      "Hidden Layers: [4, 8], Activation: sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Test Loss: 0.6405\n",
      "Hidden Layers: [4, 8], Activation: sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Test Loss: 0.6665\n",
      "Hidden Layers: [4, 8], Activation: sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Test Loss: 0.6607\n",
      "Hidden Layers: [4, 8], Activation: sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Test Loss: 0.6815\n",
      "Hidden Layers: [4, 8], Activation: sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Test Loss: 0.6862\n",
      "Hidden Layers: [4, 8], Activation: sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Test Loss: 0.6960\n",
      "Hidden Layers: [4, 8], Activation: sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Test Loss: 0.8269\n",
      "Hidden Layers: [4, 8], Activation: sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Test Loss: 0.9078\n",
      "Hidden Layers: [4, 8], Activation: sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Test Loss: 0.9353\n",
      "Hidden Layers: [4, 8], Activation: sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Test Loss: 0.6387\n",
      "Hidden Layers: [4, 8], Activation: sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Test Loss: 0.6665\n",
      "Hidden Layers: [4, 8], Activation: sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Test Loss: 0.6346\n",
      "Hidden Layers: [4, 8], Activation: sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Test Loss: 0.6749\n",
      "Hidden Layers: [4, 8], Activation: sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Test Loss: 0.6787\n",
      "Hidden Layers: [4, 8], Activation: sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Test Loss: 0.6922\n",
      "Hidden Layers: [4, 8], Activation: sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Test Loss: 0.7357\n",
      "Hidden Layers: [4, 8], Activation: sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Test Loss: 0.7695\n",
      "Hidden Layers: [4, 8], Activation: sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Test Loss: 0.8959\n",
      "Hidden Layers: [4, 8], Activation: relu, Epochs: 10, LR: 0.01, Batch Size: 16, Test Loss: 0.6630\n",
      "Hidden Layers: [4, 8], Activation: relu, Epochs: 10, LR: 0.01, Batch Size: 32, Test Loss: 0.6669\n",
      "Hidden Layers: [4, 8], Activation: relu, Epochs: 10, LR: 0.01, Batch Size: 64, Test Loss: 0.6583\n",
      "Hidden Layers: [4, 8], Activation: relu, Epochs: 10, LR: 0.001, Batch Size: 16, Test Loss: 0.6727\n",
      "Hidden Layers: [4, 8], Activation: relu, Epochs: 10, LR: 0.001, Batch Size: 32, Test Loss: 0.6954\n",
      "Hidden Layers: [4, 8], Activation: relu, Epochs: 10, LR: 0.001, Batch Size: 64, Test Loss: 0.6860\n",
      "Hidden Layers: [4, 8], Activation: relu, Epochs: 10, LR: 0.0001, Batch Size: 16, Test Loss: 0.7371\n",
      "Hidden Layers: [4, 8], Activation: relu, Epochs: 10, LR: 0.0001, Batch Size: 32, Test Loss: 0.8876\n",
      "Hidden Layers: [4, 8], Activation: relu, Epochs: 10, LR: 0.0001, Batch Size: 64, Test Loss: 0.9118\n",
      "Hidden Layers: [4, 8], Activation: relu, Epochs: 25, LR: 0.01, Batch Size: 16, Test Loss: 0.6669\n",
      "Hidden Layers: [4, 8], Activation: relu, Epochs: 25, LR: 0.01, Batch Size: 32, Test Loss: 0.6527\n",
      "Hidden Layers: [4, 8], Activation: relu, Epochs: 25, LR: 0.01, Batch Size: 64, Test Loss: 0.6655\n",
      "Hidden Layers: [4, 8], Activation: relu, Epochs: 25, LR: 0.001, Batch Size: 16, Test Loss: 0.6344\n",
      "Hidden Layers: [4, 8], Activation: relu, Epochs: 25, LR: 0.001, Batch Size: 32, Test Loss: 0.6550\n",
      "Hidden Layers: [4, 8], Activation: relu, Epochs: 25, LR: 0.001, Batch Size: 64, Test Loss: 0.6451\n",
      "Hidden Layers: [4, 8], Activation: relu, Epochs: 25, LR: 0.0001, Batch Size: 16, Test Loss: 0.6910\n",
      "Hidden Layers: [4, 8], Activation: relu, Epochs: 25, LR: 0.0001, Batch Size: 32, Test Loss: 0.7170\n",
      "Hidden Layers: [4, 8], Activation: relu, Epochs: 25, LR: 0.0001, Batch Size: 64, Test Loss: 0.9451\n",
      "Hidden Layers: [4, 8], Activation: relu, Epochs: 50, LR: 0.01, Batch Size: 16, Test Loss: 0.6480\n",
      "Hidden Layers: [4, 8], Activation: relu, Epochs: 50, LR: 0.01, Batch Size: 32, Test Loss: 0.6604\n",
      "Hidden Layers: [4, 8], Activation: relu, Epochs: 50, LR: 0.01, Batch Size: 64, Test Loss: 0.6449\n",
      "Hidden Layers: [4, 8], Activation: relu, Epochs: 50, LR: 0.001, Batch Size: 16, Test Loss: 0.6399\n",
      "Hidden Layers: [4, 8], Activation: relu, Epochs: 50, LR: 0.001, Batch Size: 32, Test Loss: 0.6703\n",
      "Hidden Layers: [4, 8], Activation: relu, Epochs: 50, LR: 0.001, Batch Size: 64, Test Loss: 0.6768\n",
      "Hidden Layers: [4, 8], Activation: relu, Epochs: 50, LR: 0.0001, Batch Size: 16, Test Loss: 0.6617\n",
      "Hidden Layers: [4, 8], Activation: relu, Epochs: 50, LR: 0.0001, Batch Size: 32, Test Loss: 0.6889\n",
      "Hidden Layers: [4, 8], Activation: relu, Epochs: 50, LR: 0.0001, Batch Size: 64, Test Loss: 0.7569\n",
      "Hidden Layers: [4, 8], Activation: softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Test Loss: 0.6571\n",
      "Hidden Layers: [4, 8], Activation: softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Test Loss: 0.6432\n",
      "Hidden Layers: [4, 8], Activation: softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Test Loss: 0.6479\n",
      "Hidden Layers: [4, 8], Activation: softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Test Loss: 0.6697\n",
      "Hidden Layers: [4, 8], Activation: softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Test Loss: 0.6768\n",
      "Hidden Layers: [4, 8], Activation: softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Test Loss: 0.7559\n",
      "Hidden Layers: [4, 8], Activation: softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Test Loss: 0.9284\n",
      "Hidden Layers: [4, 8], Activation: softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Test Loss: 0.9479\n",
      "Hidden Layers: [4, 8], Activation: softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Test Loss: 0.9481\n",
      "Hidden Layers: [4, 8], Activation: softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Test Loss: 0.6391\n",
      "Hidden Layers: [4, 8], Activation: softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Test Loss: 0.6334\n",
      "Hidden Layers: [4, 8], Activation: softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Test Loss: 0.6363\n",
      "Hidden Layers: [4, 8], Activation: softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Test Loss: 0.6547\n",
      "Hidden Layers: [4, 8], Activation: softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Test Loss: 0.6565\n",
      "Hidden Layers: [4, 8], Activation: softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Test Loss: 0.6588\n",
      "Hidden Layers: [4, 8], Activation: softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Test Loss: 0.8658\n",
      "Hidden Layers: [4, 8], Activation: softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Test Loss: 0.9342\n",
      "Hidden Layers: [4, 8], Activation: softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Test Loss: 0.9512\n",
      "Hidden Layers: [4, 8], Activation: softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Test Loss: 0.6377\n",
      "Hidden Layers: [4, 8], Activation: softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Test Loss: 0.6356\n",
      "Hidden Layers: [4, 8], Activation: softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Test Loss: 0.6293\n",
      "Hidden Layers: [4, 8], Activation: softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Test Loss: 0.6501\n",
      "Hidden Layers: [4, 8], Activation: softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Test Loss: 0.6407\n",
      "Hidden Layers: [4, 8], Activation: softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Test Loss: 0.6632\n",
      "Hidden Layers: [4, 8], Activation: softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Test Loss: 0.7485\n",
      "Hidden Layers: [4, 8], Activation: softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Test Loss: 0.8258\n",
      "Hidden Layers: [4, 8], Activation: softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Test Loss: 0.8887\n",
      "Hidden Layers: [4, 8], Activation: tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Test Loss: 0.6493\n",
      "Hidden Layers: [4, 8], Activation: tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Test Loss: 0.6700\n",
      "Hidden Layers: [4, 8], Activation: tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Test Loss: 0.6661\n",
      "Hidden Layers: [4, 8], Activation: tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Test Loss: 0.6803\n",
      "Hidden Layers: [4, 8], Activation: tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Test Loss: 0.6835\n",
      "Hidden Layers: [4, 8], Activation: tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Test Loss: 0.6888\n",
      "Hidden Layers: [4, 8], Activation: tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Test Loss: 0.7075\n",
      "Hidden Layers: [4, 8], Activation: tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Test Loss: 0.7697\n",
      "Hidden Layers: [4, 8], Activation: tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Test Loss: 0.8993\n",
      "Hidden Layers: [4, 8], Activation: tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Test Loss: 0.6274\n",
      "Hidden Layers: [4, 8], Activation: tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Test Loss: 0.6345\n",
      "Hidden Layers: [4, 8], Activation: tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Test Loss: 0.6478\n",
      "Hidden Layers: [4, 8], Activation: tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Test Loss: 0.6318\n",
      "Hidden Layers: [4, 8], Activation: tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Test Loss: 0.6604\n",
      "Hidden Layers: [4, 8], Activation: tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Test Loss: 0.6669\n",
      "Hidden Layers: [4, 8], Activation: tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Test Loss: 0.6862\n",
      "Hidden Layers: [4, 8], Activation: tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Test Loss: 0.7061\n",
      "Hidden Layers: [4, 8], Activation: tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Test Loss: 0.7633\n",
      "Hidden Layers: [4, 8], Activation: tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Test Loss: 0.6471\n",
      "Hidden Layers: [4, 8], Activation: tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Test Loss: 0.6279\n",
      "Hidden Layers: [4, 8], Activation: tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Test Loss: 0.6293\n",
      "Hidden Layers: [4, 8], Activation: tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Test Loss: 0.6607\n",
      "Hidden Layers: [4, 8], Activation: tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Test Loss: 0.6459\n",
      "Hidden Layers: [4, 8], Activation: tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Test Loss: 0.6397\n",
      "Hidden Layers: [4, 8], Activation: tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Test Loss: 0.6858\n",
      "Hidden Layers: [4, 8], Activation: tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Test Loss: 0.6961\n",
      "Hidden Layers: [4, 8], Activation: tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Test Loss: 0.7268\n",
      "Hidden Layers: [8, 16], Activation: linear, Epochs: 10, LR: 0.01, Batch Size: 16, Test Loss: 0.6982\n",
      "Hidden Layers: [8, 16], Activation: linear, Epochs: 10, LR: 0.01, Batch Size: 32, Test Loss: 0.7035\n",
      "Hidden Layers: [8, 16], Activation: linear, Epochs: 10, LR: 0.01, Batch Size: 64, Test Loss: 0.7143\n",
      "Hidden Layers: [8, 16], Activation: linear, Epochs: 10, LR: 0.001, Batch Size: 16, Test Loss: 0.6860\n",
      "Hidden Layers: [8, 16], Activation: linear, Epochs: 10, LR: 0.001, Batch Size: 32, Test Loss: 0.6932\n",
      "Hidden Layers: [8, 16], Activation: linear, Epochs: 10, LR: 0.001, Batch Size: 64, Test Loss: 0.6981\n",
      "Hidden Layers: [8, 16], Activation: linear, Epochs: 10, LR: 0.0001, Batch Size: 16, Test Loss: 0.6990\n",
      "Hidden Layers: [8, 16], Activation: linear, Epochs: 10, LR: 0.0001, Batch Size: 32, Test Loss: 0.7619\n",
      "Hidden Layers: [8, 16], Activation: linear, Epochs: 10, LR: 0.0001, Batch Size: 64, Test Loss: 0.8033\n",
      "Hidden Layers: [8, 16], Activation: linear, Epochs: 25, LR: 0.01, Batch Size: 16, Test Loss: 0.6942\n",
      "Hidden Layers: [8, 16], Activation: linear, Epochs: 25, LR: 0.01, Batch Size: 32, Test Loss: 0.6964\n",
      "Hidden Layers: [8, 16], Activation: linear, Epochs: 25, LR: 0.01, Batch Size: 64, Test Loss: 0.7048\n",
      "Hidden Layers: [8, 16], Activation: linear, Epochs: 25, LR: 0.001, Batch Size: 16, Test Loss: 0.6959\n",
      "Hidden Layers: [8, 16], Activation: linear, Epochs: 25, LR: 0.001, Batch Size: 32, Test Loss: 0.6943\n",
      "Hidden Layers: [8, 16], Activation: linear, Epochs: 25, LR: 0.001, Batch Size: 64, Test Loss: 0.6968\n",
      "Hidden Layers: [8, 16], Activation: linear, Epochs: 25, LR: 0.0001, Batch Size: 16, Test Loss: 0.6897\n",
      "Hidden Layers: [8, 16], Activation: linear, Epochs: 25, LR: 0.0001, Batch Size: 32, Test Loss: 0.6974\n",
      "Hidden Layers: [8, 16], Activation: linear, Epochs: 25, LR: 0.0001, Batch Size: 64, Test Loss: 0.7103\n",
      "Hidden Layers: [8, 16], Activation: linear, Epochs: 50, LR: 0.01, Batch Size: 16, Test Loss: 0.7091\n",
      "Hidden Layers: [8, 16], Activation: linear, Epochs: 50, LR: 0.01, Batch Size: 32, Test Loss: 0.7055\n",
      "Hidden Layers: [8, 16], Activation: linear, Epochs: 50, LR: 0.01, Batch Size: 64, Test Loss: 0.7049\n",
      "Hidden Layers: [8, 16], Activation: linear, Epochs: 50, LR: 0.001, Batch Size: 16, Test Loss: 0.7007\n",
      "Hidden Layers: [8, 16], Activation: linear, Epochs: 50, LR: 0.001, Batch Size: 32, Test Loss: 0.6939\n",
      "Hidden Layers: [8, 16], Activation: linear, Epochs: 50, LR: 0.001, Batch Size: 64, Test Loss: 0.7010\n",
      "Hidden Layers: [8, 16], Activation: linear, Epochs: 50, LR: 0.0001, Batch Size: 16, Test Loss: 0.6921\n",
      "Hidden Layers: [8, 16], Activation: linear, Epochs: 50, LR: 0.0001, Batch Size: 32, Test Loss: 0.6939\n",
      "Hidden Layers: [8, 16], Activation: linear, Epochs: 50, LR: 0.0001, Batch Size: 64, Test Loss: 0.7007\n",
      "Hidden Layers: [8, 16], Activation: sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Test Loss: 0.6522\n",
      "Hidden Layers: [8, 16], Activation: sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Test Loss: 0.6448\n",
      "Hidden Layers: [8, 16], Activation: sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Test Loss: 0.6573\n",
      "Hidden Layers: [8, 16], Activation: sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Test Loss: 0.6891\n",
      "Hidden Layers: [8, 16], Activation: sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Test Loss: 0.6964\n",
      "Hidden Layers: [8, 16], Activation: sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Test Loss: 0.7215\n",
      "Hidden Layers: [8, 16], Activation: sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Test Loss: 0.9033\n",
      "Hidden Layers: [8, 16], Activation: sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Test Loss: 0.9269\n",
      "Hidden Layers: [8, 16], Activation: sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Test Loss: 1.0065\n",
      "Hidden Layers: [8, 16], Activation: sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Test Loss: 0.6234\n",
      "Hidden Layers: [8, 16], Activation: sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Test Loss: 0.6291\n",
      "Hidden Layers: [8, 16], Activation: sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Test Loss: 0.6506\n",
      "Hidden Layers: [8, 16], Activation: sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Test Loss: 0.6786\n",
      "Hidden Layers: [8, 16], Activation: sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Test Loss: 0.6882\n",
      "Hidden Layers: [8, 16], Activation: sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Test Loss: 0.6992\n",
      "Hidden Layers: [8, 16], Activation: sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Test Loss: 0.7764\n",
      "Hidden Layers: [8, 16], Activation: sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Test Loss: 0.8205\n",
      "Hidden Layers: [8, 16], Activation: sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Test Loss: 0.9004\n",
      "Hidden Layers: [8, 16], Activation: sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Test Loss: 0.6218\n",
      "Hidden Layers: [8, 16], Activation: sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Test Loss: 0.6096\n",
      "Hidden Layers: [8, 16], Activation: sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Test Loss: 0.6364\n",
      "Hidden Layers: [8, 16], Activation: sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Test Loss: 0.6477\n",
      "Hidden Layers: [8, 16], Activation: sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Test Loss: 0.6760\n",
      "Hidden Layers: [8, 16], Activation: sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Test Loss: 0.6799\n",
      "Hidden Layers: [8, 16], Activation: sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Test Loss: 0.7115\n",
      "Hidden Layers: [8, 16], Activation: sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Test Loss: 0.7527\n",
      "Hidden Layers: [8, 16], Activation: sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Test Loss: 0.8080\n",
      "Hidden Layers: [8, 16], Activation: relu, Epochs: 10, LR: 0.01, Batch Size: 16, Test Loss: 0.6267\n",
      "Hidden Layers: [8, 16], Activation: relu, Epochs: 10, LR: 0.01, Batch Size: 32, Test Loss: 0.6170\n",
      "Hidden Layers: [8, 16], Activation: relu, Epochs: 10, LR: 0.01, Batch Size: 64, Test Loss: 0.6295\n",
      "Hidden Layers: [8, 16], Activation: relu, Epochs: 10, LR: 0.001, Batch Size: 16, Test Loss: 0.6347\n",
      "Hidden Layers: [8, 16], Activation: relu, Epochs: 10, LR: 0.001, Batch Size: 32, Test Loss: 0.6482\n",
      "Hidden Layers: [8, 16], Activation: relu, Epochs: 10, LR: 0.001, Batch Size: 64, Test Loss: 0.6650\n",
      "Hidden Layers: [8, 16], Activation: relu, Epochs: 10, LR: 0.0001, Batch Size: 16, Test Loss: 0.7615\n",
      "Hidden Layers: [8, 16], Activation: relu, Epochs: 10, LR: 0.0001, Batch Size: 32, Test Loss: 0.8269\n",
      "Hidden Layers: [8, 16], Activation: relu, Epochs: 10, LR: 0.0001, Batch Size: 64, Test Loss: 0.8876\n",
      "Hidden Layers: [8, 16], Activation: relu, Epochs: 25, LR: 0.01, Batch Size: 16, Test Loss: 0.6350\n",
      "Hidden Layers: [8, 16], Activation: relu, Epochs: 25, LR: 0.01, Batch Size: 32, Test Loss: 0.6221\n",
      "Hidden Layers: [8, 16], Activation: relu, Epochs: 25, LR: 0.01, Batch Size: 64, Test Loss: 0.6472\n",
      "Hidden Layers: [8, 16], Activation: relu, Epochs: 25, LR: 0.001, Batch Size: 16, Test Loss: 0.6352\n",
      "Hidden Layers: [8, 16], Activation: relu, Epochs: 25, LR: 0.001, Batch Size: 32, Test Loss: 0.6452\n",
      "Hidden Layers: [8, 16], Activation: relu, Epochs: 25, LR: 0.001, Batch Size: 64, Test Loss: 0.6558\n",
      "Hidden Layers: [8, 16], Activation: relu, Epochs: 25, LR: 0.0001, Batch Size: 16, Test Loss: 0.6705\n",
      "Hidden Layers: [8, 16], Activation: relu, Epochs: 25, LR: 0.0001, Batch Size: 32, Test Loss: 0.6810\n",
      "Hidden Layers: [8, 16], Activation: relu, Epochs: 25, LR: 0.0001, Batch Size: 64, Test Loss: 0.7537\n",
      "Hidden Layers: [8, 16], Activation: relu, Epochs: 50, LR: 0.01, Batch Size: 16, Test Loss: 0.6680\n",
      "Hidden Layers: [8, 16], Activation: relu, Epochs: 50, LR: 0.01, Batch Size: 32, Test Loss: 0.6321\n",
      "Hidden Layers: [8, 16], Activation: relu, Epochs: 50, LR: 0.01, Batch Size: 64, Test Loss: 0.6422\n",
      "Hidden Layers: [8, 16], Activation: relu, Epochs: 50, LR: 0.001, Batch Size: 16, Test Loss: 0.6570\n",
      "Hidden Layers: [8, 16], Activation: relu, Epochs: 50, LR: 0.001, Batch Size: 32, Test Loss: 0.6528\n",
      "Hidden Layers: [8, 16], Activation: relu, Epochs: 50, LR: 0.001, Batch Size: 64, Test Loss: 0.6240\n",
      "Hidden Layers: [8, 16], Activation: relu, Epochs: 50, LR: 0.0001, Batch Size: 16, Test Loss: 0.6607\n",
      "Hidden Layers: [8, 16], Activation: relu, Epochs: 50, LR: 0.0001, Batch Size: 32, Test Loss: 0.6727\n",
      "Hidden Layers: [8, 16], Activation: relu, Epochs: 50, LR: 0.0001, Batch Size: 64, Test Loss: 0.6790\n",
      "Hidden Layers: [8, 16], Activation: softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Test Loss: 0.6443\n",
      "Hidden Layers: [8, 16], Activation: softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Test Loss: 0.6291\n",
      "Hidden Layers: [8, 16], Activation: softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Test Loss: 0.6282\n",
      "Hidden Layers: [8, 16], Activation: softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Test Loss: 0.6489\n",
      "Hidden Layers: [8, 16], Activation: softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Test Loss: 0.6668\n",
      "Hidden Layers: [8, 16], Activation: softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Test Loss: 0.7888\n",
      "Hidden Layers: [8, 16], Activation: softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Test Loss: 0.9359\n",
      "Hidden Layers: [8, 16], Activation: softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Test Loss: 0.9450\n",
      "Hidden Layers: [8, 16], Activation: softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Test Loss: 0.9514\n",
      "Hidden Layers: [8, 16], Activation: softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Test Loss: 0.6315\n",
      "Hidden Layers: [8, 16], Activation: softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Test Loss: 0.6116\n",
      "Hidden Layers: [8, 16], Activation: softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Test Loss: 0.6044\n",
      "Hidden Layers: [8, 16], Activation: softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Test Loss: 0.6319\n",
      "Hidden Layers: [8, 16], Activation: softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Test Loss: 0.6440\n",
      "Hidden Layers: [8, 16], Activation: softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Test Loss: 0.6515\n",
      "Hidden Layers: [8, 16], Activation: softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Test Loss: 0.8788\n",
      "Hidden Layers: [8, 16], Activation: softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Test Loss: 0.9258\n",
      "Hidden Layers: [8, 16], Activation: softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Test Loss: 0.9481\n",
      "Hidden Layers: [8, 16], Activation: softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Test Loss: 0.6092\n",
      "Hidden Layers: [8, 16], Activation: softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Test Loss: 0.6127\n",
      "Hidden Layers: [8, 16], Activation: softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Test Loss: 0.6107\n",
      "Hidden Layers: [8, 16], Activation: softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Test Loss: 0.6281\n",
      "Hidden Layers: [8, 16], Activation: softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Test Loss: 0.6295\n",
      "Hidden Layers: [8, 16], Activation: softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Test Loss: 0.6526\n",
      "Hidden Layers: [8, 16], Activation: softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Test Loss: 0.7444\n",
      "Hidden Layers: [8, 16], Activation: softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Test Loss: 0.8289\n",
      "Hidden Layers: [8, 16], Activation: softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Test Loss: 0.9131\n",
      "Hidden Layers: [8, 16], Activation: tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Test Loss: 0.6223\n",
      "Hidden Layers: [8, 16], Activation: tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Test Loss: 0.6711\n",
      "Hidden Layers: [8, 16], Activation: tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Test Loss: 0.6343\n",
      "Hidden Layers: [8, 16], Activation: tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Test Loss: 0.6548\n",
      "Hidden Layers: [8, 16], Activation: tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Test Loss: 0.6646\n",
      "Hidden Layers: [8, 16], Activation: tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Test Loss: 0.6735\n",
      "Hidden Layers: [8, 16], Activation: tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Test Loss: 0.7011\n",
      "Hidden Layers: [8, 16], Activation: tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Test Loss: 0.7285\n",
      "Hidden Layers: [8, 16], Activation: tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Test Loss: 0.8347\n",
      "Hidden Layers: [8, 16], Activation: tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Test Loss: 0.6379\n",
      "Hidden Layers: [8, 16], Activation: tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Test Loss: 0.6208\n",
      "Hidden Layers: [8, 16], Activation: tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Test Loss: 0.6139\n",
      "Hidden Layers: [8, 16], Activation: tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Test Loss: 0.6245\n",
      "Hidden Layers: [8, 16], Activation: tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Test Loss: 0.6472\n",
      "Hidden Layers: [8, 16], Activation: tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Test Loss: 0.6508\n",
      "Hidden Layers: [8, 16], Activation: tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Test Loss: 0.6800\n",
      "Hidden Layers: [8, 16], Activation: tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Test Loss: 0.6878\n",
      "Hidden Layers: [8, 16], Activation: tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Test Loss: 0.7110\n",
      "Hidden Layers: [8, 16], Activation: tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Test Loss: 0.6122\n",
      "Hidden Layers: [8, 16], Activation: tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Test Loss: 0.6176\n",
      "Hidden Layers: [8, 16], Activation: tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Test Loss: 0.6230\n",
      "Hidden Layers: [8, 16], Activation: tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Test Loss: 0.6271\n",
      "Hidden Layers: [8, 16], Activation: tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Test Loss: 0.6273\n",
      "Hidden Layers: [8, 16], Activation: tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Test Loss: 0.6476\n",
      "Hidden Layers: [8, 16], Activation: tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Test Loss: 0.6767\n",
      "Hidden Layers: [8, 16], Activation: tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Test Loss: 0.6818\n",
      "Hidden Layers: [8, 16], Activation: tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Test Loss: 0.6862\n",
      "Hidden Layers: [16, 32], Activation: linear, Epochs: 10, LR: 0.01, Batch Size: 16, Test Loss: 0.7055\n",
      "Hidden Layers: [16, 32], Activation: linear, Epochs: 10, LR: 0.01, Batch Size: 32, Test Loss: 0.7088\n",
      "Hidden Layers: [16, 32], Activation: linear, Epochs: 10, LR: 0.01, Batch Size: 64, Test Loss: 0.7164\n",
      "Hidden Layers: [16, 32], Activation: linear, Epochs: 10, LR: 0.001, Batch Size: 16, Test Loss: 0.6980\n",
      "Hidden Layers: [16, 32], Activation: linear, Epochs: 10, LR: 0.001, Batch Size: 32, Test Loss: 0.6932\n",
      "Hidden Layers: [16, 32], Activation: linear, Epochs: 10, LR: 0.001, Batch Size: 64, Test Loss: 0.6983\n",
      "Hidden Layers: [16, 32], Activation: linear, Epochs: 10, LR: 0.0001, Batch Size: 16, Test Loss: 0.6994\n",
      "Hidden Layers: [16, 32], Activation: linear, Epochs: 10, LR: 0.0001, Batch Size: 32, Test Loss: 0.7035\n",
      "Hidden Layers: [16, 32], Activation: linear, Epochs: 10, LR: 0.0001, Batch Size: 64, Test Loss: 0.7446\n",
      "Hidden Layers: [16, 32], Activation: linear, Epochs: 25, LR: 0.01, Batch Size: 16, Test Loss: 0.7498\n",
      "Hidden Layers: [16, 32], Activation: linear, Epochs: 25, LR: 0.01, Batch Size: 32, Test Loss: 0.7097\n",
      "Hidden Layers: [16, 32], Activation: linear, Epochs: 25, LR: 0.01, Batch Size: 64, Test Loss: 0.7068\n",
      "Hidden Layers: [16, 32], Activation: linear, Epochs: 25, LR: 0.001, Batch Size: 16, Test Loss: 0.6912\n",
      "Hidden Layers: [16, 32], Activation: linear, Epochs: 25, LR: 0.001, Batch Size: 32, Test Loss: 0.7010\n",
      "Hidden Layers: [16, 32], Activation: linear, Epochs: 25, LR: 0.001, Batch Size: 64, Test Loss: 0.6971\n",
      "Hidden Layers: [16, 32], Activation: linear, Epochs: 25, LR: 0.0001, Batch Size: 16, Test Loss: 0.6912\n",
      "Hidden Layers: [16, 32], Activation: linear, Epochs: 25, LR: 0.0001, Batch Size: 32, Test Loss: 0.6948\n",
      "Hidden Layers: [16, 32], Activation: linear, Epochs: 25, LR: 0.0001, Batch Size: 64, Test Loss: 0.7031\n",
      "Hidden Layers: [16, 32], Activation: linear, Epochs: 50, LR: 0.01, Batch Size: 16, Test Loss: 0.7007\n",
      "Hidden Layers: [16, 32], Activation: linear, Epochs: 50, LR: 0.01, Batch Size: 32, Test Loss: 0.7082\n",
      "Hidden Layers: [16, 32], Activation: linear, Epochs: 50, LR: 0.01, Batch Size: 64, Test Loss: 0.7072\n",
      "Hidden Layers: [16, 32], Activation: linear, Epochs: 50, LR: 0.001, Batch Size: 16, Test Loss: 0.7038\n",
      "Hidden Layers: [16, 32], Activation: linear, Epochs: 50, LR: 0.001, Batch Size: 32, Test Loss: 0.7039\n",
      "Hidden Layers: [16, 32], Activation: linear, Epochs: 50, LR: 0.001, Batch Size: 64, Test Loss: 0.7061\n",
      "Hidden Layers: [16, 32], Activation: linear, Epochs: 50, LR: 0.0001, Batch Size: 16, Test Loss: 0.6915\n",
      "Hidden Layers: [16, 32], Activation: linear, Epochs: 50, LR: 0.0001, Batch Size: 32, Test Loss: 0.6922\n",
      "Hidden Layers: [16, 32], Activation: linear, Epochs: 50, LR: 0.0001, Batch Size: 64, Test Loss: 0.6962\n",
      "Hidden Layers: [16, 32], Activation: sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Test Loss: 0.6242\n",
      "Hidden Layers: [16, 32], Activation: sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Test Loss: 0.6286\n",
      "Hidden Layers: [16, 32], Activation: sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Test Loss: 0.6584\n",
      "Hidden Layers: [16, 32], Activation: sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Test Loss: 0.6839\n",
      "Hidden Layers: [16, 32], Activation: sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Test Loss: 0.6870\n",
      "Hidden Layers: [16, 32], Activation: sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Test Loss: 0.7043\n",
      "Hidden Layers: [16, 32], Activation: sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Test Loss: 0.8232\n",
      "Hidden Layers: [16, 32], Activation: sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Test Loss: 0.9146\n",
      "Hidden Layers: [16, 32], Activation: sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Test Loss: 0.9356\n",
      "Hidden Layers: [16, 32], Activation: sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Test Loss: 0.5973\n",
      "Hidden Layers: [16, 32], Activation: sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Test Loss: 0.6154\n",
      "Hidden Layers: [16, 32], Activation: sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Test Loss: 0.6330\n",
      "Hidden Layers: [16, 32], Activation: sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Test Loss: 0.6689\n",
      "Hidden Layers: [16, 32], Activation: sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Test Loss: 0.6787\n",
      "Hidden Layers: [16, 32], Activation: sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Test Loss: 0.6849\n",
      "Hidden Layers: [16, 32], Activation: sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Test Loss: 0.7311\n",
      "Hidden Layers: [16, 32], Activation: sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Test Loss: 0.7601\n",
      "Hidden Layers: [16, 32], Activation: sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Test Loss: 0.8644\n",
      "Hidden Layers: [16, 32], Activation: sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Test Loss: 0.6263\n",
      "Hidden Layers: [16, 32], Activation: sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Test Loss: 0.6022\n",
      "Hidden Layers: [16, 32], Activation: sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Test Loss: 0.6168\n",
      "Hidden Layers: [16, 32], Activation: sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Test Loss: 0.6491\n",
      "Hidden Layers: [16, 32], Activation: sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Test Loss: 0.6520\n",
      "Hidden Layers: [16, 32], Activation: sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Test Loss: 0.6761\n",
      "Hidden Layers: [16, 32], Activation: sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Test Loss: 0.6896\n",
      "Hidden Layers: [16, 32], Activation: sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Test Loss: 0.7076\n",
      "Hidden Layers: [16, 32], Activation: sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Test Loss: 0.7485\n",
      "Hidden Layers: [16, 32], Activation: relu, Epochs: 10, LR: 0.01, Batch Size: 16, Test Loss: 0.6282\n",
      "Hidden Layers: [16, 32], Activation: relu, Epochs: 10, LR: 0.01, Batch Size: 32, Test Loss: 0.6119\n",
      "Hidden Layers: [16, 32], Activation: relu, Epochs: 10, LR: 0.01, Batch Size: 64, Test Loss: 0.6038\n",
      "Hidden Layers: [16, 32], Activation: relu, Epochs: 10, LR: 0.001, Batch Size: 16, Test Loss: 0.6022\n",
      "Hidden Layers: [16, 32], Activation: relu, Epochs: 10, LR: 0.001, Batch Size: 32, Test Loss: 0.6226\n",
      "Hidden Layers: [16, 32], Activation: relu, Epochs: 10, LR: 0.001, Batch Size: 64, Test Loss: 0.6375\n",
      "Hidden Layers: [16, 32], Activation: relu, Epochs: 10, LR: 0.0001, Batch Size: 16, Test Loss: 0.6839\n",
      "Hidden Layers: [16, 32], Activation: relu, Epochs: 10, LR: 0.0001, Batch Size: 32, Test Loss: 0.7102\n",
      "Hidden Layers: [16, 32], Activation: relu, Epochs: 10, LR: 0.0001, Batch Size: 64, Test Loss: 0.8422\n",
      "Hidden Layers: [16, 32], Activation: relu, Epochs: 25, LR: 0.01, Batch Size: 16, Test Loss: 0.6712\n",
      "Hidden Layers: [16, 32], Activation: relu, Epochs: 25, LR: 0.01, Batch Size: 32, Test Loss: 0.6514\n",
      "Hidden Layers: [16, 32], Activation: relu, Epochs: 25, LR: 0.01, Batch Size: 64, Test Loss: 0.5902\n",
      "Hidden Layers: [16, 32], Activation: relu, Epochs: 25, LR: 0.001, Batch Size: 16, Test Loss: 0.5954\n",
      "Hidden Layers: [16, 32], Activation: relu, Epochs: 25, LR: 0.001, Batch Size: 32, Test Loss: 0.6413\n",
      "Hidden Layers: [16, 32], Activation: relu, Epochs: 25, LR: 0.001, Batch Size: 64, Test Loss: 0.6189\n",
      "Hidden Layers: [16, 32], Activation: relu, Epochs: 25, LR: 0.0001, Batch Size: 16, Test Loss: 0.6441\n",
      "Hidden Layers: [16, 32], Activation: relu, Epochs: 25, LR: 0.0001, Batch Size: 32, Test Loss: 0.6481\n",
      "Hidden Layers: [16, 32], Activation: relu, Epochs: 25, LR: 0.0001, Batch Size: 64, Test Loss: 0.6801\n",
      "Hidden Layers: [16, 32], Activation: relu, Epochs: 50, LR: 0.01, Batch Size: 16, Test Loss: 0.6680\n",
      "Hidden Layers: [16, 32], Activation: relu, Epochs: 50, LR: 0.01, Batch Size: 32, Test Loss: 0.5995\n",
      "Hidden Layers: [16, 32], Activation: relu, Epochs: 50, LR: 0.01, Batch Size: 64, Test Loss: 0.6303\n",
      "Hidden Layers: [16, 32], Activation: relu, Epochs: 50, LR: 0.001, Batch Size: 16, Test Loss: 0.6101\n",
      "Hidden Layers: [16, 32], Activation: relu, Epochs: 50, LR: 0.001, Batch Size: 32, Test Loss: 0.5935\n",
      "Hidden Layers: [16, 32], Activation: relu, Epochs: 50, LR: 0.001, Batch Size: 64, Test Loss: 0.5956\n",
      "Hidden Layers: [16, 32], Activation: relu, Epochs: 50, LR: 0.0001, Batch Size: 16, Test Loss: 0.6451\n",
      "Hidden Layers: [16, 32], Activation: relu, Epochs: 50, LR: 0.0001, Batch Size: 32, Test Loss: 0.6264\n",
      "Hidden Layers: [16, 32], Activation: relu, Epochs: 50, LR: 0.0001, Batch Size: 64, Test Loss: 0.6529\n",
      "Hidden Layers: [16, 32], Activation: softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Test Loss: 0.6184\n",
      "Hidden Layers: [16, 32], Activation: softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Test Loss: 0.6049\n",
      "Hidden Layers: [16, 32], Activation: softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Test Loss: 0.6196\n",
      "Hidden Layers: [16, 32], Activation: softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Test Loss: 0.6475\n",
      "Hidden Layers: [16, 32], Activation: softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Test Loss: 0.6627\n",
      "Hidden Layers: [16, 32], Activation: softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Test Loss: 0.7672\n",
      "Hidden Layers: [16, 32], Activation: softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Test Loss: 0.9371\n",
      "Hidden Layers: [16, 32], Activation: softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Test Loss: 0.9463\n",
      "Hidden Layers: [16, 32], Activation: softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Test Loss: 0.9498\n",
      "Hidden Layers: [16, 32], Activation: softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Test Loss: 0.6309\n",
      "Hidden Layers: [16, 32], Activation: softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Test Loss: 0.6094\n",
      "Hidden Layers: [16, 32], Activation: softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Test Loss: 0.6197\n",
      "Hidden Layers: [16, 32], Activation: softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Test Loss: 0.6221\n",
      "Hidden Layers: [16, 32], Activation: softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Test Loss: 0.6304\n",
      "Hidden Layers: [16, 32], Activation: softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Test Loss: 0.6466\n",
      "Hidden Layers: [16, 32], Activation: softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Test Loss: 0.8824\n",
      "Hidden Layers: [16, 32], Activation: softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Test Loss: 0.9285\n",
      "Hidden Layers: [16, 32], Activation: softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Test Loss: 0.9452\n",
      "Hidden Layers: [16, 32], Activation: softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Test Loss: 0.6356\n",
      "Hidden Layers: [16, 32], Activation: softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Test Loss: 0.6233\n",
      "Hidden Layers: [16, 32], Activation: softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Test Loss: 0.6092\n",
      "Hidden Layers: [16, 32], Activation: softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Test Loss: 0.6108\n",
      "Hidden Layers: [16, 32], Activation: softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Test Loss: 0.6135\n",
      "Hidden Layers: [16, 32], Activation: softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Test Loss: 0.6179\n",
      "Hidden Layers: [16, 32], Activation: softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Test Loss: 0.7377\n",
      "Hidden Layers: [16, 32], Activation: softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Test Loss: 0.8412\n",
      "Hidden Layers: [16, 32], Activation: softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Test Loss: 0.9191\n",
      "Hidden Layers: [16, 32], Activation: tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Test Loss: 0.6508\n",
      "Hidden Layers: [16, 32], Activation: tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Test Loss: 0.6549\n",
      "Hidden Layers: [16, 32], Activation: tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Test Loss: 0.6278\n",
      "Hidden Layers: [16, 32], Activation: tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Test Loss: 0.6554\n",
      "Hidden Layers: [16, 32], Activation: tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Test Loss: 0.6515\n",
      "Hidden Layers: [16, 32], Activation: tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Test Loss: 0.6717\n",
      "Hidden Layers: [16, 32], Activation: tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Test Loss: 0.6929\n",
      "Hidden Layers: [16, 32], Activation: tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Test Loss: 0.7011\n",
      "Hidden Layers: [16, 32], Activation: tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Test Loss: 0.7329\n",
      "Hidden Layers: [16, 32], Activation: tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Test Loss: 0.6248\n",
      "Hidden Layers: [16, 32], Activation: tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Test Loss: 0.6166\n",
      "Hidden Layers: [16, 32], Activation: tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Test Loss: 0.6165\n",
      "Hidden Layers: [16, 32], Activation: tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Test Loss: 0.6342\n",
      "Hidden Layers: [16, 32], Activation: tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Test Loss: 0.6427\n",
      "Hidden Layers: [16, 32], Activation: tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Test Loss: 0.6175\n",
      "Hidden Layers: [16, 32], Activation: tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Test Loss: 0.6782\n",
      "Hidden Layers: [16, 32], Activation: tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Test Loss: 0.6873\n",
      "Hidden Layers: [16, 32], Activation: tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Test Loss: 0.7061\n",
      "Hidden Layers: [16, 32], Activation: tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Test Loss: 0.6097\n",
      "Hidden Layers: [16, 32], Activation: tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Test Loss: 0.6011\n",
      "Hidden Layers: [16, 32], Activation: tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Test Loss: 0.6114\n",
      "Hidden Layers: [16, 32], Activation: tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Test Loss: 0.5995\n",
      "Hidden Layers: [16, 32], Activation: tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Test Loss: 0.6254\n",
      "Hidden Layers: [16, 32], Activation: tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Test Loss: 0.6142\n",
      "Hidden Layers: [16, 32], Activation: tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Test Loss: 0.6641\n",
      "Hidden Layers: [16, 32], Activation: tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Test Loss: 0.6607\n",
      "Hidden Layers: [16, 32], Activation: tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Test Loss: 0.6966\n",
      "Hidden Layers: [4, 8, 16], Activation: linear, Epochs: 10, LR: 0.01, Batch Size: 16, Test Loss: 0.6893\n",
      "Hidden Layers: [4, 8, 16], Activation: linear, Epochs: 10, LR: 0.01, Batch Size: 32, Test Loss: 0.7187\n",
      "Hidden Layers: [4, 8, 16], Activation: linear, Epochs: 10, LR: 0.01, Batch Size: 64, Test Loss: 0.7125\n",
      "Hidden Layers: [4, 8, 16], Activation: linear, Epochs: 10, LR: 0.001, Batch Size: 16, Test Loss: 0.6938\n",
      "Hidden Layers: [4, 8, 16], Activation: linear, Epochs: 10, LR: 0.001, Batch Size: 32, Test Loss: 0.6948\n",
      "Hidden Layers: [4, 8, 16], Activation: linear, Epochs: 10, LR: 0.001, Batch Size: 64, Test Loss: 0.7065\n",
      "Hidden Layers: [4, 8, 16], Activation: linear, Epochs: 10, LR: 0.0001, Batch Size: 16, Test Loss: 0.7459\n",
      "Hidden Layers: [4, 8, 16], Activation: linear, Epochs: 10, LR: 0.0001, Batch Size: 32, Test Loss: 0.8171\n",
      "Hidden Layers: [4, 8, 16], Activation: linear, Epochs: 10, LR: 0.0001, Batch Size: 64, Test Loss: 0.8129\n",
      "Hidden Layers: [4, 8, 16], Activation: linear, Epochs: 25, LR: 0.01, Batch Size: 16, Test Loss: 0.7122\n",
      "Hidden Layers: [4, 8, 16], Activation: linear, Epochs: 25, LR: 0.01, Batch Size: 32, Test Loss: 0.7027\n",
      "Hidden Layers: [4, 8, 16], Activation: linear, Epochs: 25, LR: 0.01, Batch Size: 64, Test Loss: 0.7045\n",
      "Hidden Layers: [4, 8, 16], Activation: linear, Epochs: 25, LR: 0.001, Batch Size: 16, Test Loss: 0.6934\n",
      "Hidden Layers: [4, 8, 16], Activation: linear, Epochs: 25, LR: 0.001, Batch Size: 32, Test Loss: 0.7007\n",
      "Hidden Layers: [4, 8, 16], Activation: linear, Epochs: 25, LR: 0.001, Batch Size: 64, Test Loss: 0.6973\n",
      "Hidden Layers: [4, 8, 16], Activation: linear, Epochs: 25, LR: 0.0001, Batch Size: 16, Test Loss: 0.6899\n",
      "Hidden Layers: [4, 8, 16], Activation: linear, Epochs: 25, LR: 0.0001, Batch Size: 32, Test Loss: 0.7060\n",
      "Hidden Layers: [4, 8, 16], Activation: linear, Epochs: 25, LR: 0.0001, Batch Size: 64, Test Loss: 0.7821\n",
      "Hidden Layers: [4, 8, 16], Activation: linear, Epochs: 50, LR: 0.01, Batch Size: 16, Test Loss: 0.6968\n",
      "Hidden Layers: [4, 8, 16], Activation: linear, Epochs: 50, LR: 0.01, Batch Size: 32, Test Loss: 0.7095\n",
      "Hidden Layers: [4, 8, 16], Activation: linear, Epochs: 50, LR: 0.01, Batch Size: 64, Test Loss: 0.7207\n",
      "Hidden Layers: [4, 8, 16], Activation: linear, Epochs: 50, LR: 0.001, Batch Size: 16, Test Loss: 0.7010\n",
      "Hidden Layers: [4, 8, 16], Activation: linear, Epochs: 50, LR: 0.001, Batch Size: 32, Test Loss: 0.7020\n",
      "Hidden Layers: [4, 8, 16], Activation: linear, Epochs: 50, LR: 0.001, Batch Size: 64, Test Loss: 0.7046\n",
      "Hidden Layers: [4, 8, 16], Activation: linear, Epochs: 50, LR: 0.0001, Batch Size: 16, Test Loss: 0.6892\n",
      "Hidden Layers: [4, 8, 16], Activation: linear, Epochs: 50, LR: 0.0001, Batch Size: 32, Test Loss: 0.6938\n",
      "Hidden Layers: [4, 8, 16], Activation: linear, Epochs: 50, LR: 0.0001, Batch Size: 64, Test Loss: 0.6954\n",
      "Hidden Layers: [4, 8, 16], Activation: sigmoid, Epochs: 10, LR: 0.01, Batch Size: 16, Test Loss: 0.6530\n",
      "Hidden Layers: [4, 8, 16], Activation: sigmoid, Epochs: 10, LR: 0.01, Batch Size: 32, Test Loss: 0.6705\n",
      "Hidden Layers: [4, 8, 16], Activation: sigmoid, Epochs: 10, LR: 0.01, Batch Size: 64, Test Loss: 0.6918\n",
      "Hidden Layers: [4, 8, 16], Activation: sigmoid, Epochs: 10, LR: 0.001, Batch Size: 16, Test Loss: 0.7129\n",
      "Hidden Layers: [4, 8, 16], Activation: sigmoid, Epochs: 10, LR: 0.001, Batch Size: 32, Test Loss: 0.7154\n",
      "Hidden Layers: [4, 8, 16], Activation: sigmoid, Epochs: 10, LR: 0.001, Batch Size: 64, Test Loss: 0.7659\n",
      "Hidden Layers: [4, 8, 16], Activation: sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 16, Test Loss: 0.9391\n",
      "Hidden Layers: [4, 8, 16], Activation: sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 32, Test Loss: 0.9449\n",
      "Hidden Layers: [4, 8, 16], Activation: sigmoid, Epochs: 10, LR: 0.0001, Batch Size: 64, Test Loss: 0.9497\n",
      "Hidden Layers: [4, 8, 16], Activation: sigmoid, Epochs: 25, LR: 0.01, Batch Size: 16, Test Loss: 0.6637\n",
      "Hidden Layers: [4, 8, 16], Activation: sigmoid, Epochs: 25, LR: 0.01, Batch Size: 32, Test Loss: 0.6516\n",
      "Hidden Layers: [4, 8, 16], Activation: sigmoid, Epochs: 25, LR: 0.01, Batch Size: 64, Test Loss: 0.6607\n",
      "Hidden Layers: [4, 8, 16], Activation: sigmoid, Epochs: 25, LR: 0.001, Batch Size: 16, Test Loss: 0.6947\n",
      "Hidden Layers: [4, 8, 16], Activation: sigmoid, Epochs: 25, LR: 0.001, Batch Size: 32, Test Loss: 0.7026\n",
      "Hidden Layers: [4, 8, 16], Activation: sigmoid, Epochs: 25, LR: 0.001, Batch Size: 64, Test Loss: 0.7038\n",
      "Hidden Layers: [4, 8, 16], Activation: sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 16, Test Loss: 0.9186\n",
      "Hidden Layers: [4, 8, 16], Activation: sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 32, Test Loss: 0.9384\n",
      "Hidden Layers: [4, 8, 16], Activation: sigmoid, Epochs: 25, LR: 0.0001, Batch Size: 64, Test Loss: 0.9483\n",
      "Hidden Layers: [4, 8, 16], Activation: sigmoid, Epochs: 50, LR: 0.01, Batch Size: 16, Test Loss: 0.6367\n",
      "Hidden Layers: [4, 8, 16], Activation: sigmoid, Epochs: 50, LR: 0.01, Batch Size: 32, Test Loss: 0.6550\n",
      "Hidden Layers: [4, 8, 16], Activation: sigmoid, Epochs: 50, LR: 0.01, Batch Size: 64, Test Loss: 0.6757\n",
      "Hidden Layers: [4, 8, 16], Activation: sigmoid, Epochs: 50, LR: 0.001, Batch Size: 16, Test Loss: 0.6836\n",
      "Hidden Layers: [4, 8, 16], Activation: sigmoid, Epochs: 50, LR: 0.001, Batch Size: 32, Test Loss: 0.6836\n",
      "Hidden Layers: [4, 8, 16], Activation: sigmoid, Epochs: 50, LR: 0.001, Batch Size: 64, Test Loss: 0.6887\n",
      "Hidden Layers: [4, 8, 16], Activation: sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 16, Test Loss: 0.7410\n",
      "Hidden Layers: [4, 8, 16], Activation: sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 32, Test Loss: 0.8443\n",
      "Hidden Layers: [4, 8, 16], Activation: sigmoid, Epochs: 50, LR: 0.0001, Batch Size: 64, Test Loss: 0.9252\n",
      "Hidden Layers: [4, 8, 16], Activation: relu, Epochs: 10, LR: 0.01, Batch Size: 16, Test Loss: 0.6988\n",
      "Hidden Layers: [4, 8, 16], Activation: relu, Epochs: 10, LR: 0.01, Batch Size: 32, Test Loss: 0.6513\n",
      "Hidden Layers: [4, 8, 16], Activation: relu, Epochs: 10, LR: 0.01, Batch Size: 64, Test Loss: 0.6677\n",
      "Hidden Layers: [4, 8, 16], Activation: relu, Epochs: 10, LR: 0.001, Batch Size: 16, Test Loss: 0.6512\n",
      "Hidden Layers: [4, 8, 16], Activation: relu, Epochs: 10, LR: 0.001, Batch Size: 32, Test Loss: 0.6550\n",
      "Hidden Layers: [4, 8, 16], Activation: relu, Epochs: 10, LR: 0.001, Batch Size: 64, Test Loss: 0.6553\n",
      "Hidden Layers: [4, 8, 16], Activation: relu, Epochs: 10, LR: 0.0001, Batch Size: 16, Test Loss: 0.8595\n",
      "Hidden Layers: [4, 8, 16], Activation: relu, Epochs: 10, LR: 0.0001, Batch Size: 32, Test Loss: 0.8828\n",
      "Hidden Layers: [4, 8, 16], Activation: relu, Epochs: 10, LR: 0.0001, Batch Size: 64, Test Loss: 0.9291\n",
      "Hidden Layers: [4, 8, 16], Activation: relu, Epochs: 25, LR: 0.01, Batch Size: 16, Test Loss: 0.6563\n",
      "Hidden Layers: [4, 8, 16], Activation: relu, Epochs: 25, LR: 0.01, Batch Size: 32, Test Loss: 0.6577\n",
      "Hidden Layers: [4, 8, 16], Activation: relu, Epochs: 25, LR: 0.01, Batch Size: 64, Test Loss: 0.6418\n",
      "Hidden Layers: [4, 8, 16], Activation: relu, Epochs: 25, LR: 0.001, Batch Size: 16, Test Loss: 0.6516\n",
      "Hidden Layers: [4, 8, 16], Activation: relu, Epochs: 25, LR: 0.001, Batch Size: 32, Test Loss: 0.6700\n",
      "Hidden Layers: [4, 8, 16], Activation: relu, Epochs: 25, LR: 0.001, Batch Size: 64, Test Loss: 0.6581\n",
      "Hidden Layers: [4, 8, 16], Activation: relu, Epochs: 25, LR: 0.0001, Batch Size: 16, Test Loss: 0.6850\n",
      "Hidden Layers: [4, 8, 16], Activation: relu, Epochs: 25, LR: 0.0001, Batch Size: 32, Test Loss: 0.6968\n",
      "Hidden Layers: [4, 8, 16], Activation: relu, Epochs: 25, LR: 0.0001, Batch Size: 64, Test Loss: 0.8112\n",
      "Hidden Layers: [4, 8, 16], Activation: relu, Epochs: 50, LR: 0.01, Batch Size: 16, Test Loss: 0.6776\n",
      "Hidden Layers: [4, 8, 16], Activation: relu, Epochs: 50, LR: 0.01, Batch Size: 32, Test Loss: 0.6771\n",
      "Hidden Layers: [4, 8, 16], Activation: relu, Epochs: 50, LR: 0.01, Batch Size: 64, Test Loss: 0.6815\n",
      "Hidden Layers: [4, 8, 16], Activation: relu, Epochs: 50, LR: 0.001, Batch Size: 16, Test Loss: 0.6321\n",
      "Hidden Layers: [4, 8, 16], Activation: relu, Epochs: 50, LR: 0.001, Batch Size: 32, Test Loss: 0.6412\n",
      "Hidden Layers: [4, 8, 16], Activation: relu, Epochs: 50, LR: 0.001, Batch Size: 64, Test Loss: 0.6584\n",
      "Hidden Layers: [4, 8, 16], Activation: relu, Epochs: 50, LR: 0.0001, Batch Size: 16, Test Loss: 0.6766\n",
      "Hidden Layers: [4, 8, 16], Activation: relu, Epochs: 50, LR: 0.0001, Batch Size: 32, Test Loss: 0.6739\n",
      "Hidden Layers: [4, 8, 16], Activation: relu, Epochs: 50, LR: 0.0001, Batch Size: 64, Test Loss: 0.6918\n",
      "Hidden Layers: [4, 8, 16], Activation: softmax, Epochs: 10, LR: 0.01, Batch Size: 16, Test Loss: 0.6517\n",
      "Hidden Layers: [4, 8, 16], Activation: softmax, Epochs: 10, LR: 0.01, Batch Size: 32, Test Loss: 0.6596\n",
      "Hidden Layers: [4, 8, 16], Activation: softmax, Epochs: 10, LR: 0.01, Batch Size: 64, Test Loss: 0.6608\n",
      "Hidden Layers: [4, 8, 16], Activation: softmax, Epochs: 10, LR: 0.001, Batch Size: 16, Test Loss: 0.6743\n",
      "Hidden Layers: [4, 8, 16], Activation: softmax, Epochs: 10, LR: 0.001, Batch Size: 32, Test Loss: 0.7017\n",
      "Hidden Layers: [4, 8, 16], Activation: softmax, Epochs: 10, LR: 0.001, Batch Size: 64, Test Loss: 0.8325\n",
      "Hidden Layers: [4, 8, 16], Activation: softmax, Epochs: 10, LR: 0.0001, Batch Size: 16, Test Loss: 0.9437\n",
      "Hidden Layers: [4, 8, 16], Activation: softmax, Epochs: 10, LR: 0.0001, Batch Size: 32, Test Loss: 0.9514\n",
      "Hidden Layers: [4, 8, 16], Activation: softmax, Epochs: 10, LR: 0.0001, Batch Size: 64, Test Loss: 0.9518\n",
      "Hidden Layers: [4, 8, 16], Activation: softmax, Epochs: 25, LR: 0.01, Batch Size: 16, Test Loss: 0.6283\n",
      "Hidden Layers: [4, 8, 16], Activation: softmax, Epochs: 25, LR: 0.01, Batch Size: 32, Test Loss: 0.6383\n",
      "Hidden Layers: [4, 8, 16], Activation: softmax, Epochs: 25, LR: 0.01, Batch Size: 64, Test Loss: 0.6294\n",
      "Hidden Layers: [4, 8, 16], Activation: softmax, Epochs: 25, LR: 0.001, Batch Size: 16, Test Loss: 0.6602\n",
      "Hidden Layers: [4, 8, 16], Activation: softmax, Epochs: 25, LR: 0.001, Batch Size: 32, Test Loss: 0.6623\n",
      "Hidden Layers: [4, 8, 16], Activation: softmax, Epochs: 25, LR: 0.001, Batch Size: 64, Test Loss: 0.6671\n",
      "Hidden Layers: [4, 8, 16], Activation: softmax, Epochs: 25, LR: 0.0001, Batch Size: 16, Test Loss: 0.9356\n",
      "Hidden Layers: [4, 8, 16], Activation: softmax, Epochs: 25, LR: 0.0001, Batch Size: 32, Test Loss: 0.9467\n",
      "Hidden Layers: [4, 8, 16], Activation: softmax, Epochs: 25, LR: 0.0001, Batch Size: 64, Test Loss: 0.9514\n",
      "Hidden Layers: [4, 8, 16], Activation: softmax, Epochs: 50, LR: 0.01, Batch Size: 16, Test Loss: 0.6259\n",
      "Hidden Layers: [4, 8, 16], Activation: softmax, Epochs: 50, LR: 0.01, Batch Size: 32, Test Loss: 0.6403\n",
      "Hidden Layers: [4, 8, 16], Activation: softmax, Epochs: 50, LR: 0.01, Batch Size: 64, Test Loss: 0.6292\n",
      "Hidden Layers: [4, 8, 16], Activation: softmax, Epochs: 50, LR: 0.001, Batch Size: 16, Test Loss: 0.6403\n",
      "Hidden Layers: [4, 8, 16], Activation: softmax, Epochs: 50, LR: 0.001, Batch Size: 32, Test Loss: 0.6505\n",
      "Hidden Layers: [4, 8, 16], Activation: softmax, Epochs: 50, LR: 0.001, Batch Size: 64, Test Loss: 0.6504\n",
      "Hidden Layers: [4, 8, 16], Activation: softmax, Epochs: 50, LR: 0.0001, Batch Size: 16, Test Loss: 0.8161\n",
      "Hidden Layers: [4, 8, 16], Activation: softmax, Epochs: 50, LR: 0.0001, Batch Size: 32, Test Loss: 0.9064\n",
      "Hidden Layers: [4, 8, 16], Activation: softmax, Epochs: 50, LR: 0.0001, Batch Size: 64, Test Loss: 0.9449\n",
      "Hidden Layers: [4, 8, 16], Activation: tanh, Epochs: 10, LR: 0.01, Batch Size: 16, Test Loss: 0.6376\n",
      "Hidden Layers: [4, 8, 16], Activation: tanh, Epochs: 10, LR: 0.01, Batch Size: 32, Test Loss: 0.6413\n",
      "Hidden Layers: [4, 8, 16], Activation: tanh, Epochs: 10, LR: 0.01, Batch Size: 64, Test Loss: 0.6753\n",
      "Hidden Layers: [4, 8, 16], Activation: tanh, Epochs: 10, LR: 0.001, Batch Size: 16, Test Loss: 0.6657\n",
      "Hidden Layers: [4, 8, 16], Activation: tanh, Epochs: 10, LR: 0.001, Batch Size: 32, Test Loss: 0.6830\n",
      "Hidden Layers: [4, 8, 16], Activation: tanh, Epochs: 10, LR: 0.001, Batch Size: 64, Test Loss: 0.6826\n",
      "Hidden Layers: [4, 8, 16], Activation: tanh, Epochs: 10, LR: 0.0001, Batch Size: 16, Test Loss: 0.7013\n",
      "Hidden Layers: [4, 8, 16], Activation: tanh, Epochs: 10, LR: 0.0001, Batch Size: 32, Test Loss: 0.7590\n",
      "Hidden Layers: [4, 8, 16], Activation: tanh, Epochs: 10, LR: 0.0001, Batch Size: 64, Test Loss: 0.8031\n",
      "Hidden Layers: [4, 8, 16], Activation: tanh, Epochs: 25, LR: 0.01, Batch Size: 16, Test Loss: 0.6328\n",
      "Hidden Layers: [4, 8, 16], Activation: tanh, Epochs: 25, LR: 0.01, Batch Size: 32, Test Loss: 0.6362\n",
      "Hidden Layers: [4, 8, 16], Activation: tanh, Epochs: 25, LR: 0.01, Batch Size: 64, Test Loss: 0.6385\n",
      "Hidden Layers: [4, 8, 16], Activation: tanh, Epochs: 25, LR: 0.001, Batch Size: 16, Test Loss: 0.6502\n",
      "Hidden Layers: [4, 8, 16], Activation: tanh, Epochs: 25, LR: 0.001, Batch Size: 32, Test Loss: 0.6591\n",
      "Hidden Layers: [4, 8, 16], Activation: tanh, Epochs: 25, LR: 0.001, Batch Size: 64, Test Loss: 0.6716\n",
      "Hidden Layers: [4, 8, 16], Activation: tanh, Epochs: 25, LR: 0.0001, Batch Size: 16, Test Loss: 0.6924\n",
      "Hidden Layers: [4, 8, 16], Activation: tanh, Epochs: 25, LR: 0.0001, Batch Size: 32, Test Loss: 0.6936\n",
      "Hidden Layers: [4, 8, 16], Activation: tanh, Epochs: 25, LR: 0.0001, Batch Size: 64, Test Loss: 0.7525\n",
      "Hidden Layers: [4, 8, 16], Activation: tanh, Epochs: 50, LR: 0.01, Batch Size: 16, Test Loss: 0.6334\n",
      "Hidden Layers: [4, 8, 16], Activation: tanh, Epochs: 50, LR: 0.01, Batch Size: 32, Test Loss: 0.6311\n",
      "Hidden Layers: [4, 8, 16], Activation: tanh, Epochs: 50, LR: 0.01, Batch Size: 64, Test Loss: 0.6165\n",
      "Hidden Layers: [4, 8, 16], Activation: tanh, Epochs: 50, LR: 0.001, Batch Size: 16, Test Loss: 0.6364\n",
      "Hidden Layers: [4, 8, 16], Activation: tanh, Epochs: 50, LR: 0.001, Batch Size: 32, Test Loss: 0.6447\n",
      "Hidden Layers: [4, 8, 16], Activation: tanh, Epochs: 50, LR: 0.001, Batch Size: 64, Test Loss: 0.6674\n",
      "Hidden Layers: [4, 8, 16], Activation: tanh, Epochs: 50, LR: 0.0001, Batch Size: 16, Test Loss: 0.6907\n",
      "Hidden Layers: [4, 8, 16], Activation: tanh, Epochs: 50, LR: 0.0001, Batch Size: 32, Test Loss: 0.6925\n",
      "Hidden Layers: [4, 8, 16], Activation: tanh, Epochs: 50, LR: 0.0001, Batch Size: 64, Test Loss: 0.6997\n"
     ]
    }
   ],
   "source": [
    "# Loop untuk menguji semua kombinasi parameter\n",
    "for hidden_layers in hidden_layer_configs:\n",
    "    for act_name, activation_fn in activation_functions.items():\n",
    "        for epochs in epochs_list:\n",
    "            for lr in learning_rates:\n",
    "                for batch_size in batch_sizes:\n",
    "                    # Buat DataLoader untuk batching data\n",
    "                    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "                    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "                    # Buat model, loss function, dan optimizer\n",
    "                    model = MLPRegressor(X.shape[1], hidden_layers, activation_fn).to(device)  # Model MLP\n",
    "                    criterion = nn.MSELoss()  # Mean Squared Error untuk regresi\n",
    "                    optimizer = optim.Adam(model.parameters(), lr=lr)  # Optimizer Adam\n",
    "\n",
    "                    # Training loop\n",
    "                    model.train()\n",
    "                    for epoch in range(epochs):\n",
    "                        for inputs, targets in train_loader:\n",
    "                            inputs, targets = inputs.to(device), targets.to(device)  # Pindahkan data ke GPU/CPU\n",
    "                            optimizer.zero_grad()  # Reset gradien\n",
    "                            outputs = model(inputs).squeeze()  # Forward pass\n",
    "                            loss = criterion(outputs, targets)  # Hitung loss\n",
    "                            loss.backward()  # Backpropagation\n",
    "                            optimizer.step()  # Update bobot model\n",
    "\n",
    "                    # Evaluation (uji model)\n",
    "                    model.eval()\n",
    "                    test_loss = 0\n",
    "                    with torch.no_grad():  # Nonaktifkan gradien selama evaluasi\n",
    "                        for inputs, targets in test_loader:\n",
    "                            inputs, targets = inputs.to(device), targets.to(device)\n",
    "                            outputs = model(inputs).squeeze()\n",
    "                            test_loss += criterion(outputs, targets).item()  # Hitung loss untuk data uji\n",
    "\n",
    "                    test_loss /= len(test_loader)  # Rata-rata loss\n",
    "                    # Simpan hasil\n",
    "                    results.append((hidden_layers, act_name, epochs, lr, batch_size, test_loss))\n",
    "                    print(f\"Hidden Layers: {hidden_layers}, Activation: {act_name}, Epochs: {epochs}, LR: {lr}, Batch Size: {batch_size}, Test Loss: {test_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
