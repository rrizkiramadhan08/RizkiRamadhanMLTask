{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split  # Untuk membagi data menjadi latih dan uji\n",
    "from sklearn.preprocessing import StandardScaler  # Untuk normalisasi data\n",
    "from sklearn.metrics import accuracy_score  # Untuk menghitung akurasi\n",
    "import matplotlib.pyplot as plt  # Untuk visualisasi hasil\n",
    "from torch.utils.data import DataLoader, TensorDataset  # Untuk membuat DataLoader\n",
    "from fpdf import FPDF  # Untuk membuat laporan PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Data Preprocessing\n",
    "df = pd.read_csv('winequality-white.csv', delimiter=';')\n",
    "\n",
    "# Pisahkan fitur (X) dan target (y)\n",
    "X = df.drop('quality', axis=1).values  # Semua kolom selain 'quality' sebagai fitur\n",
    "y = df['quality'].values  # Kolom 'quality' sebagai target\n",
    "\n",
    "# Normalisasi data fitur agar nilai berada dalam rentang yang sama\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)  # Fit dan transform data fitur\n",
    "\n",
    "# Membagi data menjadi set latih (80%) dan uji (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Mengubah data menjadi tensor PyTorch agar bisa digunakan dalam pelatihan\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Membuat dataset Tensor untuk DataLoader\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_data = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Membuat DataLoader untuk batch training dan testing\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Model Definition: Vanilla MLP\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_layers, hidden_neurons, activation_fn):\n",
    "        super(MLP, self).__init__()\n",
    "        layers = []  # List untuk menyimpan layer-layer\n",
    "\n",
    "        prev_layer = input_dim  # Dimensi input adalah jumlah fitur\n",
    "\n",
    "        # Menambahkan hidden layers sesuai jumlah yang ditentukan\n",
    "        for _ in range(hidden_layers):\n",
    "            layers.append(nn.Linear(prev_layer, hidden_neurons))  # Menambahkan layer Linear\n",
    "            if activation_fn == 'relu':  # Jika fungsi aktivasi ReLU\n",
    "                layers.append(nn.ReLU())  # Menambahkan ReLU\n",
    "            elif activation_fn == 'sigmoid':  # Jika fungsi aktivasi Sigmoid\n",
    "                layers.append(nn.Sigmoid())  # Menambahkan Sigmoid\n",
    "            elif activation_fn == 'tanh':  # Jika fungsi aktivasi Tanh\n",
    "                layers.append(nn.Tanh())  # Menambahkan Tanh\n",
    "            elif activation_fn == 'softmax':  # Jika fungsi aktivasi Softmax\n",
    "                layers.append(nn.Softmax(dim=1))  # Menambahkan Softmax di layer akhir\n",
    "            prev_layer = hidden_neurons  # Setel prev_layer ke jumlah neuron di layer sebelumnya\n",
    "        \n",
    "        # Menambahkan layer output, di sini outputnya adalah 10 kelas\n",
    "        layers.append(nn.Linear(prev_layer, 10))  # 10 kelas (quality wine)\n",
    "\n",
    "        # Menyusun layer-layer ke dalam model\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    # Mendefinisikan fungsi forward untuk propagasi data lewat jaringan\n",
    "    def forward(self, x):\n",
    "        return self.model(x)  # Mengembalikan hasil dari model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Training & Evaluation Function (Perubahan di sini)\n",
    "def train_model(model, criterion, optimizer, epochs, train_loader, test_loader):\n",
    "    train_losses = []  # Menyimpan loss selama pelatihan\n",
    "    test_accuracies = []  # Menyimpan akurasi setiap epoch\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()  # Menyiapkan model untuk pelatihan\n",
    "        running_loss = 0.0  # Variabel untuk menghitung loss selama satu epoch\n",
    "\n",
    "        # Loop untuk setiap batch di train_loader\n",
    "        for inputs, labels in train_loader:\n",
    "            # Forward pass: menghitung output dari model\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)  # Menghitung loss\n",
    "\n",
    "            # Backward pass dan optimasi: memperbarui parameter model\n",
    "            optimizer.zero_grad()  # Mengatur gradient ke 0 sebelum backward pass\n",
    "            loss.backward()  # Menghitung gradien\n",
    "            optimizer.step()  # Mengupdate parameter model\n",
    "\n",
    "            running_loss += loss.item()  # Menambah loss per batch ke total loss\n",
    "        \n",
    "        # Menyimpan rata-rata loss untuk epoch ini\n",
    "        train_losses.append(running_loss / len(train_loader))\n",
    "\n",
    "        # Evaluasi model pada data uji setelah tiap epoch\n",
    "        model.eval()  # Menyiapkan model untuk evaluasi\n",
    "        correct = 0  # Variabel untuk menghitung jumlah prediksi yang benar\n",
    "        total = 0  # Variabel untuk menghitung total data\n",
    "\n",
    "        with torch.no_grad():  # Menonaktifkan gradient calculation\n",
    "            for inputs, labels in test_loader:\n",
    "                outputs = model(inputs)  # Menghitung output model\n",
    "                _, predicted = torch.max(outputs, 1)  # Mengambil kelas dengan probabilitas tertinggi\n",
    "                total += labels.size(0)  # Menambahkan jumlah data\n",
    "                correct += (predicted == labels).sum().item()  # Menghitung prediksi yang benar\n",
    "        \n",
    "        accuracy = 100 * correct / total  # Menghitung akurasi\n",
    "        test_accuracies.append(accuracy)  # Menyimpan akurasi per epoch\n",
    "    \n",
    "    # Menampilkan hanya akurasi terbaik akhir epoch\n",
    "    print(f\"Final Accuracy: {test_accuracies[-1]}%\")\n",
    "    \n",
    "    return train_losses, test_accuracies  # Mengembalikan loss dan akurasi untuk analisis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with 1 hidden layers, 4 neurons, relu activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 52.55102040816327%\n",
      "Training with 1 hidden layers, 4 neurons, relu activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 51.53061224489796%\n",
      "Training with 1 hidden layers, 4 neurons, relu activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 52.857142857142854%\n",
      "Training with 1 hidden layers, 4 neurons, relu activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 51.83673469387755%\n",
      "Training with 1 hidden layers, 4 neurons, relu activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 51.326530612244895%\n",
      "Training with 1 hidden layers, 4 neurons, relu activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 52.6530612244898%\n",
      "Training with 1 hidden layers, 4 neurons, relu activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 25.918367346938776%\n",
      "Training with 1 hidden layers, 4 neurons, relu activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 29.285714285714285%\n",
      "Training with 1 hidden layers, 4 neurons, relu activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 32.6530612244898%\n",
      "Training with 1 hidden layers, 4 neurons, relu activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 52.3469387755102%\n",
      "Training with 1 hidden layers, 4 neurons, relu activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 53.16326530612245%\n",
      "Training with 1 hidden layers, 4 neurons, relu activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 52.55102040816327%\n",
      "Training with 1 hidden layers, 4 neurons, relu activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 52.44897959183673%\n",
      "Training with 1 hidden layers, 4 neurons, relu activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 54.795918367346935%\n",
      "Training with 1 hidden layers, 4 neurons, relu activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 53.265306122448976%\n",
      "Training with 1 hidden layers, 4 neurons, relu activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 42.142857142857146%\n",
      "Training with 1 hidden layers, 4 neurons, relu activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.183673469387756%\n",
      "Training with 1 hidden layers, 4 neurons, relu activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 1 hidden layers, 4 neurons, relu activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 53.265306122448976%\n",
      "Training with 1 hidden layers, 4 neurons, relu activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 50.816326530612244%\n",
      "Training with 1 hidden layers, 4 neurons, relu activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 52.95918367346939%\n",
      "Training with 1 hidden layers, 4 neurons, relu activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 51.93877551020408%\n",
      "Training with 1 hidden layers, 4 neurons, relu activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 52.755102040816325%\n",
      "Training with 1 hidden layers, 4 neurons, relu activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 53.57142857142857%\n",
      "Training with 1 hidden layers, 4 neurons, relu activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 49.89795918367347%\n",
      "Training with 1 hidden layers, 4 neurons, relu activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 46.12244897959184%\n",
      "Training with 1 hidden layers, 4 neurons, relu activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 47.04081632653061%\n",
      "Training with 1 hidden layers, 4 neurons, sigmoid activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 52.44897959183673%\n",
      "Training with 1 hidden layers, 4 neurons, sigmoid activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 52.244897959183675%\n",
      "Training with 1 hidden layers, 4 neurons, sigmoid activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 54.285714285714285%\n",
      "Training with 1 hidden layers, 4 neurons, sigmoid activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 51.224489795918366%\n",
      "Training with 1 hidden layers, 4 neurons, sigmoid activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 51.224489795918366%\n",
      "Training with 1 hidden layers, 4 neurons, sigmoid activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 49.285714285714285%\n",
      "Training with 1 hidden layers, 4 neurons, sigmoid activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 1 hidden layers, 4 neurons, sigmoid activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 39.38775510204081%\n",
      "Training with 1 hidden layers, 4 neurons, sigmoid activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 26.836734693877553%\n",
      "Training with 1 hidden layers, 4 neurons, sigmoid activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 54.183673469387756%\n",
      "Training with 1 hidden layers, 4 neurons, sigmoid activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 52.755102040816325%\n",
      "Training with 1 hidden layers, 4 neurons, sigmoid activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 53.57142857142857%\n",
      "Training with 1 hidden layers, 4 neurons, sigmoid activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 52.3469387755102%\n",
      "Training with 1 hidden layers, 4 neurons, sigmoid activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 52.244897959183675%\n",
      "Training with 1 hidden layers, 4 neurons, sigmoid activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 52.44897959183673%\n",
      "Training with 1 hidden layers, 4 neurons, sigmoid activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.183673469387756%\n",
      "Training with 1 hidden layers, 4 neurons, sigmoid activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 30.306122448979593%\n",
      "Training with 1 hidden layers, 4 neurons, sigmoid activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 1 hidden layers, 4 neurons, sigmoid activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 56.224489795918366%\n",
      "Training with 1 hidden layers, 4 neurons, sigmoid activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 53.36734693877551%\n",
      "Training with 1 hidden layers, 4 neurons, sigmoid activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 54.38775510204081%\n",
      "Training with 1 hidden layers, 4 neurons, sigmoid activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 53.46938775510204%\n",
      "Training with 1 hidden layers, 4 neurons, sigmoid activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 53.46938775510204%\n",
      "Training with 1 hidden layers, 4 neurons, sigmoid activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 52.755102040816325%\n",
      "Training with 1 hidden layers, 4 neurons, sigmoid activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 46.53061224489796%\n",
      "Training with 1 hidden layers, 4 neurons, sigmoid activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 46.83673469387755%\n",
      "Training with 1 hidden layers, 4 neurons, sigmoid activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 47.6530612244898%\n",
      "Training with 1 hidden layers, 4 neurons, tanh activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 54.48979591836735%\n",
      "Training with 1 hidden layers, 4 neurons, tanh activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 53.57142857142857%\n",
      "Training with 1 hidden layers, 4 neurons, tanh activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 53.673469387755105%\n",
      "Training with 1 hidden layers, 4 neurons, tanh activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 51.83673469387755%\n",
      "Training with 1 hidden layers, 4 neurons, tanh activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 51.53061224489796%\n",
      "Training with 1 hidden layers, 4 neurons, tanh activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 53.06122448979592%\n",
      "Training with 1 hidden layers, 4 neurons, tanh activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 26.020408163265305%\n",
      "Training with 1 hidden layers, 4 neurons, tanh activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 35.714285714285715%\n",
      "Training with 1 hidden layers, 4 neurons, tanh activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 42.6530612244898%\n",
      "Training with 1 hidden layers, 4 neurons, tanh activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 54.38775510204081%\n",
      "Training with 1 hidden layers, 4 neurons, tanh activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 54.08163265306123%\n",
      "Training with 1 hidden layers, 4 neurons, tanh activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 53.16326530612245%\n",
      "Training with 1 hidden layers, 4 neurons, tanh activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 52.44897959183673%\n",
      "Training with 1 hidden layers, 4 neurons, tanh activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 53.57142857142857%\n",
      "Training with 1 hidden layers, 4 neurons, tanh activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 53.06122448979592%\n",
      "Training with 1 hidden layers, 4 neurons, tanh activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 46.53061224489796%\n",
      "Training with 1 hidden layers, 4 neurons, tanh activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 46.42857142857143%\n",
      "Training with 1 hidden layers, 4 neurons, tanh activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 45.10204081632653%\n",
      "Training with 1 hidden layers, 4 neurons, tanh activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 53.46938775510204%\n",
      "Training with 1 hidden layers, 4 neurons, tanh activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 52.3469387755102%\n",
      "Training with 1 hidden layers, 4 neurons, tanh activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 55.816326530612244%\n",
      "Training with 1 hidden layers, 4 neurons, tanh activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 53.36734693877551%\n",
      "Training with 1 hidden layers, 4 neurons, tanh activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 54.285714285714285%\n",
      "Training with 1 hidden layers, 4 neurons, tanh activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 53.673469387755105%\n",
      "Training with 1 hidden layers, 4 neurons, tanh activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 46.12244897959184%\n",
      "Training with 1 hidden layers, 4 neurons, tanh activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 53.06122448979592%\n",
      "Training with 1 hidden layers, 4 neurons, tanh activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 50.0%\n",
      "Training with 1 hidden layers, 4 neurons, softmax activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 53.36734693877551%\n",
      "Training with 1 hidden layers, 4 neurons, softmax activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 53.87755102040816%\n",
      "Training with 1 hidden layers, 4 neurons, softmax activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 53.87755102040816%\n",
      "Training with 1 hidden layers, 4 neurons, softmax activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 49.795918367346935%\n",
      "Training with 1 hidden layers, 4 neurons, softmax activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 51.63265306122449%\n",
      "Training with 1 hidden layers, 4 neurons, softmax activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 51.12244897959184%\n",
      "Training with 1 hidden layers, 4 neurons, softmax activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 1 hidden layers, 4 neurons, softmax activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 29.693877551020407%\n",
      "Training with 1 hidden layers, 4 neurons, softmax activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 43.775510204081634%\n",
      "Training with 1 hidden layers, 4 neurons, softmax activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 53.97959183673469%\n",
      "Training with 1 hidden layers, 4 neurons, softmax activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 53.775510204081634%\n",
      "Training with 1 hidden layers, 4 neurons, softmax activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 53.673469387755105%\n",
      "Training with 1 hidden layers, 4 neurons, softmax activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 52.6530612244898%\n",
      "Training with 1 hidden layers, 4 neurons, softmax activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 52.244897959183675%\n",
      "Training with 1 hidden layers, 4 neurons, softmax activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 52.3469387755102%\n",
      "Training with 1 hidden layers, 4 neurons, softmax activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 48.97959183673469%\n",
      "Training with 1 hidden layers, 4 neurons, softmax activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 45.51020408163265%\n",
      "Training with 1 hidden layers, 4 neurons, softmax activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.38775510204081%\n",
      "Training with 1 hidden layers, 4 neurons, softmax activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 53.97959183673469%\n",
      "Training with 1 hidden layers, 4 neurons, softmax activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 54.183673469387756%\n",
      "Training with 1 hidden layers, 4 neurons, softmax activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 54.08163265306123%\n",
      "Training with 1 hidden layers, 4 neurons, softmax activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 54.48979591836735%\n",
      "Training with 1 hidden layers, 4 neurons, softmax activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 52.44897959183673%\n",
      "Training with 1 hidden layers, 4 neurons, softmax activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 54.48979591836735%\n",
      "Training with 1 hidden layers, 4 neurons, softmax activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 49.795918367346935%\n",
      "Training with 1 hidden layers, 4 neurons, softmax activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 46.224489795918366%\n",
      "Training with 1 hidden layers, 4 neurons, softmax activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 47.04081632653061%\n",
      "Training with 1 hidden layers, 8 neurons, relu activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 55.204081632653065%\n",
      "Training with 1 hidden layers, 8 neurons, relu activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 53.06122448979592%\n",
      "Training with 1 hidden layers, 8 neurons, relu activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 54.38775510204081%\n",
      "Training with 1 hidden layers, 8 neurons, relu activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 52.6530612244898%\n",
      "Training with 1 hidden layers, 8 neurons, relu activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 52.95918367346939%\n",
      "Training with 1 hidden layers, 8 neurons, relu activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 54.183673469387756%\n",
      "Training with 1 hidden layers, 8 neurons, relu activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 41.93877551020408%\n",
      "Training with 1 hidden layers, 8 neurons, relu activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 45.816326530612244%\n",
      "Training with 1 hidden layers, 8 neurons, relu activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 29.285714285714285%\n",
      "Training with 1 hidden layers, 8 neurons, relu activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 55.10204081632653%\n",
      "Training with 1 hidden layers, 8 neurons, relu activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 53.775510204081634%\n",
      "Training with 1 hidden layers, 8 neurons, relu activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 53.36734693877551%\n",
      "Training with 1 hidden layers, 8 neurons, relu activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 53.06122448979592%\n",
      "Training with 1 hidden layers, 8 neurons, relu activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 53.16326530612245%\n",
      "Training with 1 hidden layers, 8 neurons, relu activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 53.16326530612245%\n",
      "Training with 1 hidden layers, 8 neurons, relu activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 47.857142857142854%\n",
      "Training with 1 hidden layers, 8 neurons, relu activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 48.06122448979592%\n",
      "Training with 1 hidden layers, 8 neurons, relu activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 46.12244897959184%\n",
      "Training with 1 hidden layers, 8 neurons, relu activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 55.10204081632653%\n",
      "Training with 1 hidden layers, 8 neurons, relu activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 53.36734693877551%\n",
      "Training with 1 hidden layers, 8 neurons, relu activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 53.06122448979592%\n",
      "Training with 1 hidden layers, 8 neurons, relu activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 53.775510204081634%\n",
      "Training with 1 hidden layers, 8 neurons, relu activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 53.36734693877551%\n",
      "Training with 1 hidden layers, 8 neurons, relu activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 53.36734693877551%\n",
      "Training with 1 hidden layers, 8 neurons, relu activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 52.04081632653061%\n",
      "Training with 1 hidden layers, 8 neurons, relu activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 52.142857142857146%\n",
      "Training with 1 hidden layers, 8 neurons, relu activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 51.53061224489796%\n",
      "Training with 1 hidden layers, 8 neurons, sigmoid activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 53.87755102040816%\n",
      "Training with 1 hidden layers, 8 neurons, sigmoid activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 54.183673469387756%\n",
      "Training with 1 hidden layers, 8 neurons, sigmoid activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 53.673469387755105%\n",
      "Training with 1 hidden layers, 8 neurons, sigmoid activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 51.83673469387755%\n",
      "Training with 1 hidden layers, 8 neurons, sigmoid activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 51.63265306122449%\n",
      "Training with 1 hidden layers, 8 neurons, sigmoid activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 52.04081632653061%\n",
      "Training with 1 hidden layers, 8 neurons, sigmoid activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 45.204081632653065%\n",
      "Training with 1 hidden layers, 8 neurons, sigmoid activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.183673469387756%\n",
      "Training with 1 hidden layers, 8 neurons, sigmoid activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 38.775510204081634%\n",
      "Training with 1 hidden layers, 8 neurons, sigmoid activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 54.38775510204081%\n",
      "Training with 1 hidden layers, 8 neurons, sigmoid activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 53.16326530612245%\n",
      "Training with 1 hidden layers, 8 neurons, sigmoid activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 54.48979591836735%\n",
      "Training with 1 hidden layers, 8 neurons, sigmoid activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 52.142857142857146%\n",
      "Training with 1 hidden layers, 8 neurons, sigmoid activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 51.93877551020408%\n",
      "Training with 1 hidden layers, 8 neurons, sigmoid activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 52.142857142857146%\n",
      "Training with 1 hidden layers, 8 neurons, sigmoid activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 45.10204081632653%\n",
      "Training with 1 hidden layers, 8 neurons, sigmoid activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 46.83673469387755%\n",
      "Training with 1 hidden layers, 8 neurons, sigmoid activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 47.244897959183675%\n",
      "Training with 1 hidden layers, 8 neurons, sigmoid activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 55.0%\n",
      "Training with 1 hidden layers, 8 neurons, sigmoid activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 53.97959183673469%\n",
      "Training with 1 hidden layers, 8 neurons, sigmoid activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 55.40816326530612%\n",
      "Training with 1 hidden layers, 8 neurons, sigmoid activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 53.36734693877551%\n",
      "Training with 1 hidden layers, 8 neurons, sigmoid activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 53.06122448979592%\n",
      "Training with 1 hidden layers, 8 neurons, sigmoid activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 53.46938775510204%\n",
      "Training with 1 hidden layers, 8 neurons, sigmoid activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 48.97959183673469%\n",
      "Training with 1 hidden layers, 8 neurons, sigmoid activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 48.36734693877551%\n",
      "Training with 1 hidden layers, 8 neurons, sigmoid activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 48.673469387755105%\n",
      "Training with 1 hidden layers, 8 neurons, tanh activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 55.714285714285715%\n",
      "Training with 1 hidden layers, 8 neurons, tanh activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 55.0%\n",
      "Training with 1 hidden layers, 8 neurons, tanh activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 55.0%\n",
      "Training with 1 hidden layers, 8 neurons, tanh activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 53.06122448979592%\n",
      "Training with 1 hidden layers, 8 neurons, tanh activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 52.3469387755102%\n",
      "Training with 1 hidden layers, 8 neurons, tanh activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 51.326530612244895%\n",
      "Training with 1 hidden layers, 8 neurons, tanh activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 39.285714285714285%\n",
      "Training with 1 hidden layers, 8 neurons, tanh activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 46.42857142857143%\n",
      "Training with 1 hidden layers, 8 neurons, tanh activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 39.183673469387756%\n",
      "Training with 1 hidden layers, 8 neurons, tanh activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 53.87755102040816%\n",
      "Training with 1 hidden layers, 8 neurons, tanh activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 54.89795918367347%\n",
      "Training with 1 hidden layers, 8 neurons, tanh activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 55.0%\n",
      "Training with 1 hidden layers, 8 neurons, tanh activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 53.265306122448976%\n",
      "Training with 1 hidden layers, 8 neurons, tanh activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 53.87755102040816%\n",
      "Training with 1 hidden layers, 8 neurons, tanh activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 53.265306122448976%\n",
      "Training with 1 hidden layers, 8 neurons, tanh activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 50.10204081632653%\n",
      "Training with 1 hidden layers, 8 neurons, tanh activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 45.0%\n",
      "Training with 1 hidden layers, 8 neurons, tanh activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 49.59183673469388%\n",
      "Training with 1 hidden layers, 8 neurons, tanh activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 54.89795918367347%\n",
      "Training with 1 hidden layers, 8 neurons, tanh activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 56.224489795918366%\n",
      "Training with 1 hidden layers, 8 neurons, tanh activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 56.12244897959184%\n",
      "Training with 1 hidden layers, 8 neurons, tanh activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 53.97959183673469%\n",
      "Training with 1 hidden layers, 8 neurons, tanh activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 53.36734693877551%\n",
      "Training with 1 hidden layers, 8 neurons, tanh activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 54.285714285714285%\n",
      "Training with 1 hidden layers, 8 neurons, tanh activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 51.224489795918366%\n",
      "Training with 1 hidden layers, 8 neurons, tanh activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 51.63265306122449%\n",
      "Training with 1 hidden layers, 8 neurons, tanh activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 52.3469387755102%\n",
      "Training with 1 hidden layers, 8 neurons, softmax activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 55.10204081632653%\n",
      "Training with 1 hidden layers, 8 neurons, softmax activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 54.183673469387756%\n",
      "Training with 1 hidden layers, 8 neurons, softmax activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 52.755102040816325%\n",
      "Training with 1 hidden layers, 8 neurons, softmax activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 49.795918367346935%\n",
      "Training with 1 hidden layers, 8 neurons, softmax activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 51.02040816326531%\n",
      "Training with 1 hidden layers, 8 neurons, softmax activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 48.775510204081634%\n",
      "Training with 1 hidden layers, 8 neurons, softmax activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 38.46938775510204%\n",
      "Training with 1 hidden layers, 8 neurons, softmax activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 1 hidden layers, 8 neurons, softmax activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 26.836734693877553%\n",
      "Training with 1 hidden layers, 8 neurons, softmax activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 56.02040816326531%\n",
      "Training with 1 hidden layers, 8 neurons, softmax activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 53.265306122448976%\n",
      "Training with 1 hidden layers, 8 neurons, softmax activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 55.30612244897959%\n",
      "Training with 1 hidden layers, 8 neurons, softmax activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 52.04081632653061%\n",
      "Training with 1 hidden layers, 8 neurons, softmax activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 53.97959183673469%\n",
      "Training with 1 hidden layers, 8 neurons, softmax activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 51.326530612244895%\n",
      "Training with 1 hidden layers, 8 neurons, softmax activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 45.51020408163265%\n",
      "Training with 1 hidden layers, 8 neurons, softmax activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 45.204081632653065%\n",
      "Training with 1 hidden layers, 8 neurons, softmax activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 46.12244897959184%\n",
      "Training with 1 hidden layers, 8 neurons, softmax activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 55.10204081632653%\n",
      "Training with 1 hidden layers, 8 neurons, softmax activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 55.91836734693877%\n",
      "Training with 1 hidden layers, 8 neurons, softmax activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 55.30612244897959%\n",
      "Training with 1 hidden layers, 8 neurons, softmax activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 53.673469387755105%\n",
      "Training with 1 hidden layers, 8 neurons, softmax activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 54.59183673469388%\n",
      "Training with 1 hidden layers, 8 neurons, softmax activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 54.59183673469388%\n",
      "Training with 1 hidden layers, 8 neurons, softmax activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 1 hidden layers, 8 neurons, softmax activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 1 hidden layers, 8 neurons, softmax activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 46.326530612244895%\n",
      "Training with 1 hidden layers, 16 neurons, relu activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 55.0%\n",
      "Training with 1 hidden layers, 16 neurons, relu activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 53.06122448979592%\n",
      "Training with 1 hidden layers, 16 neurons, relu activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 52.755102040816325%\n",
      "Training with 1 hidden layers, 16 neurons, relu activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 53.06122448979592%\n",
      "Training with 1 hidden layers, 16 neurons, relu activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 53.06122448979592%\n",
      "Training with 1 hidden layers, 16 neurons, relu activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 54.285714285714285%\n",
      "Training with 1 hidden layers, 16 neurons, relu activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 46.734693877551024%\n",
      "Training with 1 hidden layers, 16 neurons, relu activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 47.3469387755102%\n",
      "Training with 1 hidden layers, 16 neurons, relu activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 45.51020408163265%\n",
      "Training with 1 hidden layers, 16 neurons, relu activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 54.183673469387756%\n",
      "Training with 1 hidden layers, 16 neurons, relu activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 53.87755102040816%\n",
      "Training with 1 hidden layers, 16 neurons, relu activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 53.673469387755105%\n",
      "Training with 1 hidden layers, 16 neurons, relu activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 53.87755102040816%\n",
      "Training with 1 hidden layers, 16 neurons, relu activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 54.795918367346935%\n",
      "Training with 1 hidden layers, 16 neurons, relu activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 54.69387755102041%\n",
      "Training with 1 hidden layers, 16 neurons, relu activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 50.10204081632653%\n",
      "Training with 1 hidden layers, 16 neurons, relu activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 52.44897959183673%\n",
      "Training with 1 hidden layers, 16 neurons, relu activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 49.38775510204081%\n",
      "Training with 1 hidden layers, 16 neurons, relu activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 57.142857142857146%\n",
      "Training with 1 hidden layers, 16 neurons, relu activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 55.61224489795919%\n",
      "Training with 1 hidden layers, 16 neurons, relu activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 54.59183673469388%\n",
      "Training with 1 hidden layers, 16 neurons, relu activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 55.10204081632653%\n",
      "Training with 1 hidden layers, 16 neurons, relu activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 56.83673469387755%\n",
      "Training with 1 hidden layers, 16 neurons, relu activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 54.38775510204081%\n",
      "Training with 1 hidden layers, 16 neurons, relu activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 53.97959183673469%\n",
      "Training with 1 hidden layers, 16 neurons, relu activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 52.857142857142854%\n",
      "Training with 1 hidden layers, 16 neurons, relu activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 53.265306122448976%\n",
      "Training with 1 hidden layers, 16 neurons, sigmoid activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 51.63265306122449%\n",
      "Training with 1 hidden layers, 16 neurons, sigmoid activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 53.46938775510204%\n",
      "Training with 1 hidden layers, 16 neurons, sigmoid activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 54.59183673469388%\n",
      "Training with 1 hidden layers, 16 neurons, sigmoid activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 52.44897959183673%\n",
      "Training with 1 hidden layers, 16 neurons, sigmoid activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 52.244897959183675%\n",
      "Training with 1 hidden layers, 16 neurons, sigmoid activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 52.04081632653061%\n",
      "Training with 1 hidden layers, 16 neurons, sigmoid activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 45.714285714285715%\n",
      "Training with 1 hidden layers, 16 neurons, sigmoid activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.89795918367347%\n",
      "Training with 1 hidden layers, 16 neurons, sigmoid activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 45.0%\n",
      "Training with 1 hidden layers, 16 neurons, sigmoid activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 53.97959183673469%\n",
      "Training with 1 hidden layers, 16 neurons, sigmoid activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 52.55102040816327%\n",
      "Training with 1 hidden layers, 16 neurons, sigmoid activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 54.285714285714285%\n",
      "Training with 1 hidden layers, 16 neurons, sigmoid activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 52.55102040816327%\n",
      "Training with 1 hidden layers, 16 neurons, sigmoid activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 52.44897959183673%\n",
      "Training with 1 hidden layers, 16 neurons, sigmoid activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 52.6530612244898%\n",
      "Training with 1 hidden layers, 16 neurons, sigmoid activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 45.30612244897959%\n",
      "Training with 1 hidden layers, 16 neurons, sigmoid activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 47.95918367346939%\n",
      "Training with 1 hidden layers, 16 neurons, sigmoid activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 47.755102040816325%\n",
      "Training with 1 hidden layers, 16 neurons, sigmoid activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 55.61224489795919%\n",
      "Training with 1 hidden layers, 16 neurons, sigmoid activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 55.61224489795919%\n",
      "Training with 1 hidden layers, 16 neurons, sigmoid activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 54.69387755102041%\n",
      "Training with 1 hidden layers, 16 neurons, sigmoid activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 54.183673469387756%\n",
      "Training with 1 hidden layers, 16 neurons, sigmoid activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 52.6530612244898%\n",
      "Training with 1 hidden layers, 16 neurons, sigmoid activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 53.775510204081634%\n",
      "Training with 1 hidden layers, 16 neurons, sigmoid activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 49.69387755102041%\n",
      "Training with 1 hidden layers, 16 neurons, sigmoid activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 49.69387755102041%\n",
      "Training with 1 hidden layers, 16 neurons, sigmoid activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 50.0%\n",
      "Training with 1 hidden layers, 16 neurons, tanh activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 55.10204081632653%\n",
      "Training with 1 hidden layers, 16 neurons, tanh activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 55.10204081632653%\n",
      "Training with 1 hidden layers, 16 neurons, tanh activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 55.204081632653065%\n",
      "Training with 1 hidden layers, 16 neurons, tanh activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 52.755102040816325%\n",
      "Training with 1 hidden layers, 16 neurons, tanh activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 52.6530612244898%\n",
      "Training with 1 hidden layers, 16 neurons, tanh activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 52.755102040816325%\n",
      "Training with 1 hidden layers, 16 neurons, tanh activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 47.244897959183675%\n",
      "Training with 1 hidden layers, 16 neurons, tanh activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 48.36734693877551%\n",
      "Training with 1 hidden layers, 16 neurons, tanh activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 47.755102040816325%\n",
      "Training with 1 hidden layers, 16 neurons, tanh activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 54.08163265306123%\n",
      "Training with 1 hidden layers, 16 neurons, tanh activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 52.6530612244898%\n",
      "Training with 1 hidden layers, 16 neurons, tanh activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 55.61224489795919%\n",
      "Training with 1 hidden layers, 16 neurons, tanh activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 53.87755102040816%\n",
      "Training with 1 hidden layers, 16 neurons, tanh activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 53.775510204081634%\n",
      "Training with 1 hidden layers, 16 neurons, tanh activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 53.46938775510204%\n",
      "Training with 1 hidden layers, 16 neurons, tanh activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 50.40816326530612%\n",
      "Training with 1 hidden layers, 16 neurons, tanh activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 50.816326530612244%\n",
      "Training with 1 hidden layers, 16 neurons, tanh activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 51.83673469387755%\n",
      "Training with 1 hidden layers, 16 neurons, tanh activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 56.63265306122449%\n",
      "Training with 1 hidden layers, 16 neurons, tanh activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 53.97959183673469%\n",
      "Training with 1 hidden layers, 16 neurons, tanh activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 56.12244897959184%\n",
      "Training with 1 hidden layers, 16 neurons, tanh activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 54.48979591836735%\n",
      "Training with 1 hidden layers, 16 neurons, tanh activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 55.51020408163265%\n",
      "Training with 1 hidden layers, 16 neurons, tanh activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 54.69387755102041%\n",
      "Training with 1 hidden layers, 16 neurons, tanh activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 51.53061224489796%\n",
      "Training with 1 hidden layers, 16 neurons, tanh activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 51.02040816326531%\n",
      "Training with 1 hidden layers, 16 neurons, tanh activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 51.734693877551024%\n",
      "Training with 1 hidden layers, 16 neurons, softmax activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 54.59183673469388%\n",
      "Training with 1 hidden layers, 16 neurons, softmax activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 53.265306122448976%\n",
      "Training with 1 hidden layers, 16 neurons, softmax activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 54.08163265306123%\n",
      "Training with 1 hidden layers, 16 neurons, softmax activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 49.285714285714285%\n",
      "Training with 1 hidden layers, 16 neurons, softmax activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 50.0%\n",
      "Training with 1 hidden layers, 16 neurons, softmax activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 51.12244897959184%\n",
      "Training with 1 hidden layers, 16 neurons, softmax activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.183673469387756%\n",
      "Training with 1 hidden layers, 16 neurons, softmax activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 37.95918367346939%\n",
      "Training with 1 hidden layers, 16 neurons, softmax activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 46.224489795918366%\n",
      "Training with 1 hidden layers, 16 neurons, softmax activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 56.224489795918366%\n",
      "Training with 1 hidden layers, 16 neurons, softmax activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 55.0%\n",
      "Training with 1 hidden layers, 16 neurons, softmax activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 55.10204081632653%\n",
      "Training with 1 hidden layers, 16 neurons, softmax activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 53.673469387755105%\n",
      "Training with 1 hidden layers, 16 neurons, softmax activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 51.02040816326531%\n",
      "Training with 1 hidden layers, 16 neurons, softmax activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 53.87755102040816%\n",
      "Training with 1 hidden layers, 16 neurons, softmax activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 45.10204081632653%\n",
      "Training with 1 hidden layers, 16 neurons, softmax activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 37.95918367346939%\n",
      "Training with 1 hidden layers, 16 neurons, softmax activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.69387755102041%\n",
      "Training with 1 hidden layers, 16 neurons, softmax activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 54.69387755102041%\n",
      "Training with 1 hidden layers, 16 neurons, softmax activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 56.326530612244895%\n",
      "Training with 1 hidden layers, 16 neurons, softmax activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 53.46938775510204%\n",
      "Training with 1 hidden layers, 16 neurons, softmax activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 53.673469387755105%\n",
      "Training with 1 hidden layers, 16 neurons, softmax activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 55.10204081632653%\n",
      "Training with 1 hidden layers, 16 neurons, softmax activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 53.87755102040816%\n",
      "Training with 1 hidden layers, 16 neurons, softmax activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 47.244897959183675%\n",
      "Training with 1 hidden layers, 16 neurons, softmax activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 47.55102040816327%\n",
      "Training with 1 hidden layers, 16 neurons, softmax activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 47.6530612244898%\n",
      "Training with 1 hidden layers, 32 neurons, relu activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 57.857142857142854%\n",
      "Training with 1 hidden layers, 32 neurons, relu activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 53.06122448979592%\n",
      "Training with 1 hidden layers, 32 neurons, relu activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 53.97959183673469%\n",
      "Training with 1 hidden layers, 32 neurons, relu activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 54.38775510204081%\n",
      "Training with 1 hidden layers, 32 neurons, relu activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 54.08163265306123%\n",
      "Training with 1 hidden layers, 32 neurons, relu activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 55.0%\n",
      "Training with 1 hidden layers, 32 neurons, relu activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 50.0%\n",
      "Training with 1 hidden layers, 32 neurons, relu activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 50.40816326530612%\n",
      "Training with 1 hidden layers, 32 neurons, relu activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 48.57142857142857%\n",
      "Training with 1 hidden layers, 32 neurons, relu activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 55.10204081632653%\n",
      "Training with 1 hidden layers, 32 neurons, relu activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 53.87755102040816%\n",
      "Training with 1 hidden layers, 32 neurons, relu activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 54.89795918367347%\n",
      "Training with 1 hidden layers, 32 neurons, relu activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 53.46938775510204%\n",
      "Training with 1 hidden layers, 32 neurons, relu activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 55.51020408163265%\n",
      "Training with 1 hidden layers, 32 neurons, relu activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 55.10204081632653%\n",
      "Training with 1 hidden layers, 32 neurons, relu activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 52.755102040816325%\n",
      "Training with 1 hidden layers, 32 neurons, relu activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 51.02040816326531%\n",
      "Training with 1 hidden layers, 32 neurons, relu activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 52.55102040816327%\n",
      "Training with 1 hidden layers, 32 neurons, relu activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 54.89795918367347%\n",
      "Training with 1 hidden layers, 32 neurons, relu activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 56.326530612244895%\n",
      "Training with 1 hidden layers, 32 neurons, relu activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 55.40816326530612%\n",
      "Training with 1 hidden layers, 32 neurons, relu activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 54.69387755102041%\n",
      "Training with 1 hidden layers, 32 neurons, relu activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 54.183673469387756%\n",
      "Training with 1 hidden layers, 32 neurons, relu activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 54.795918367346935%\n",
      "Training with 1 hidden layers, 32 neurons, relu activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 53.16326530612245%\n",
      "Training with 1 hidden layers, 32 neurons, relu activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 54.69387755102041%\n",
      "Training with 1 hidden layers, 32 neurons, relu activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 54.59183673469388%\n",
      "Training with 1 hidden layers, 32 neurons, sigmoid activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 54.285714285714285%\n",
      "Training with 1 hidden layers, 32 neurons, sigmoid activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 55.204081632653065%\n",
      "Training with 1 hidden layers, 32 neurons, sigmoid activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 55.10204081632653%\n",
      "Training with 1 hidden layers, 32 neurons, sigmoid activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 51.734693877551024%\n",
      "Training with 1 hidden layers, 32 neurons, sigmoid activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 52.244897959183675%\n",
      "Training with 1 hidden layers, 32 neurons, sigmoid activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 52.04081632653061%\n",
      "Training with 1 hidden layers, 32 neurons, sigmoid activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 45.51020408163265%\n",
      "Training with 1 hidden layers, 32 neurons, sigmoid activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 46.326530612244895%\n",
      "Training with 1 hidden layers, 32 neurons, sigmoid activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 45.204081632653065%\n",
      "Training with 1 hidden layers, 32 neurons, sigmoid activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 54.285714285714285%\n",
      "Training with 1 hidden layers, 32 neurons, sigmoid activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 54.48979591836735%\n",
      "Training with 1 hidden layers, 32 neurons, sigmoid activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 52.857142857142854%\n",
      "Training with 1 hidden layers, 32 neurons, sigmoid activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 51.734693877551024%\n",
      "Training with 1 hidden layers, 32 neurons, sigmoid activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 52.3469387755102%\n",
      "Training with 1 hidden layers, 32 neurons, sigmoid activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 52.244897959183675%\n",
      "Training with 1 hidden layers, 32 neurons, sigmoid activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 48.673469387755105%\n",
      "Training with 1 hidden layers, 32 neurons, sigmoid activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 47.44897959183673%\n",
      "Training with 1 hidden layers, 32 neurons, sigmoid activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 47.6530612244898%\n",
      "Training with 1 hidden layers, 32 neurons, sigmoid activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 55.204081632653065%\n",
      "Training with 1 hidden layers, 32 neurons, sigmoid activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 55.30612244897959%\n",
      "Training with 1 hidden layers, 32 neurons, sigmoid activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 55.40816326530612%\n",
      "Training with 1 hidden layers, 32 neurons, sigmoid activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 52.95918367346939%\n",
      "Training with 1 hidden layers, 32 neurons, sigmoid activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 53.87755102040816%\n",
      "Training with 1 hidden layers, 32 neurons, sigmoid activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 53.16326530612245%\n",
      "Training with 1 hidden layers, 32 neurons, sigmoid activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 51.224489795918366%\n",
      "Training with 1 hidden layers, 32 neurons, sigmoid activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 51.42857142857143%\n",
      "Training with 1 hidden layers, 32 neurons, sigmoid activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 51.734693877551024%\n",
      "Training with 1 hidden layers, 32 neurons, tanh activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 56.02040816326531%\n",
      "Training with 1 hidden layers, 32 neurons, tanh activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 55.10204081632653%\n",
      "Training with 1 hidden layers, 32 neurons, tanh activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 54.285714285714285%\n",
      "Training with 1 hidden layers, 32 neurons, tanh activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 52.755102040816325%\n",
      "Training with 1 hidden layers, 32 neurons, tanh activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 53.46938775510204%\n",
      "Training with 1 hidden layers, 32 neurons, tanh activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 52.755102040816325%\n",
      "Training with 1 hidden layers, 32 neurons, tanh activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 50.204081632653065%\n",
      "Training with 1 hidden layers, 32 neurons, tanh activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 53.16326530612245%\n",
      "Training with 1 hidden layers, 32 neurons, tanh activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 48.87755102040816%\n",
      "Training with 1 hidden layers, 32 neurons, tanh activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 54.89795918367347%\n",
      "Training with 1 hidden layers, 32 neurons, tanh activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 55.10204081632653%\n",
      "Training with 1 hidden layers, 32 neurons, tanh activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 55.30612244897959%\n",
      "Training with 1 hidden layers, 32 neurons, tanh activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 54.38775510204081%\n",
      "Training with 1 hidden layers, 32 neurons, tanh activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 54.48979591836735%\n",
      "Training with 1 hidden layers, 32 neurons, tanh activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 54.38775510204081%\n",
      "Training with 1 hidden layers, 32 neurons, tanh activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 52.244897959183675%\n",
      "Training with 1 hidden layers, 32 neurons, tanh activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 52.55102040816327%\n",
      "Training with 1 hidden layers, 32 neurons, tanh activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 51.734693877551024%\n",
      "Training with 1 hidden layers, 32 neurons, tanh activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 53.87755102040816%\n",
      "Training with 1 hidden layers, 32 neurons, tanh activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 54.08163265306123%\n",
      "Training with 1 hidden layers, 32 neurons, tanh activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 53.16326530612245%\n",
      "Training with 1 hidden layers, 32 neurons, tanh activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 55.0%\n",
      "Training with 1 hidden layers, 32 neurons, tanh activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 56.02040816326531%\n",
      "Training with 1 hidden layers, 32 neurons, tanh activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 54.69387755102041%\n",
      "Training with 1 hidden layers, 32 neurons, tanh activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 52.6530612244898%\n",
      "Training with 1 hidden layers, 32 neurons, tanh activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 51.734693877551024%\n",
      "Training with 1 hidden layers, 32 neurons, tanh activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 51.53061224489796%\n",
      "Training with 1 hidden layers, 32 neurons, softmax activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 54.89795918367347%\n",
      "Training with 1 hidden layers, 32 neurons, softmax activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 53.265306122448976%\n",
      "Training with 1 hidden layers, 32 neurons, softmax activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 53.775510204081634%\n",
      "Training with 1 hidden layers, 32 neurons, softmax activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 51.63265306122449%\n",
      "Training with 1 hidden layers, 32 neurons, softmax activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 52.55102040816327%\n",
      "Training with 1 hidden layers, 32 neurons, softmax activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 52.55102040816327%\n",
      "Training with 1 hidden layers, 32 neurons, softmax activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 1 hidden layers, 32 neurons, softmax activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 1 hidden layers, 32 neurons, softmax activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 1 hidden layers, 32 neurons, softmax activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 55.30612244897959%\n",
      "Training with 1 hidden layers, 32 neurons, softmax activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 55.204081632653065%\n",
      "Training with 1 hidden layers, 32 neurons, softmax activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 54.59183673469388%\n",
      "Training with 1 hidden layers, 32 neurons, softmax activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 52.04081632653061%\n",
      "Training with 1 hidden layers, 32 neurons, softmax activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 50.51020408163265%\n",
      "Training with 1 hidden layers, 32 neurons, softmax activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 52.244897959183675%\n",
      "Training with 1 hidden layers, 32 neurons, softmax activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 43.36734693877551%\n",
      "Training with 1 hidden layers, 32 neurons, softmax activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 1 hidden layers, 32 neurons, softmax activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 41.83673469387755%\n",
      "Training with 1 hidden layers, 32 neurons, softmax activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 56.63265306122449%\n",
      "Training with 1 hidden layers, 32 neurons, softmax activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 55.30612244897959%\n",
      "Training with 1 hidden layers, 32 neurons, softmax activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 54.285714285714285%\n",
      "Training with 1 hidden layers, 32 neurons, softmax activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 54.08163265306123%\n",
      "Training with 1 hidden layers, 32 neurons, softmax activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 55.204081632653065%\n",
      "Training with 1 hidden layers, 32 neurons, softmax activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 53.265306122448976%\n",
      "Training with 1 hidden layers, 32 neurons, softmax activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 47.755102040816325%\n",
      "Training with 1 hidden layers, 32 neurons, softmax activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 47.857142857142854%\n",
      "Training with 1 hidden layers, 32 neurons, softmax activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 47.244897959183675%\n",
      "Training with 1 hidden layers, 64 neurons, relu activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 54.38775510204081%\n",
      "Training with 1 hidden layers, 64 neurons, relu activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 54.59183673469388%\n",
      "Training with 1 hidden layers, 64 neurons, relu activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 52.95918367346939%\n",
      "Training with 1 hidden layers, 64 neurons, relu activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 53.06122448979592%\n",
      "Training with 1 hidden layers, 64 neurons, relu activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 55.816326530612244%\n",
      "Training with 1 hidden layers, 64 neurons, relu activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 55.40816326530612%\n",
      "Training with 1 hidden layers, 64 neurons, relu activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 51.53061224489796%\n",
      "Training with 1 hidden layers, 64 neurons, relu activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 50.714285714285715%\n",
      "Training with 1 hidden layers, 64 neurons, relu activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 52.142857142857146%\n",
      "Training with 1 hidden layers, 64 neurons, relu activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 54.89795918367347%\n",
      "Training with 1 hidden layers, 64 neurons, relu activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 56.12244897959184%\n",
      "Training with 1 hidden layers, 64 neurons, relu activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 55.204081632653065%\n",
      "Training with 1 hidden layers, 64 neurons, relu activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 56.42857142857143%\n",
      "Training with 1 hidden layers, 64 neurons, relu activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 56.83673469387755%\n",
      "Training with 1 hidden layers, 64 neurons, relu activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 54.38775510204081%\n",
      "Training with 1 hidden layers, 64 neurons, relu activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 52.95918367346939%\n",
      "Training with 1 hidden layers, 64 neurons, relu activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 53.87755102040816%\n",
      "Training with 1 hidden layers, 64 neurons, relu activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 54.59183673469388%\n",
      "Training with 1 hidden layers, 64 neurons, relu activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 56.12244897959184%\n",
      "Training with 1 hidden layers, 64 neurons, relu activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 53.87755102040816%\n",
      "Training with 1 hidden layers, 64 neurons, relu activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 56.224489795918366%\n",
      "Training with 1 hidden layers, 64 neurons, relu activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 54.795918367346935%\n",
      "Training with 1 hidden layers, 64 neurons, relu activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 55.91836734693877%\n",
      "Training with 1 hidden layers, 64 neurons, relu activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 55.816326530612244%\n",
      "Training with 1 hidden layers, 64 neurons, relu activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 54.38775510204081%\n",
      "Training with 1 hidden layers, 64 neurons, relu activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 53.57142857142857%\n",
      "Training with 1 hidden layers, 64 neurons, relu activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 54.89795918367347%\n",
      "Training with 1 hidden layers, 64 neurons, sigmoid activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 52.55102040816327%\n",
      "Training with 1 hidden layers, 64 neurons, sigmoid activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 56.224489795918366%\n",
      "Training with 1 hidden layers, 64 neurons, sigmoid activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 56.734693877551024%\n",
      "Training with 1 hidden layers, 64 neurons, sigmoid activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 52.142857142857146%\n",
      "Training with 1 hidden layers, 64 neurons, sigmoid activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 52.95918367346939%\n",
      "Training with 1 hidden layers, 64 neurons, sigmoid activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 51.53061224489796%\n",
      "Training with 1 hidden layers, 64 neurons, sigmoid activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 46.326530612244895%\n",
      "Training with 1 hidden layers, 64 neurons, sigmoid activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 45.816326530612244%\n",
      "Training with 1 hidden layers, 64 neurons, sigmoid activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 47.44897959183673%\n",
      "Training with 1 hidden layers, 64 neurons, sigmoid activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 57.55102040816327%\n",
      "Training with 1 hidden layers, 64 neurons, sigmoid activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 57.142857142857146%\n",
      "Training with 1 hidden layers, 64 neurons, sigmoid activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 55.51020408163265%\n",
      "Training with 1 hidden layers, 64 neurons, sigmoid activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 52.142857142857146%\n",
      "Training with 1 hidden layers, 64 neurons, sigmoid activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 51.734693877551024%\n",
      "Training with 1 hidden layers, 64 neurons, sigmoid activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 51.63265306122449%\n",
      "Training with 1 hidden layers, 64 neurons, sigmoid activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 49.69387755102041%\n",
      "Training with 1 hidden layers, 64 neurons, sigmoid activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 50.51020408163265%\n",
      "Training with 1 hidden layers, 64 neurons, sigmoid activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 50.0%\n",
      "Training with 1 hidden layers, 64 neurons, sigmoid activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 56.63265306122449%\n",
      "Training with 1 hidden layers, 64 neurons, sigmoid activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 54.795918367346935%\n",
      "Training with 1 hidden layers, 64 neurons, sigmoid activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 57.3469387755102%\n",
      "Training with 1 hidden layers, 64 neurons, sigmoid activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 53.06122448979592%\n",
      "Training with 1 hidden layers, 64 neurons, sigmoid activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 53.87755102040816%\n",
      "Training with 1 hidden layers, 64 neurons, sigmoid activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 51.93877551020408%\n",
      "Training with 1 hidden layers, 64 neurons, sigmoid activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 51.83673469387755%\n",
      "Training with 1 hidden layers, 64 neurons, sigmoid activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 51.83673469387755%\n",
      "Training with 1 hidden layers, 64 neurons, sigmoid activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 52.04081632653061%\n",
      "Training with 1 hidden layers, 64 neurons, tanh activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 55.51020408163265%\n",
      "Training with 1 hidden layers, 64 neurons, tanh activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 54.89795918367347%\n",
      "Training with 1 hidden layers, 64 neurons, tanh activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 55.714285714285715%\n",
      "Training with 1 hidden layers, 64 neurons, tanh activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 53.673469387755105%\n",
      "Training with 1 hidden layers, 64 neurons, tanh activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 53.16326530612245%\n",
      "Training with 1 hidden layers, 64 neurons, tanh activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 53.16326530612245%\n",
      "Training with 1 hidden layers, 64 neurons, tanh activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 51.93877551020408%\n",
      "Training with 1 hidden layers, 64 neurons, tanh activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 51.53061224489796%\n",
      "Training with 1 hidden layers, 64 neurons, tanh activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 50.40816326530612%\n",
      "Training with 1 hidden layers, 64 neurons, tanh activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 58.16326530612245%\n",
      "Training with 1 hidden layers, 64 neurons, tanh activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 55.0%\n",
      "Training with 1 hidden layers, 64 neurons, tanh activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 55.30612244897959%\n",
      "Training with 1 hidden layers, 64 neurons, tanh activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 54.48979591836735%\n",
      "Training with 1 hidden layers, 64 neurons, tanh activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 55.714285714285715%\n",
      "Training with 1 hidden layers, 64 neurons, tanh activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 55.40816326530612%\n",
      "Training with 1 hidden layers, 64 neurons, tanh activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 51.93877551020408%\n",
      "Training with 1 hidden layers, 64 neurons, tanh activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 51.63265306122449%\n",
      "Training with 1 hidden layers, 64 neurons, tanh activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 52.3469387755102%\n",
      "Training with 1 hidden layers, 64 neurons, tanh activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 52.04081632653061%\n",
      "Training with 1 hidden layers, 64 neurons, tanh activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 57.142857142857146%\n",
      "Training with 1 hidden layers, 64 neurons, tanh activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 53.16326530612245%\n",
      "Training with 1 hidden layers, 64 neurons, tanh activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 54.89795918367347%\n",
      "Training with 1 hidden layers, 64 neurons, tanh activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 55.91836734693877%\n",
      "Training with 1 hidden layers, 64 neurons, tanh activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 55.40816326530612%\n",
      "Training with 1 hidden layers, 64 neurons, tanh activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 52.6530612244898%\n",
      "Training with 1 hidden layers, 64 neurons, tanh activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 51.734693877551024%\n",
      "Training with 1 hidden layers, 64 neurons, tanh activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 51.93877551020408%\n",
      "Training with 1 hidden layers, 64 neurons, softmax activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 56.42857142857143%\n",
      "Training with 1 hidden layers, 64 neurons, softmax activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 53.36734693877551%\n",
      "Training with 1 hidden layers, 64 neurons, softmax activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 54.183673469387756%\n",
      "Training with 1 hidden layers, 64 neurons, softmax activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 51.12244897959184%\n",
      "Training with 1 hidden layers, 64 neurons, softmax activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 51.224489795918366%\n",
      "Training with 1 hidden layers, 64 neurons, softmax activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 50.51020408163265%\n",
      "Training with 1 hidden layers, 64 neurons, softmax activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 1 hidden layers, 64 neurons, softmax activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 29.79591836734694%\n",
      "Training with 1 hidden layers, 64 neurons, softmax activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 43.97959183673469%\n",
      "Training with 1 hidden layers, 64 neurons, softmax activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 56.326530612244895%\n",
      "Training with 1 hidden layers, 64 neurons, softmax activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 54.38775510204081%\n",
      "Training with 1 hidden layers, 64 neurons, softmax activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 55.714285714285715%\n",
      "Training with 1 hidden layers, 64 neurons, softmax activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 51.93877551020408%\n",
      "Training with 1 hidden layers, 64 neurons, softmax activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 52.95918367346939%\n",
      "Training with 1 hidden layers, 64 neurons, softmax activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 54.08163265306123%\n",
      "Training with 1 hidden layers, 64 neurons, softmax activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 1 hidden layers, 64 neurons, softmax activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 1 hidden layers, 64 neurons, softmax activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.183673469387756%\n",
      "Training with 1 hidden layers, 64 neurons, softmax activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 55.51020408163265%\n",
      "Training with 1 hidden layers, 64 neurons, softmax activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 57.142857142857146%\n",
      "Training with 1 hidden layers, 64 neurons, softmax activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 55.51020408163265%\n",
      "Training with 1 hidden layers, 64 neurons, softmax activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 54.48979591836735%\n",
      "Training with 1 hidden layers, 64 neurons, softmax activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 53.775510204081634%\n",
      "Training with 1 hidden layers, 64 neurons, softmax activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 54.285714285714285%\n",
      "Training with 1 hidden layers, 64 neurons, softmax activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 48.36734693877551%\n",
      "Training with 1 hidden layers, 64 neurons, softmax activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 45.816326530612244%\n",
      "Training with 1 hidden layers, 64 neurons, softmax activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 49.59183673469388%\n",
      "Training with 2 hidden layers, 4 neurons, relu activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 53.16326530612245%\n",
      "Training with 2 hidden layers, 4 neurons, relu activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 50.61224489795919%\n",
      "Training with 2 hidden layers, 4 neurons, relu activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 53.57142857142857%\n",
      "Training with 2 hidden layers, 4 neurons, relu activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 51.734693877551024%\n",
      "Training with 2 hidden layers, 4 neurons, relu activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 50.91836734693877%\n",
      "Training with 2 hidden layers, 4 neurons, relu activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 53.57142857142857%\n",
      "Training with 2 hidden layers, 4 neurons, relu activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 24.387755102040817%\n",
      "Training with 2 hidden layers, 4 neurons, relu activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 38.97959183673469%\n",
      "Training with 2 hidden layers, 4 neurons, relu activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 37.3469387755102%\n",
      "Training with 2 hidden layers, 4 neurons, relu activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 53.06122448979592%\n",
      "Training with 2 hidden layers, 4 neurons, relu activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 52.6530612244898%\n",
      "Training with 2 hidden layers, 4 neurons, relu activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 53.673469387755105%\n",
      "Training with 2 hidden layers, 4 neurons, relu activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 51.83673469387755%\n",
      "Training with 2 hidden layers, 4 neurons, relu activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 52.3469387755102%\n",
      "Training with 2 hidden layers, 4 neurons, relu activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 52.857142857142854%\n",
      "Training with 2 hidden layers, 4 neurons, relu activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 47.142857142857146%\n",
      "Training with 2 hidden layers, 4 neurons, relu activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 46.12244897959184%\n",
      "Training with 2 hidden layers, 4 neurons, relu activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 43.46938775510204%\n",
      "Training with 2 hidden layers, 4 neurons, relu activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 53.06122448979592%\n",
      "Training with 2 hidden layers, 4 neurons, relu activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 53.57142857142857%\n",
      "Training with 2 hidden layers, 4 neurons, relu activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 53.97959183673469%\n",
      "Training with 2 hidden layers, 4 neurons, relu activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 52.857142857142854%\n",
      "Training with 2 hidden layers, 4 neurons, relu activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 53.775510204081634%\n",
      "Training with 2 hidden layers, 4 neurons, relu activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 52.857142857142854%\n",
      "Training with 2 hidden layers, 4 neurons, relu activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 46.63265306122449%\n",
      "Training with 2 hidden layers, 4 neurons, relu activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.59183673469388%\n",
      "Training with 2 hidden layers, 4 neurons, relu activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 50.40816326530612%\n",
      "Training with 2 hidden layers, 4 neurons, sigmoid activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 54.285714285714285%\n",
      "Training with 2 hidden layers, 4 neurons, sigmoid activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 53.36734693877551%\n",
      "Training with 2 hidden layers, 4 neurons, sigmoid activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 53.16326530612245%\n",
      "Training with 2 hidden layers, 4 neurons, sigmoid activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 4 neurons, sigmoid activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 4 neurons, sigmoid activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 4 neurons, sigmoid activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 4 neurons, sigmoid activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 29.79591836734694%\n",
      "Training with 2 hidden layers, 4 neurons, sigmoid activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.48979591836735%\n",
      "Training with 2 hidden layers, 4 neurons, sigmoid activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 52.857142857142854%\n",
      "Training with 2 hidden layers, 4 neurons, sigmoid activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 53.57142857142857%\n",
      "Training with 2 hidden layers, 4 neurons, sigmoid activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 52.55102040816327%\n",
      "Training with 2 hidden layers, 4 neurons, sigmoid activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 51.224489795918366%\n",
      "Training with 2 hidden layers, 4 neurons, sigmoid activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 51.53061224489796%\n",
      "Training with 2 hidden layers, 4 neurons, sigmoid activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 4 neurons, sigmoid activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 4 neurons, sigmoid activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 4 neurons, sigmoid activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 4 neurons, sigmoid activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 54.285714285714285%\n",
      "Training with 2 hidden layers, 4 neurons, sigmoid activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 53.775510204081634%\n",
      "Training with 2 hidden layers, 4 neurons, sigmoid activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 54.08163265306123%\n",
      "Training with 2 hidden layers, 4 neurons, sigmoid activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 53.06122448979592%\n",
      "Training with 2 hidden layers, 4 neurons, sigmoid activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 52.6530612244898%\n",
      "Training with 2 hidden layers, 4 neurons, sigmoid activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 53.16326530612245%\n",
      "Training with 2 hidden layers, 4 neurons, sigmoid activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 4 neurons, sigmoid activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 4 neurons, sigmoid activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 4 neurons, tanh activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 53.46938775510204%\n",
      "Training with 2 hidden layers, 4 neurons, tanh activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 53.06122448979592%\n",
      "Training with 2 hidden layers, 4 neurons, tanh activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 54.59183673469388%\n",
      "Training with 2 hidden layers, 4 neurons, tanh activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 50.91836734693877%\n",
      "Training with 2 hidden layers, 4 neurons, tanh activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 51.93877551020408%\n",
      "Training with 2 hidden layers, 4 neurons, tanh activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 52.6530612244898%\n",
      "Training with 2 hidden layers, 4 neurons, tanh activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 45.816326530612244%\n",
      "Training with 2 hidden layers, 4 neurons, tanh activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 30.510204081632654%\n",
      "Training with 2 hidden layers, 4 neurons, tanh activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 46.12244897959184%\n",
      "Training with 2 hidden layers, 4 neurons, tanh activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 54.08163265306123%\n",
      "Training with 2 hidden layers, 4 neurons, tanh activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 54.285714285714285%\n",
      "Training with 2 hidden layers, 4 neurons, tanh activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 54.38775510204081%\n",
      "Training with 2 hidden layers, 4 neurons, tanh activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 52.04081632653061%\n",
      "Training with 2 hidden layers, 4 neurons, tanh activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 53.36734693877551%\n",
      "Training with 2 hidden layers, 4 neurons, tanh activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 52.6530612244898%\n",
      "Training with 2 hidden layers, 4 neurons, tanh activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 4 neurons, tanh activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 49.183673469387756%\n",
      "Training with 2 hidden layers, 4 neurons, tanh activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 4 neurons, tanh activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 54.69387755102041%\n",
      "Training with 2 hidden layers, 4 neurons, tanh activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 54.69387755102041%\n",
      "Training with 2 hidden layers, 4 neurons, tanh activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 55.10204081632653%\n",
      "Training with 2 hidden layers, 4 neurons, tanh activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 54.183673469387756%\n",
      "Training with 2 hidden layers, 4 neurons, tanh activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 54.183673469387756%\n",
      "Training with 2 hidden layers, 4 neurons, tanh activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 52.857142857142854%\n",
      "Training with 2 hidden layers, 4 neurons, tanh activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 51.63265306122449%\n",
      "Training with 2 hidden layers, 4 neurons, tanh activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 45.10204081632653%\n",
      "Training with 2 hidden layers, 4 neurons, tanh activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 46.53061224489796%\n",
      "Training with 2 hidden layers, 4 neurons, softmax activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 52.6530612244898%\n",
      "Training with 2 hidden layers, 4 neurons, softmax activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 52.142857142857146%\n",
      "Training with 2 hidden layers, 4 neurons, softmax activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 53.265306122448976%\n",
      "Training with 2 hidden layers, 4 neurons, softmax activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 4 neurons, softmax activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 50.816326530612244%\n",
      "Training with 2 hidden layers, 4 neurons, softmax activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 50.10204081632653%\n",
      "Training with 2 hidden layers, 4 neurons, softmax activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 19.591836734693878%\n",
      "Training with 2 hidden layers, 4 neurons, softmax activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.183673469387756%\n",
      "Training with 2 hidden layers, 4 neurons, softmax activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 29.693877551020407%\n",
      "Training with 2 hidden layers, 4 neurons, softmax activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 53.46938775510204%\n",
      "Training with 2 hidden layers, 4 neurons, softmax activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 52.95918367346939%\n",
      "Training with 2 hidden layers, 4 neurons, softmax activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 52.95918367346939%\n",
      "Training with 2 hidden layers, 4 neurons, softmax activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 51.02040816326531%\n",
      "Training with 2 hidden layers, 4 neurons, softmax activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 49.69387755102041%\n",
      "Training with 2 hidden layers, 4 neurons, softmax activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 50.816326530612244%\n",
      "Training with 2 hidden layers, 4 neurons, softmax activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 29.693877551020407%\n",
      "Training with 2 hidden layers, 4 neurons, softmax activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 4 neurons, softmax activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 4 neurons, softmax activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 53.87755102040816%\n",
      "Training with 2 hidden layers, 4 neurons, softmax activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 52.755102040816325%\n",
      "Training with 2 hidden layers, 4 neurons, softmax activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 54.38775510204081%\n",
      "Training with 2 hidden layers, 4 neurons, softmax activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 51.02040816326531%\n",
      "Training with 2 hidden layers, 4 neurons, softmax activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 51.734693877551024%\n",
      "Training with 2 hidden layers, 4 neurons, softmax activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 52.857142857142854%\n",
      "Training with 2 hidden layers, 4 neurons, softmax activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.89795918367347%\n",
      "Training with 2 hidden layers, 4 neurons, softmax activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 4 neurons, softmax activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 48.36734693877551%\n",
      "Training with 2 hidden layers, 8 neurons, relu activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 53.775510204081634%\n",
      "Training with 2 hidden layers, 8 neurons, relu activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 56.224489795918366%\n",
      "Training with 2 hidden layers, 8 neurons, relu activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 52.3469387755102%\n",
      "Training with 2 hidden layers, 8 neurons, relu activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 53.57142857142857%\n",
      "Training with 2 hidden layers, 8 neurons, relu activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 52.857142857142854%\n",
      "Training with 2 hidden layers, 8 neurons, relu activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 53.36734693877551%\n",
      "Training with 2 hidden layers, 8 neurons, relu activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 8 neurons, relu activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 47.142857142857146%\n",
      "Training with 2 hidden layers, 8 neurons, relu activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 43.57142857142857%\n",
      "Training with 2 hidden layers, 8 neurons, relu activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 54.08163265306123%\n",
      "Training with 2 hidden layers, 8 neurons, relu activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 55.0%\n",
      "Training with 2 hidden layers, 8 neurons, relu activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 54.38775510204081%\n",
      "Training with 2 hidden layers, 8 neurons, relu activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 54.38775510204081%\n",
      "Training with 2 hidden layers, 8 neurons, relu activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 52.755102040816325%\n",
      "Training with 2 hidden layers, 8 neurons, relu activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 53.87755102040816%\n",
      "Training with 2 hidden layers, 8 neurons, relu activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 8 neurons, relu activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 48.36734693877551%\n",
      "Training with 2 hidden layers, 8 neurons, relu activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 46.02040816326531%\n",
      "Training with 2 hidden layers, 8 neurons, relu activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 57.857142857142854%\n",
      "Training with 2 hidden layers, 8 neurons, relu activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 54.48979591836735%\n",
      "Training with 2 hidden layers, 8 neurons, relu activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 54.59183673469388%\n",
      "Training with 2 hidden layers, 8 neurons, relu activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 53.673469387755105%\n",
      "Training with 2 hidden layers, 8 neurons, relu activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 54.38775510204081%\n",
      "Training with 2 hidden layers, 8 neurons, relu activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 52.755102040816325%\n",
      "Training with 2 hidden layers, 8 neurons, relu activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 53.16326530612245%\n",
      "Training with 2 hidden layers, 8 neurons, relu activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 52.44897959183673%\n",
      "Training with 2 hidden layers, 8 neurons, relu activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 49.795918367346935%\n",
      "Training with 2 hidden layers, 8 neurons, sigmoid activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 54.59183673469388%\n",
      "Training with 2 hidden layers, 8 neurons, sigmoid activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 54.59183673469388%\n",
      "Training with 2 hidden layers, 8 neurons, sigmoid activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 53.87755102040816%\n",
      "Training with 2 hidden layers, 8 neurons, sigmoid activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 50.816326530612244%\n",
      "Training with 2 hidden layers, 8 neurons, sigmoid activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 51.224489795918366%\n",
      "Training with 2 hidden layers, 8 neurons, sigmoid activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 50.51020408163265%\n",
      "Training with 2 hidden layers, 8 neurons, sigmoid activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 8 neurons, sigmoid activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 8 neurons, sigmoid activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 8 neurons, sigmoid activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 54.48979591836735%\n",
      "Training with 2 hidden layers, 8 neurons, sigmoid activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 54.48979591836735%\n",
      "Training with 2 hidden layers, 8 neurons, sigmoid activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 55.61224489795919%\n",
      "Training with 2 hidden layers, 8 neurons, sigmoid activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 52.6530612244898%\n",
      "Training with 2 hidden layers, 8 neurons, sigmoid activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 51.734693877551024%\n",
      "Training with 2 hidden layers, 8 neurons, sigmoid activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 51.93877551020408%\n",
      "Training with 2 hidden layers, 8 neurons, sigmoid activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 8 neurons, sigmoid activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 8 neurons, sigmoid activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 8 neurons, sigmoid activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 53.87755102040816%\n",
      "Training with 2 hidden layers, 8 neurons, sigmoid activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 54.183673469387756%\n",
      "Training with 2 hidden layers, 8 neurons, sigmoid activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 55.10204081632653%\n",
      "Training with 2 hidden layers, 8 neurons, sigmoid activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 53.87755102040816%\n",
      "Training with 2 hidden layers, 8 neurons, sigmoid activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 53.673469387755105%\n",
      "Training with 2 hidden layers, 8 neurons, sigmoid activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 54.183673469387756%\n",
      "Training with 2 hidden layers, 8 neurons, sigmoid activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 8 neurons, sigmoid activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 8 neurons, sigmoid activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 8 neurons, tanh activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 53.97959183673469%\n",
      "Training with 2 hidden layers, 8 neurons, tanh activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 54.38775510204081%\n",
      "Training with 2 hidden layers, 8 neurons, tanh activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 55.204081632653065%\n",
      "Training with 2 hidden layers, 8 neurons, tanh activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 53.16326530612245%\n",
      "Training with 2 hidden layers, 8 neurons, tanh activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 51.53061224489796%\n",
      "Training with 2 hidden layers, 8 neurons, tanh activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 53.57142857142857%\n",
      "Training with 2 hidden layers, 8 neurons, tanh activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 43.97959183673469%\n",
      "Training with 2 hidden layers, 8 neurons, tanh activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.285714285714285%\n",
      "Training with 2 hidden layers, 8 neurons, tanh activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 48.06122448979592%\n",
      "Training with 2 hidden layers, 8 neurons, tanh activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 53.97959183673469%\n",
      "Training with 2 hidden layers, 8 neurons, tanh activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 55.30612244897959%\n",
      "Training with 2 hidden layers, 8 neurons, tanh activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 55.30612244897959%\n",
      "Training with 2 hidden layers, 8 neurons, tanh activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 54.69387755102041%\n",
      "Training with 2 hidden layers, 8 neurons, tanh activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 54.08163265306123%\n",
      "Training with 2 hidden layers, 8 neurons, tanh activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 55.204081632653065%\n",
      "Training with 2 hidden layers, 8 neurons, tanh activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 47.95918367346939%\n",
      "Training with 2 hidden layers, 8 neurons, tanh activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 48.87755102040816%\n",
      "Training with 2 hidden layers, 8 neurons, tanh activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 50.204081632653065%\n",
      "Training with 2 hidden layers, 8 neurons, tanh activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 54.69387755102041%\n",
      "Training with 2 hidden layers, 8 neurons, tanh activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 53.36734693877551%\n",
      "Training with 2 hidden layers, 8 neurons, tanh activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 54.59183673469388%\n",
      "Training with 2 hidden layers, 8 neurons, tanh activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 54.795918367346935%\n",
      "Training with 2 hidden layers, 8 neurons, tanh activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 53.673469387755105%\n",
      "Training with 2 hidden layers, 8 neurons, tanh activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 54.795918367346935%\n",
      "Training with 2 hidden layers, 8 neurons, tanh activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 51.02040816326531%\n",
      "Training with 2 hidden layers, 8 neurons, tanh activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 52.3469387755102%\n",
      "Training with 2 hidden layers, 8 neurons, tanh activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 52.55102040816327%\n",
      "Training with 2 hidden layers, 8 neurons, softmax activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 53.16326530612245%\n",
      "Training with 2 hidden layers, 8 neurons, softmax activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 54.285714285714285%\n",
      "Training with 2 hidden layers, 8 neurons, softmax activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 53.673469387755105%\n",
      "Training with 2 hidden layers, 8 neurons, softmax activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 8 neurons, softmax activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 8 neurons, softmax activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 51.93877551020408%\n",
      "Training with 2 hidden layers, 8 neurons, softmax activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 8 neurons, softmax activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 29.693877551020407%\n",
      "Training with 2 hidden layers, 8 neurons, softmax activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 8 neurons, softmax activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 55.40816326530612%\n",
      "Training with 2 hidden layers, 8 neurons, softmax activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 54.285714285714285%\n",
      "Training with 2 hidden layers, 8 neurons, softmax activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 56.63265306122449%\n",
      "Training with 2 hidden layers, 8 neurons, softmax activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 51.02040816326531%\n",
      "Training with 2 hidden layers, 8 neurons, softmax activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 51.93877551020408%\n",
      "Training with 2 hidden layers, 8 neurons, softmax activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 51.93877551020408%\n",
      "Training with 2 hidden layers, 8 neurons, softmax activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 8 neurons, softmax activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 8 neurons, softmax activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 8 neurons, softmax activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 55.91836734693877%\n",
      "Training with 2 hidden layers, 8 neurons, softmax activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 55.30612244897959%\n",
      "Training with 2 hidden layers, 8 neurons, softmax activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 57.04081632653061%\n",
      "Training with 2 hidden layers, 8 neurons, softmax activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 53.673469387755105%\n",
      "Training with 2 hidden layers, 8 neurons, softmax activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 54.183673469387756%\n",
      "Training with 2 hidden layers, 8 neurons, softmax activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 55.0%\n",
      "Training with 2 hidden layers, 8 neurons, softmax activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 8 neurons, softmax activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 8 neurons, softmax activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 16 neurons, relu activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 56.326530612244895%\n",
      "Training with 2 hidden layers, 16 neurons, relu activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 53.87755102040816%\n",
      "Training with 2 hidden layers, 16 neurons, relu activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 54.48979591836735%\n",
      "Training with 2 hidden layers, 16 neurons, relu activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 54.59183673469388%\n",
      "Training with 2 hidden layers, 16 neurons, relu activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 55.10204081632653%\n",
      "Training with 2 hidden layers, 16 neurons, relu activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 54.285714285714285%\n",
      "Training with 2 hidden layers, 16 neurons, relu activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.285714285714285%\n",
      "Training with 2 hidden layers, 16 neurons, relu activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 45.714285714285715%\n",
      "Training with 2 hidden layers, 16 neurons, relu activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 46.224489795918366%\n",
      "Training with 2 hidden layers, 16 neurons, relu activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 55.204081632653065%\n",
      "Training with 2 hidden layers, 16 neurons, relu activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 56.42857142857143%\n",
      "Training with 2 hidden layers, 16 neurons, relu activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 54.69387755102041%\n",
      "Training with 2 hidden layers, 16 neurons, relu activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 55.204081632653065%\n",
      "Training with 2 hidden layers, 16 neurons, relu activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 54.48979591836735%\n",
      "Training with 2 hidden layers, 16 neurons, relu activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 56.326530612244895%\n",
      "Training with 2 hidden layers, 16 neurons, relu activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 50.61224489795919%\n",
      "Training with 2 hidden layers, 16 neurons, relu activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 51.224489795918366%\n",
      "Training with 2 hidden layers, 16 neurons, relu activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 51.326530612244895%\n",
      "Training with 2 hidden layers, 16 neurons, relu activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 58.265306122448976%\n",
      "Training with 2 hidden layers, 16 neurons, relu activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 54.89795918367347%\n",
      "Training with 2 hidden layers, 16 neurons, relu activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 54.89795918367347%\n",
      "Training with 2 hidden layers, 16 neurons, relu activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 53.775510204081634%\n",
      "Training with 2 hidden layers, 16 neurons, relu activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 54.183673469387756%\n",
      "Training with 2 hidden layers, 16 neurons, relu activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 56.63265306122449%\n",
      "Training with 2 hidden layers, 16 neurons, relu activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 54.183673469387756%\n",
      "Training with 2 hidden layers, 16 neurons, relu activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 53.87755102040816%\n",
      "Training with 2 hidden layers, 16 neurons, relu activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 52.857142857142854%\n",
      "Training with 2 hidden layers, 16 neurons, sigmoid activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 54.285714285714285%\n",
      "Training with 2 hidden layers, 16 neurons, sigmoid activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 52.755102040816325%\n",
      "Training with 2 hidden layers, 16 neurons, sigmoid activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 55.40816326530612%\n",
      "Training with 2 hidden layers, 16 neurons, sigmoid activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 52.6530612244898%\n",
      "Training with 2 hidden layers, 16 neurons, sigmoid activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 52.142857142857146%\n",
      "Training with 2 hidden layers, 16 neurons, sigmoid activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 52.244897959183675%\n",
      "Training with 2 hidden layers, 16 neurons, sigmoid activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 16 neurons, sigmoid activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 16 neurons, sigmoid activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 16 neurons, sigmoid activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 54.08163265306123%\n",
      "Training with 2 hidden layers, 16 neurons, sigmoid activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 55.204081632653065%\n",
      "Training with 2 hidden layers, 16 neurons, sigmoid activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 55.40816326530612%\n",
      "Training with 2 hidden layers, 16 neurons, sigmoid activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 52.95918367346939%\n",
      "Training with 2 hidden layers, 16 neurons, sigmoid activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 52.857142857142854%\n",
      "Training with 2 hidden layers, 16 neurons, sigmoid activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 52.95918367346939%\n",
      "Training with 2 hidden layers, 16 neurons, sigmoid activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 16 neurons, sigmoid activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 16 neurons, sigmoid activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 16 neurons, sigmoid activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 55.714285714285715%\n",
      "Training with 2 hidden layers, 16 neurons, sigmoid activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 53.673469387755105%\n",
      "Training with 2 hidden layers, 16 neurons, sigmoid activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 54.59183673469388%\n",
      "Training with 2 hidden layers, 16 neurons, sigmoid activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 53.57142857142857%\n",
      "Training with 2 hidden layers, 16 neurons, sigmoid activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 53.46938775510204%\n",
      "Training with 2 hidden layers, 16 neurons, sigmoid activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 54.38775510204081%\n",
      "Training with 2 hidden layers, 16 neurons, sigmoid activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 45.61224489795919%\n",
      "Training with 2 hidden layers, 16 neurons, sigmoid activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 47.857142857142854%\n",
      "Training with 2 hidden layers, 16 neurons, sigmoid activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 46.83673469387755%\n",
      "Training with 2 hidden layers, 16 neurons, tanh activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 55.51020408163265%\n",
      "Training with 2 hidden layers, 16 neurons, tanh activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 57.3469387755102%\n",
      "Training with 2 hidden layers, 16 neurons, tanh activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 56.224489795918366%\n",
      "Training with 2 hidden layers, 16 neurons, tanh activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 53.57142857142857%\n",
      "Training with 2 hidden layers, 16 neurons, tanh activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 52.857142857142854%\n",
      "Training with 2 hidden layers, 16 neurons, tanh activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 54.08163265306123%\n",
      "Training with 2 hidden layers, 16 neurons, tanh activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 48.46938775510204%\n",
      "Training with 2 hidden layers, 16 neurons, tanh activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 47.244897959183675%\n",
      "Training with 2 hidden layers, 16 neurons, tanh activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 51.326530612244895%\n",
      "Training with 2 hidden layers, 16 neurons, tanh activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 55.30612244897959%\n",
      "Training with 2 hidden layers, 16 neurons, tanh activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 55.204081632653065%\n",
      "Training with 2 hidden layers, 16 neurons, tanh activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 55.51020408163265%\n",
      "Training with 2 hidden layers, 16 neurons, tanh activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 55.0%\n",
      "Training with 2 hidden layers, 16 neurons, tanh activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 55.51020408163265%\n",
      "Training with 2 hidden layers, 16 neurons, tanh activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 54.285714285714285%\n",
      "Training with 2 hidden layers, 16 neurons, tanh activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 51.83673469387755%\n",
      "Training with 2 hidden layers, 16 neurons, tanh activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 52.6530612244898%\n",
      "Training with 2 hidden layers, 16 neurons, tanh activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 51.83673469387755%\n",
      "Training with 2 hidden layers, 16 neurons, tanh activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 55.10204081632653%\n",
      "Training with 2 hidden layers, 16 neurons, tanh activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 54.48979591836735%\n",
      "Training with 2 hidden layers, 16 neurons, tanh activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 56.326530612244895%\n",
      "Training with 2 hidden layers, 16 neurons, tanh activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 56.12244897959184%\n",
      "Training with 2 hidden layers, 16 neurons, tanh activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 55.0%\n",
      "Training with 2 hidden layers, 16 neurons, tanh activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 56.326530612244895%\n",
      "Training with 2 hidden layers, 16 neurons, tanh activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 52.3469387755102%\n",
      "Training with 2 hidden layers, 16 neurons, tanh activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 52.04081632653061%\n",
      "Training with 2 hidden layers, 16 neurons, tanh activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 52.244897959183675%\n",
      "Training with 2 hidden layers, 16 neurons, softmax activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 56.02040816326531%\n",
      "Training with 2 hidden layers, 16 neurons, softmax activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 56.42857142857143%\n",
      "Training with 2 hidden layers, 16 neurons, softmax activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 55.714285714285715%\n",
      "Training with 2 hidden layers, 16 neurons, softmax activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 48.97959183673469%\n",
      "Training with 2 hidden layers, 16 neurons, softmax activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 51.42857142857143%\n",
      "Training with 2 hidden layers, 16 neurons, softmax activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 51.63265306122449%\n",
      "Training with 2 hidden layers, 16 neurons, softmax activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 16 neurons, softmax activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 23.775510204081634%\n",
      "Training with 2 hidden layers, 16 neurons, softmax activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 16 neurons, softmax activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 55.204081632653065%\n",
      "Training with 2 hidden layers, 16 neurons, softmax activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 54.08163265306123%\n",
      "Training with 2 hidden layers, 16 neurons, softmax activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 56.63265306122449%\n",
      "Training with 2 hidden layers, 16 neurons, softmax activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 51.734693877551024%\n",
      "Training with 2 hidden layers, 16 neurons, softmax activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 51.734693877551024%\n",
      "Training with 2 hidden layers, 16 neurons, softmax activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 52.3469387755102%\n",
      "Training with 2 hidden layers, 16 neurons, softmax activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 16 neurons, softmax activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 16 neurons, softmax activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 16 neurons, softmax activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 56.326530612244895%\n",
      "Training with 2 hidden layers, 16 neurons, softmax activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 55.91836734693877%\n",
      "Training with 2 hidden layers, 16 neurons, softmax activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 54.89795918367347%\n",
      "Training with 2 hidden layers, 16 neurons, softmax activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 54.38775510204081%\n",
      "Training with 2 hidden layers, 16 neurons, softmax activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 54.795918367346935%\n",
      "Training with 2 hidden layers, 16 neurons, softmax activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 53.673469387755105%\n",
      "Training with 2 hidden layers, 16 neurons, softmax activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 16 neurons, softmax activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 16 neurons, softmax activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 32 neurons, relu activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 56.02040816326531%\n",
      "Training with 2 hidden layers, 32 neurons, relu activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 53.87755102040816%\n",
      "Training with 2 hidden layers, 32 neurons, relu activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 56.42857142857143%\n",
      "Training with 2 hidden layers, 32 neurons, relu activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 56.53061224489796%\n",
      "Training with 2 hidden layers, 32 neurons, relu activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 56.02040816326531%\n",
      "Training with 2 hidden layers, 32 neurons, relu activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 54.59183673469388%\n",
      "Training with 2 hidden layers, 32 neurons, relu activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 49.08163265306123%\n",
      "Training with 2 hidden layers, 32 neurons, relu activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 50.714285714285715%\n",
      "Training with 2 hidden layers, 32 neurons, relu activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 51.83673469387755%\n",
      "Training with 2 hidden layers, 32 neurons, relu activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 57.244897959183675%\n",
      "Training with 2 hidden layers, 32 neurons, relu activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 54.795918367346935%\n",
      "Training with 2 hidden layers, 32 neurons, relu activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 55.40816326530612%\n",
      "Training with 2 hidden layers, 32 neurons, relu activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 55.204081632653065%\n",
      "Training with 2 hidden layers, 32 neurons, relu activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 55.91836734693877%\n",
      "Training with 2 hidden layers, 32 neurons, relu activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 55.51020408163265%\n",
      "Training with 2 hidden layers, 32 neurons, relu activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 54.48979591836735%\n",
      "Training with 2 hidden layers, 32 neurons, relu activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 53.36734693877551%\n",
      "Training with 2 hidden layers, 32 neurons, relu activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 52.857142857142854%\n",
      "Training with 2 hidden layers, 32 neurons, relu activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 58.46938775510204%\n",
      "Training with 2 hidden layers, 32 neurons, relu activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 56.53061224489796%\n",
      "Training with 2 hidden layers, 32 neurons, relu activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 57.04081632653061%\n",
      "Training with 2 hidden layers, 32 neurons, relu activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 56.224489795918366%\n",
      "Training with 2 hidden layers, 32 neurons, relu activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 53.97959183673469%\n",
      "Training with 2 hidden layers, 32 neurons, relu activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 56.42857142857143%\n",
      "Training with 2 hidden layers, 32 neurons, relu activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 55.0%\n",
      "Training with 2 hidden layers, 32 neurons, relu activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 53.87755102040816%\n",
      "Training with 2 hidden layers, 32 neurons, relu activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 54.183673469387756%\n",
      "Training with 2 hidden layers, 32 neurons, sigmoid activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 53.775510204081634%\n",
      "Training with 2 hidden layers, 32 neurons, sigmoid activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 55.51020408163265%\n",
      "Training with 2 hidden layers, 32 neurons, sigmoid activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 55.10204081632653%\n",
      "Training with 2 hidden layers, 32 neurons, sigmoid activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 52.244897959183675%\n",
      "Training with 2 hidden layers, 32 neurons, sigmoid activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 51.734693877551024%\n",
      "Training with 2 hidden layers, 32 neurons, sigmoid activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 52.142857142857146%\n",
      "Training with 2 hidden layers, 32 neurons, sigmoid activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 32 neurons, sigmoid activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 32 neurons, sigmoid activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 32 neurons, sigmoid activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 55.816326530612244%\n",
      "Training with 2 hidden layers, 32 neurons, sigmoid activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 56.734693877551024%\n",
      "Training with 2 hidden layers, 32 neurons, sigmoid activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 56.42857142857143%\n",
      "Training with 2 hidden layers, 32 neurons, sigmoid activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 52.3469387755102%\n",
      "Training with 2 hidden layers, 32 neurons, sigmoid activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 53.06122448979592%\n",
      "Training with 2 hidden layers, 32 neurons, sigmoid activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 52.95918367346939%\n",
      "Training with 2 hidden layers, 32 neurons, sigmoid activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 45.30612244897959%\n",
      "Training with 2 hidden layers, 32 neurons, sigmoid activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 45.51020408163265%\n",
      "Training with 2 hidden layers, 32 neurons, sigmoid activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 47.44897959183673%\n",
      "Training with 2 hidden layers, 32 neurons, sigmoid activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 57.95918367346939%\n",
      "Training with 2 hidden layers, 32 neurons, sigmoid activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 58.16326530612245%\n",
      "Training with 2 hidden layers, 32 neurons, sigmoid activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 57.6530612244898%\n",
      "Training with 2 hidden layers, 32 neurons, sigmoid activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 54.183673469387756%\n",
      "Training with 2 hidden layers, 32 neurons, sigmoid activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 55.91836734693877%\n",
      "Training with 2 hidden layers, 32 neurons, sigmoid activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 55.30612244897959%\n",
      "Training with 2 hidden layers, 32 neurons, sigmoid activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 50.714285714285715%\n",
      "Training with 2 hidden layers, 32 neurons, sigmoid activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 51.224489795918366%\n",
      "Training with 2 hidden layers, 32 neurons, sigmoid activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 51.63265306122449%\n",
      "Training with 2 hidden layers, 32 neurons, tanh activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 56.83673469387755%\n",
      "Training with 2 hidden layers, 32 neurons, tanh activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 56.42857142857143%\n",
      "Training with 2 hidden layers, 32 neurons, tanh activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 54.89795918367347%\n",
      "Training with 2 hidden layers, 32 neurons, tanh activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 55.61224489795919%\n",
      "Training with 2 hidden layers, 32 neurons, tanh activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 55.204081632653065%\n",
      "Training with 2 hidden layers, 32 neurons, tanh activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 54.08163265306123%\n",
      "Training with 2 hidden layers, 32 neurons, tanh activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 51.326530612244895%\n",
      "Training with 2 hidden layers, 32 neurons, tanh activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 50.91836734693877%\n",
      "Training with 2 hidden layers, 32 neurons, tanh activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 51.53061224489796%\n",
      "Training with 2 hidden layers, 32 neurons, tanh activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 57.95918367346939%\n",
      "Training with 2 hidden layers, 32 neurons, tanh activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 55.91836734693877%\n",
      "Training with 2 hidden layers, 32 neurons, tanh activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 58.36734693877551%\n",
      "Training with 2 hidden layers, 32 neurons, tanh activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 55.30612244897959%\n",
      "Training with 2 hidden layers, 32 neurons, tanh activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 56.224489795918366%\n",
      "Training with 2 hidden layers, 32 neurons, tanh activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 55.51020408163265%\n",
      "Training with 2 hidden layers, 32 neurons, tanh activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 51.93877551020408%\n",
      "Training with 2 hidden layers, 32 neurons, tanh activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 51.326530612244895%\n",
      "Training with 2 hidden layers, 32 neurons, tanh activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 52.244897959183675%\n",
      "Training with 2 hidden layers, 32 neurons, tanh activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 57.755102040816325%\n",
      "Training with 2 hidden layers, 32 neurons, tanh activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 60.204081632653065%\n",
      "Training with 2 hidden layers, 32 neurons, tanh activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 57.55102040816327%\n",
      "Training with 2 hidden layers, 32 neurons, tanh activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 54.69387755102041%\n",
      "Training with 2 hidden layers, 32 neurons, tanh activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 55.91836734693877%\n",
      "Training with 2 hidden layers, 32 neurons, tanh activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 54.38775510204081%\n",
      "Training with 2 hidden layers, 32 neurons, tanh activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 52.55102040816327%\n",
      "Training with 2 hidden layers, 32 neurons, tanh activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 51.93877551020408%\n",
      "Training with 2 hidden layers, 32 neurons, tanh activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 53.06122448979592%\n",
      "Training with 2 hidden layers, 32 neurons, softmax activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 56.42857142857143%\n",
      "Training with 2 hidden layers, 32 neurons, softmax activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 55.0%\n",
      "Training with 2 hidden layers, 32 neurons, softmax activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 56.63265306122449%\n",
      "Training with 2 hidden layers, 32 neurons, softmax activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 51.02040816326531%\n",
      "Training with 2 hidden layers, 32 neurons, softmax activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 51.326530612244895%\n",
      "Training with 2 hidden layers, 32 neurons, softmax activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 51.734693877551024%\n",
      "Training with 2 hidden layers, 32 neurons, softmax activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 32 neurons, softmax activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 32 neurons, softmax activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 29.693877551020407%\n",
      "Training with 2 hidden layers, 32 neurons, softmax activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 56.02040816326531%\n",
      "Training with 2 hidden layers, 32 neurons, softmax activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 52.95918367346939%\n",
      "Training with 2 hidden layers, 32 neurons, softmax activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 56.93877551020408%\n",
      "Training with 2 hidden layers, 32 neurons, softmax activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 51.83673469387755%\n",
      "Training with 2 hidden layers, 32 neurons, softmax activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 50.91836734693877%\n",
      "Training with 2 hidden layers, 32 neurons, softmax activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 51.93877551020408%\n",
      "Training with 2 hidden layers, 32 neurons, softmax activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 32 neurons, softmax activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 32 neurons, softmax activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 32 neurons, softmax activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 56.53061224489796%\n",
      "Training with 2 hidden layers, 32 neurons, softmax activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 56.12244897959184%\n",
      "Training with 2 hidden layers, 32 neurons, softmax activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 55.51020408163265%\n",
      "Training with 2 hidden layers, 32 neurons, softmax activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 53.97959183673469%\n",
      "Training with 2 hidden layers, 32 neurons, softmax activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 53.97959183673469%\n",
      "Training with 2 hidden layers, 32 neurons, softmax activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 53.97959183673469%\n",
      "Training with 2 hidden layers, 32 neurons, softmax activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 32 neurons, softmax activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 32 neurons, softmax activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 64 neurons, relu activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 55.204081632653065%\n",
      "Training with 2 hidden layers, 64 neurons, relu activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 56.53061224489796%\n",
      "Training with 2 hidden layers, 64 neurons, relu activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 56.83673469387755%\n",
      "Training with 2 hidden layers, 64 neurons, relu activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 55.816326530612244%\n",
      "Training with 2 hidden layers, 64 neurons, relu activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 54.89795918367347%\n",
      "Training with 2 hidden layers, 64 neurons, relu activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 55.816326530612244%\n",
      "Training with 2 hidden layers, 64 neurons, relu activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 53.97959183673469%\n",
      "Training with 2 hidden layers, 64 neurons, relu activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 54.285714285714285%\n",
      "Training with 2 hidden layers, 64 neurons, relu activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 53.16326530612245%\n",
      "Training with 2 hidden layers, 64 neurons, relu activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 58.265306122448976%\n",
      "Training with 2 hidden layers, 64 neurons, relu activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 62.244897959183675%\n",
      "Training with 2 hidden layers, 64 neurons, relu activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 59.89795918367347%\n",
      "Training with 2 hidden layers, 64 neurons, relu activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 58.16326530612245%\n",
      "Training with 2 hidden layers, 64 neurons, relu activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 58.06122448979592%\n",
      "Training with 2 hidden layers, 64 neurons, relu activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 56.83673469387755%\n",
      "Training with 2 hidden layers, 64 neurons, relu activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 54.48979591836735%\n",
      "Training with 2 hidden layers, 64 neurons, relu activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 53.775510204081634%\n",
      "Training with 2 hidden layers, 64 neurons, relu activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 53.775510204081634%\n",
      "Training with 2 hidden layers, 64 neurons, relu activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 61.42857142857143%\n",
      "Training with 2 hidden layers, 64 neurons, relu activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 60.714285714285715%\n",
      "Training with 2 hidden layers, 64 neurons, relu activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 61.734693877551024%\n",
      "Training with 2 hidden layers, 64 neurons, relu activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 57.244897959183675%\n",
      "Training with 2 hidden layers, 64 neurons, relu activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 58.46938775510204%\n",
      "Training with 2 hidden layers, 64 neurons, relu activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 57.04081632653061%\n",
      "Training with 2 hidden layers, 64 neurons, relu activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 56.53061224489796%\n",
      "Training with 2 hidden layers, 64 neurons, relu activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 55.714285714285715%\n",
      "Training with 2 hidden layers, 64 neurons, relu activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 55.91836734693877%\n",
      "Training with 2 hidden layers, 64 neurons, sigmoid activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 56.93877551020408%\n",
      "Training with 2 hidden layers, 64 neurons, sigmoid activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 54.38775510204081%\n",
      "Training with 2 hidden layers, 64 neurons, sigmoid activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 55.30612244897959%\n",
      "Training with 2 hidden layers, 64 neurons, sigmoid activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 52.755102040816325%\n",
      "Training with 2 hidden layers, 64 neurons, sigmoid activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 52.04081632653061%\n",
      "Training with 2 hidden layers, 64 neurons, sigmoid activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 53.36734693877551%\n",
      "Training with 2 hidden layers, 64 neurons, sigmoid activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.48979591836735%\n",
      "Training with 2 hidden layers, 64 neurons, sigmoid activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.59183673469388%\n",
      "Training with 2 hidden layers, 64 neurons, sigmoid activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.285714285714285%\n",
      "Training with 2 hidden layers, 64 neurons, sigmoid activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 59.38775510204081%\n",
      "Training with 2 hidden layers, 64 neurons, sigmoid activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 57.44897959183673%\n",
      "Training with 2 hidden layers, 64 neurons, sigmoid activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 57.6530612244898%\n",
      "Training with 2 hidden layers, 64 neurons, sigmoid activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 54.08163265306123%\n",
      "Training with 2 hidden layers, 64 neurons, sigmoid activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 54.795918367346935%\n",
      "Training with 2 hidden layers, 64 neurons, sigmoid activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 53.97959183673469%\n",
      "Training with 2 hidden layers, 64 neurons, sigmoid activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 48.57142857142857%\n",
      "Training with 2 hidden layers, 64 neurons, sigmoid activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 50.10204081632653%\n",
      "Training with 2 hidden layers, 64 neurons, sigmoid activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 49.69387755102041%\n",
      "Training with 2 hidden layers, 64 neurons, sigmoid activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 62.55102040816327%\n",
      "Training with 2 hidden layers, 64 neurons, sigmoid activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 62.755102040816325%\n",
      "Training with 2 hidden layers, 64 neurons, sigmoid activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 63.36734693877551%\n",
      "Training with 2 hidden layers, 64 neurons, sigmoid activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 55.51020408163265%\n",
      "Training with 2 hidden layers, 64 neurons, sigmoid activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 56.224489795918366%\n",
      "Training with 2 hidden layers, 64 neurons, sigmoid activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 55.30612244897959%\n",
      "Training with 2 hidden layers, 64 neurons, sigmoid activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 51.63265306122449%\n",
      "Training with 2 hidden layers, 64 neurons, sigmoid activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 51.734693877551024%\n",
      "Training with 2 hidden layers, 64 neurons, sigmoid activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 52.244897959183675%\n",
      "Training with 2 hidden layers, 64 neurons, tanh activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 58.46938775510204%\n",
      "Training with 2 hidden layers, 64 neurons, tanh activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 58.06122448979592%\n",
      "Training with 2 hidden layers, 64 neurons, tanh activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 55.91836734693877%\n",
      "Training with 2 hidden layers, 64 neurons, tanh activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 55.714285714285715%\n",
      "Training with 2 hidden layers, 64 neurons, tanh activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 56.12244897959184%\n",
      "Training with 2 hidden layers, 64 neurons, tanh activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 55.40816326530612%\n",
      "Training with 2 hidden layers, 64 neurons, tanh activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 51.53061224489796%\n",
      "Training with 2 hidden layers, 64 neurons, tanh activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 52.142857142857146%\n",
      "Training with 2 hidden layers, 64 neurons, tanh activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 51.93877551020408%\n",
      "Training with 2 hidden layers, 64 neurons, tanh activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 61.12244897959184%\n",
      "Training with 2 hidden layers, 64 neurons, tanh activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 60.61224489795919%\n",
      "Training with 2 hidden layers, 64 neurons, tanh activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 59.59183673469388%\n",
      "Training with 2 hidden layers, 64 neurons, tanh activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 55.61224489795919%\n",
      "Training with 2 hidden layers, 64 neurons, tanh activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 56.63265306122449%\n",
      "Training with 2 hidden layers, 64 neurons, tanh activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 56.326530612244895%\n",
      "Training with 2 hidden layers, 64 neurons, tanh activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 51.326530612244895%\n",
      "Training with 2 hidden layers, 64 neurons, tanh activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 52.6530612244898%\n",
      "Training with 2 hidden layers, 64 neurons, tanh activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 53.265306122448976%\n",
      "Training with 2 hidden layers, 64 neurons, tanh activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 63.673469387755105%\n",
      "Training with 2 hidden layers, 64 neurons, tanh activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 63.265306122448976%\n",
      "Training with 2 hidden layers, 64 neurons, tanh activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 62.44897959183673%\n",
      "Training with 2 hidden layers, 64 neurons, tanh activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 54.59183673469388%\n",
      "Training with 2 hidden layers, 64 neurons, tanh activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 57.6530612244898%\n",
      "Training with 2 hidden layers, 64 neurons, tanh activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 56.42857142857143%\n",
      "Training with 2 hidden layers, 64 neurons, tanh activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 53.775510204081634%\n",
      "Training with 2 hidden layers, 64 neurons, tanh activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 53.57142857142857%\n",
      "Training with 2 hidden layers, 64 neurons, tanh activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 53.673469387755105%\n",
      "Training with 2 hidden layers, 64 neurons, softmax activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 56.42857142857143%\n",
      "Training with 2 hidden layers, 64 neurons, softmax activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 55.30612244897959%\n",
      "Training with 2 hidden layers, 64 neurons, softmax activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 57.142857142857146%\n",
      "Training with 2 hidden layers, 64 neurons, softmax activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 51.63265306122449%\n",
      "Training with 2 hidden layers, 64 neurons, softmax activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 50.714285714285715%\n",
      "Training with 2 hidden layers, 64 neurons, softmax activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 51.02040816326531%\n",
      "Training with 2 hidden layers, 64 neurons, softmax activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 29.693877551020407%\n",
      "Training with 2 hidden layers, 64 neurons, softmax activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 64 neurons, softmax activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 64 neurons, softmax activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 55.0%\n",
      "Training with 2 hidden layers, 64 neurons, softmax activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 56.63265306122449%\n",
      "Training with 2 hidden layers, 64 neurons, softmax activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 56.734693877551024%\n",
      "Training with 2 hidden layers, 64 neurons, softmax activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 53.775510204081634%\n",
      "Training with 2 hidden layers, 64 neurons, softmax activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 52.755102040816325%\n",
      "Training with 2 hidden layers, 64 neurons, softmax activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 53.46938775510204%\n",
      "Training with 2 hidden layers, 64 neurons, softmax activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 29.693877551020407%\n",
      "Training with 2 hidden layers, 64 neurons, softmax activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 64 neurons, softmax activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 64 neurons, softmax activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 58.673469387755105%\n",
      "Training with 2 hidden layers, 64 neurons, softmax activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 57.04081632653061%\n",
      "Training with 2 hidden layers, 64 neurons, softmax activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 57.44897959183673%\n",
      "Training with 2 hidden layers, 64 neurons, softmax activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 55.91836734693877%\n",
      "Training with 2 hidden layers, 64 neurons, softmax activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 54.183673469387756%\n",
      "Training with 2 hidden layers, 64 neurons, softmax activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 53.97959183673469%\n",
      "Training with 2 hidden layers, 64 neurons, softmax activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 64 neurons, softmax activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 2 hidden layers, 64 neurons, softmax activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 4 neurons, relu activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 48.36734693877551%\n",
      "Training with 3 hidden layers, 4 neurons, relu activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 52.95918367346939%\n",
      "Training with 3 hidden layers, 4 neurons, relu activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 4 neurons, relu activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 50.714285714285715%\n",
      "Training with 3 hidden layers, 4 neurons, relu activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 52.142857142857146%\n",
      "Training with 3 hidden layers, 4 neurons, relu activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 50.91836734693877%\n",
      "Training with 3 hidden layers, 4 neurons, relu activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 0.0%\n",
      "Training with 3 hidden layers, 4 neurons, relu activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 29.693877551020407%\n",
      "Training with 3 hidden layers, 4 neurons, relu activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 4 neurons, relu activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 53.775510204081634%\n",
      "Training with 3 hidden layers, 4 neurons, relu activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 53.673469387755105%\n",
      "Training with 3 hidden layers, 4 neurons, relu activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 53.775510204081634%\n",
      "Training with 3 hidden layers, 4 neurons, relu activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 52.3469387755102%\n",
      "Training with 3 hidden layers, 4 neurons, relu activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 50.51020408163265%\n",
      "Training with 3 hidden layers, 4 neurons, relu activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 52.95918367346939%\n",
      "Training with 3 hidden layers, 4 neurons, relu activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 45.61224489795919%\n",
      "Training with 3 hidden layers, 4 neurons, relu activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 4 neurons, relu activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.48979591836735%\n",
      "Training with 3 hidden layers, 4 neurons, relu activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 52.44897959183673%\n",
      "Training with 3 hidden layers, 4 neurons, relu activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 53.673469387755105%\n",
      "Training with 3 hidden layers, 4 neurons, relu activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 54.48979591836735%\n",
      "Training with 3 hidden layers, 4 neurons, relu activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 53.46938775510204%\n",
      "Training with 3 hidden layers, 4 neurons, relu activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 53.57142857142857%\n",
      "Training with 3 hidden layers, 4 neurons, relu activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 52.3469387755102%\n",
      "Training with 3 hidden layers, 4 neurons, relu activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 48.673469387755105%\n",
      "Training with 3 hidden layers, 4 neurons, relu activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 4 neurons, relu activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 4 neurons, sigmoid activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 52.55102040816327%\n",
      "Training with 3 hidden layers, 4 neurons, sigmoid activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 53.46938775510204%\n",
      "Training with 3 hidden layers, 4 neurons, sigmoid activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 52.95918367346939%\n",
      "Training with 3 hidden layers, 4 neurons, sigmoid activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 4 neurons, sigmoid activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 4 neurons, sigmoid activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 4 neurons, sigmoid activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 4 neurons, sigmoid activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 29.693877551020407%\n",
      "Training with 3 hidden layers, 4 neurons, sigmoid activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 29.693877551020407%\n",
      "Training with 3 hidden layers, 4 neurons, sigmoid activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 53.46938775510204%\n",
      "Training with 3 hidden layers, 4 neurons, sigmoid activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 53.775510204081634%\n",
      "Training with 3 hidden layers, 4 neurons, sigmoid activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 53.673469387755105%\n",
      "Training with 3 hidden layers, 4 neurons, sigmoid activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 50.40816326530612%\n",
      "Training with 3 hidden layers, 4 neurons, sigmoid activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 4 neurons, sigmoid activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 4 neurons, sigmoid activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 4 neurons, sigmoid activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 4 neurons, sigmoid activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 4 neurons, sigmoid activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 54.183673469387756%\n",
      "Training with 3 hidden layers, 4 neurons, sigmoid activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 53.265306122448976%\n",
      "Training with 3 hidden layers, 4 neurons, sigmoid activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 53.97959183673469%\n",
      "Training with 3 hidden layers, 4 neurons, sigmoid activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 51.12244897959184%\n",
      "Training with 3 hidden layers, 4 neurons, sigmoid activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 50.816326530612244%\n",
      "Training with 3 hidden layers, 4 neurons, sigmoid activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 52.95918367346939%\n",
      "Training with 3 hidden layers, 4 neurons, sigmoid activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 4 neurons, sigmoid activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 4 neurons, sigmoid activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 4 neurons, tanh activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 53.16326530612245%\n",
      "Training with 3 hidden layers, 4 neurons, tanh activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 53.36734693877551%\n",
      "Training with 3 hidden layers, 4 neurons, tanh activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 53.36734693877551%\n",
      "Training with 3 hidden layers, 4 neurons, tanh activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 53.46938775510204%\n",
      "Training with 3 hidden layers, 4 neurons, tanh activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 51.224489795918366%\n",
      "Training with 3 hidden layers, 4 neurons, tanh activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 54.08163265306123%\n",
      "Training with 3 hidden layers, 4 neurons, tanh activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 4 neurons, tanh activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 19.591836734693878%\n",
      "Training with 3 hidden layers, 4 neurons, tanh activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 30.306122448979593%\n",
      "Training with 3 hidden layers, 4 neurons, tanh activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 54.183673469387756%\n",
      "Training with 3 hidden layers, 4 neurons, tanh activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 55.10204081632653%\n",
      "Training with 3 hidden layers, 4 neurons, tanh activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 55.204081632653065%\n",
      "Training with 3 hidden layers, 4 neurons, tanh activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 53.87755102040816%\n",
      "Training with 3 hidden layers, 4 neurons, tanh activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 53.775510204081634%\n",
      "Training with 3 hidden layers, 4 neurons, tanh activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 53.97959183673469%\n",
      "Training with 3 hidden layers, 4 neurons, tanh activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 4 neurons, tanh activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 29.693877551020407%\n",
      "Training with 3 hidden layers, 4 neurons, tanh activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 31.836734693877553%\n",
      "Training with 3 hidden layers, 4 neurons, tanh activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 53.87755102040816%\n",
      "Training with 3 hidden layers, 4 neurons, tanh activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 53.97959183673469%\n",
      "Training with 3 hidden layers, 4 neurons, tanh activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 53.673469387755105%\n",
      "Training with 3 hidden layers, 4 neurons, tanh activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 53.97959183673469%\n",
      "Training with 3 hidden layers, 4 neurons, tanh activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 53.57142857142857%\n",
      "Training with 3 hidden layers, 4 neurons, tanh activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 54.69387755102041%\n",
      "Training with 3 hidden layers, 4 neurons, tanh activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 4 neurons, tanh activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 45.30612244897959%\n",
      "Training with 3 hidden layers, 4 neurons, tanh activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 50.51020408163265%\n",
      "Training with 3 hidden layers, 4 neurons, softmax activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 52.55102040816327%\n",
      "Training with 3 hidden layers, 4 neurons, softmax activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 54.183673469387756%\n",
      "Training with 3 hidden layers, 4 neurons, softmax activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 52.6530612244898%\n",
      "Training with 3 hidden layers, 4 neurons, softmax activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 51.63265306122449%\n",
      "Training with 3 hidden layers, 4 neurons, softmax activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 4 neurons, softmax activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 4 neurons, softmax activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 0.0%\n",
      "Training with 3 hidden layers, 4 neurons, softmax activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 0.0%\n",
      "Training with 3 hidden layers, 4 neurons, softmax activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 29.693877551020407%\n",
      "Training with 3 hidden layers, 4 neurons, softmax activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 53.36734693877551%\n",
      "Training with 3 hidden layers, 4 neurons, softmax activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 53.57142857142857%\n",
      "Training with 3 hidden layers, 4 neurons, softmax activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 53.36734693877551%\n",
      "Training with 3 hidden layers, 4 neurons, softmax activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 51.42857142857143%\n",
      "Training with 3 hidden layers, 4 neurons, softmax activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 47.142857142857146%\n",
      "Training with 3 hidden layers, 4 neurons, softmax activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 50.91836734693877%\n",
      "Training with 3 hidden layers, 4 neurons, softmax activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 4 neurons, softmax activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 4 neurons, softmax activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 4 neurons, softmax activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 53.673469387755105%\n",
      "Training with 3 hidden layers, 4 neurons, softmax activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 53.775510204081634%\n",
      "Training with 3 hidden layers, 4 neurons, softmax activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 53.673469387755105%\n",
      "Training with 3 hidden layers, 4 neurons, softmax activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 52.3469387755102%\n",
      "Training with 3 hidden layers, 4 neurons, softmax activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 4 neurons, softmax activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 51.83673469387755%\n",
      "Training with 3 hidden layers, 4 neurons, softmax activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 4 neurons, softmax activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 4 neurons, softmax activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 8 neurons, relu activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 54.59183673469388%\n",
      "Training with 3 hidden layers, 8 neurons, relu activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 54.89795918367347%\n",
      "Training with 3 hidden layers, 8 neurons, relu activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 53.87755102040816%\n",
      "Training with 3 hidden layers, 8 neurons, relu activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 54.285714285714285%\n",
      "Training with 3 hidden layers, 8 neurons, relu activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 52.755102040816325%\n",
      "Training with 3 hidden layers, 8 neurons, relu activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 53.46938775510204%\n",
      "Training with 3 hidden layers, 8 neurons, relu activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 46.02040816326531%\n",
      "Training with 3 hidden layers, 8 neurons, relu activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 45.91836734693877%\n",
      "Training with 3 hidden layers, 8 neurons, relu activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 42.55102040816327%\n",
      "Training with 3 hidden layers, 8 neurons, relu activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 55.61224489795919%\n",
      "Training with 3 hidden layers, 8 neurons, relu activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 53.97959183673469%\n",
      "Training with 3 hidden layers, 8 neurons, relu activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 53.673469387755105%\n",
      "Training with 3 hidden layers, 8 neurons, relu activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 52.6530612244898%\n",
      "Training with 3 hidden layers, 8 neurons, relu activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 53.673469387755105%\n",
      "Training with 3 hidden layers, 8 neurons, relu activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 53.97959183673469%\n",
      "Training with 3 hidden layers, 8 neurons, relu activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 46.63265306122449%\n",
      "Training with 3 hidden layers, 8 neurons, relu activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 46.53061224489796%\n",
      "Training with 3 hidden layers, 8 neurons, relu activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 46.12244897959184%\n",
      "Training with 3 hidden layers, 8 neurons, relu activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 54.38775510204081%\n",
      "Training with 3 hidden layers, 8 neurons, relu activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 54.89795918367347%\n",
      "Training with 3 hidden layers, 8 neurons, relu activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 54.795918367346935%\n",
      "Training with 3 hidden layers, 8 neurons, relu activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 55.204081632653065%\n",
      "Training with 3 hidden layers, 8 neurons, relu activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 55.30612244897959%\n",
      "Training with 3 hidden layers, 8 neurons, relu activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 55.714285714285715%\n",
      "Training with 3 hidden layers, 8 neurons, relu activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 51.53061224489796%\n",
      "Training with 3 hidden layers, 8 neurons, relu activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 51.83673469387755%\n",
      "Training with 3 hidden layers, 8 neurons, relu activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 53.16326530612245%\n",
      "Training with 3 hidden layers, 8 neurons, sigmoid activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 53.265306122448976%\n",
      "Training with 3 hidden layers, 8 neurons, sigmoid activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 52.44897959183673%\n",
      "Training with 3 hidden layers, 8 neurons, sigmoid activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 52.95918367346939%\n",
      "Training with 3 hidden layers, 8 neurons, sigmoid activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 50.30612244897959%\n",
      "Training with 3 hidden layers, 8 neurons, sigmoid activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 8 neurons, sigmoid activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 50.61224489795919%\n",
      "Training with 3 hidden layers, 8 neurons, sigmoid activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 8 neurons, sigmoid activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 19.591836734693878%\n",
      "Training with 3 hidden layers, 8 neurons, sigmoid activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 8 neurons, sigmoid activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 54.59183673469388%\n",
      "Training with 3 hidden layers, 8 neurons, sigmoid activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 55.204081632653065%\n",
      "Training with 3 hidden layers, 8 neurons, sigmoid activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 55.91836734693877%\n",
      "Training with 3 hidden layers, 8 neurons, sigmoid activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 50.91836734693877%\n",
      "Training with 3 hidden layers, 8 neurons, sigmoid activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 49.285714285714285%\n",
      "Training with 3 hidden layers, 8 neurons, sigmoid activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 51.12244897959184%\n",
      "Training with 3 hidden layers, 8 neurons, sigmoid activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 8 neurons, sigmoid activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 8 neurons, sigmoid activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 8 neurons, sigmoid activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 54.48979591836735%\n",
      "Training with 3 hidden layers, 8 neurons, sigmoid activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 56.42857142857143%\n",
      "Training with 3 hidden layers, 8 neurons, sigmoid activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 54.59183673469388%\n",
      "Training with 3 hidden layers, 8 neurons, sigmoid activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 53.265306122448976%\n",
      "Training with 3 hidden layers, 8 neurons, sigmoid activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 53.673469387755105%\n",
      "Training with 3 hidden layers, 8 neurons, sigmoid activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 52.857142857142854%\n",
      "Training with 3 hidden layers, 8 neurons, sigmoid activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 8 neurons, sigmoid activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 8 neurons, sigmoid activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 8 neurons, tanh activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 54.69387755102041%\n",
      "Training with 3 hidden layers, 8 neurons, tanh activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 54.183673469387756%\n",
      "Training with 3 hidden layers, 8 neurons, tanh activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 55.10204081632653%\n",
      "Training with 3 hidden layers, 8 neurons, tanh activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 52.6530612244898%\n",
      "Training with 3 hidden layers, 8 neurons, tanh activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 52.857142857142854%\n",
      "Training with 3 hidden layers, 8 neurons, tanh activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 53.36734693877551%\n",
      "Training with 3 hidden layers, 8 neurons, tanh activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.795918367346935%\n",
      "Training with 3 hidden layers, 8 neurons, tanh activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 8 neurons, tanh activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 47.6530612244898%\n",
      "Training with 3 hidden layers, 8 neurons, tanh activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 55.91836734693877%\n",
      "Training with 3 hidden layers, 8 neurons, tanh activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 55.51020408163265%\n",
      "Training with 3 hidden layers, 8 neurons, tanh activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 54.48979591836735%\n",
      "Training with 3 hidden layers, 8 neurons, tanh activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 55.61224489795919%\n",
      "Training with 3 hidden layers, 8 neurons, tanh activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 53.57142857142857%\n",
      "Training with 3 hidden layers, 8 neurons, tanh activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 54.89795918367347%\n",
      "Training with 3 hidden layers, 8 neurons, tanh activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 50.204081632653065%\n",
      "Training with 3 hidden layers, 8 neurons, tanh activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 8 neurons, tanh activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.69387755102041%\n",
      "Training with 3 hidden layers, 8 neurons, tanh activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 55.61224489795919%\n",
      "Training with 3 hidden layers, 8 neurons, tanh activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 53.87755102040816%\n",
      "Training with 3 hidden layers, 8 neurons, tanh activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 55.30612244897959%\n",
      "Training with 3 hidden layers, 8 neurons, tanh activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 54.795918367346935%\n",
      "Training with 3 hidden layers, 8 neurons, tanh activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 53.97959183673469%\n",
      "Training with 3 hidden layers, 8 neurons, tanh activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 56.63265306122449%\n",
      "Training with 3 hidden layers, 8 neurons, tanh activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 49.795918367346935%\n",
      "Training with 3 hidden layers, 8 neurons, tanh activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 51.224489795918366%\n",
      "Training with 3 hidden layers, 8 neurons, tanh activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 51.02040816326531%\n",
      "Training with 3 hidden layers, 8 neurons, softmax activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 55.91836734693877%\n",
      "Training with 3 hidden layers, 8 neurons, softmax activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 53.673469387755105%\n",
      "Training with 3 hidden layers, 8 neurons, softmax activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 52.3469387755102%\n",
      "Training with 3 hidden layers, 8 neurons, softmax activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 8 neurons, softmax activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 8 neurons, softmax activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 8 neurons, softmax activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 8 neurons, softmax activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 8 neurons, softmax activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 29.693877551020407%\n",
      "Training with 3 hidden layers, 8 neurons, softmax activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 56.12244897959184%\n",
      "Training with 3 hidden layers, 8 neurons, softmax activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 53.87755102040816%\n",
      "Training with 3 hidden layers, 8 neurons, softmax activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 55.51020408163265%\n",
      "Training with 3 hidden layers, 8 neurons, softmax activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 51.02040816326531%\n",
      "Training with 3 hidden layers, 8 neurons, softmax activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 48.57142857142857%\n",
      "Training with 3 hidden layers, 8 neurons, softmax activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 50.61224489795919%\n",
      "Training with 3 hidden layers, 8 neurons, softmax activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 29.693877551020407%\n",
      "Training with 3 hidden layers, 8 neurons, softmax activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 29.693877551020407%\n",
      "Training with 3 hidden layers, 8 neurons, softmax activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 8 neurons, softmax activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 55.816326530612244%\n",
      "Training with 3 hidden layers, 8 neurons, softmax activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 56.734693877551024%\n",
      "Training with 3 hidden layers, 8 neurons, softmax activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 54.48979591836735%\n",
      "Training with 3 hidden layers, 8 neurons, softmax activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 53.06122448979592%\n",
      "Training with 3 hidden layers, 8 neurons, softmax activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 51.12244897959184%\n",
      "Training with 3 hidden layers, 8 neurons, softmax activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 51.734693877551024%\n",
      "Training with 3 hidden layers, 8 neurons, softmax activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 8 neurons, softmax activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 8 neurons, softmax activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 16 neurons, relu activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 55.51020408163265%\n",
      "Training with 3 hidden layers, 16 neurons, relu activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 53.673469387755105%\n",
      "Training with 3 hidden layers, 16 neurons, relu activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 55.91836734693877%\n",
      "Training with 3 hidden layers, 16 neurons, relu activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 53.673469387755105%\n",
      "Training with 3 hidden layers, 16 neurons, relu activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 54.59183673469388%\n",
      "Training with 3 hidden layers, 16 neurons, relu activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 55.0%\n",
      "Training with 3 hidden layers, 16 neurons, relu activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 49.38775510204081%\n",
      "Training with 3 hidden layers, 16 neurons, relu activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.69387755102041%\n",
      "Training with 3 hidden layers, 16 neurons, relu activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.48979591836735%\n",
      "Training with 3 hidden layers, 16 neurons, relu activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 54.08163265306123%\n",
      "Training with 3 hidden layers, 16 neurons, relu activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 54.795918367346935%\n",
      "Training with 3 hidden layers, 16 neurons, relu activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 54.59183673469388%\n",
      "Training with 3 hidden layers, 16 neurons, relu activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 55.61224489795919%\n",
      "Training with 3 hidden layers, 16 neurons, relu activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 54.795918367346935%\n",
      "Training with 3 hidden layers, 16 neurons, relu activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 56.53061224489796%\n",
      "Training with 3 hidden layers, 16 neurons, relu activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 51.734693877551024%\n",
      "Training with 3 hidden layers, 16 neurons, relu activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 51.93877551020408%\n",
      "Training with 3 hidden layers, 16 neurons, relu activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 50.204081632653065%\n",
      "Training with 3 hidden layers, 16 neurons, relu activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 52.857142857142854%\n",
      "Training with 3 hidden layers, 16 neurons, relu activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 54.285714285714285%\n",
      "Training with 3 hidden layers, 16 neurons, relu activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 53.57142857142857%\n",
      "Training with 3 hidden layers, 16 neurons, relu activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 55.91836734693877%\n",
      "Training with 3 hidden layers, 16 neurons, relu activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 56.63265306122449%\n",
      "Training with 3 hidden layers, 16 neurons, relu activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 56.12244897959184%\n",
      "Training with 3 hidden layers, 16 neurons, relu activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 53.16326530612245%\n",
      "Training with 3 hidden layers, 16 neurons, relu activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 53.673469387755105%\n",
      "Training with 3 hidden layers, 16 neurons, relu activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 54.795918367346935%\n",
      "Training with 3 hidden layers, 16 neurons, sigmoid activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 55.30612244897959%\n",
      "Training with 3 hidden layers, 16 neurons, sigmoid activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 54.48979591836735%\n",
      "Training with 3 hidden layers, 16 neurons, sigmoid activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 55.714285714285715%\n",
      "Training with 3 hidden layers, 16 neurons, sigmoid activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 16 neurons, sigmoid activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 50.816326530612244%\n",
      "Training with 3 hidden layers, 16 neurons, sigmoid activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 50.204081632653065%\n",
      "Training with 3 hidden layers, 16 neurons, sigmoid activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 16 neurons, sigmoid activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 16 neurons, sigmoid activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 16 neurons, sigmoid activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 56.42857142857143%\n",
      "Training with 3 hidden layers, 16 neurons, sigmoid activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 55.714285714285715%\n",
      "Training with 3 hidden layers, 16 neurons, sigmoid activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 55.51020408163265%\n",
      "Training with 3 hidden layers, 16 neurons, sigmoid activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 53.673469387755105%\n",
      "Training with 3 hidden layers, 16 neurons, sigmoid activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 52.44897959183673%\n",
      "Training with 3 hidden layers, 16 neurons, sigmoid activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 52.95918367346939%\n",
      "Training with 3 hidden layers, 16 neurons, sigmoid activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 16 neurons, sigmoid activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 16 neurons, sigmoid activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 16 neurons, sigmoid activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 56.224489795918366%\n",
      "Training with 3 hidden layers, 16 neurons, sigmoid activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 54.59183673469388%\n",
      "Training with 3 hidden layers, 16 neurons, sigmoid activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 55.51020408163265%\n",
      "Training with 3 hidden layers, 16 neurons, sigmoid activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 54.38775510204081%\n",
      "Training with 3 hidden layers, 16 neurons, sigmoid activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 54.285714285714285%\n",
      "Training with 3 hidden layers, 16 neurons, sigmoid activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 53.46938775510204%\n",
      "Training with 3 hidden layers, 16 neurons, sigmoid activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 16 neurons, sigmoid activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 16 neurons, sigmoid activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 16 neurons, tanh activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 56.83673469387755%\n",
      "Training with 3 hidden layers, 16 neurons, tanh activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 56.734693877551024%\n",
      "Training with 3 hidden layers, 16 neurons, tanh activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 55.61224489795919%\n",
      "Training with 3 hidden layers, 16 neurons, tanh activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 54.795918367346935%\n",
      "Training with 3 hidden layers, 16 neurons, tanh activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 55.0%\n",
      "Training with 3 hidden layers, 16 neurons, tanh activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 54.08163265306123%\n",
      "Training with 3 hidden layers, 16 neurons, tanh activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 51.02040816326531%\n",
      "Training with 3 hidden layers, 16 neurons, tanh activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 48.87755102040816%\n",
      "Training with 3 hidden layers, 16 neurons, tanh activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 48.16326530612245%\n",
      "Training with 3 hidden layers, 16 neurons, tanh activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 56.42857142857143%\n",
      "Training with 3 hidden layers, 16 neurons, tanh activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 58.265306122448976%\n",
      "Training with 3 hidden layers, 16 neurons, tanh activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 56.734693877551024%\n",
      "Training with 3 hidden layers, 16 neurons, tanh activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 54.795918367346935%\n",
      "Training with 3 hidden layers, 16 neurons, tanh activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 54.59183673469388%\n",
      "Training with 3 hidden layers, 16 neurons, tanh activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 55.10204081632653%\n",
      "Training with 3 hidden layers, 16 neurons, tanh activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 50.51020408163265%\n",
      "Training with 3 hidden layers, 16 neurons, tanh activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 50.91836734693877%\n",
      "Training with 3 hidden layers, 16 neurons, tanh activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 51.83673469387755%\n",
      "Training with 3 hidden layers, 16 neurons, tanh activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 57.244897959183675%\n",
      "Training with 3 hidden layers, 16 neurons, tanh activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 56.83673469387755%\n",
      "Training with 3 hidden layers, 16 neurons, tanh activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 57.142857142857146%\n",
      "Training with 3 hidden layers, 16 neurons, tanh activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 56.326530612244895%\n",
      "Training with 3 hidden layers, 16 neurons, tanh activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 56.02040816326531%\n",
      "Training with 3 hidden layers, 16 neurons, tanh activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 55.91836734693877%\n",
      "Training with 3 hidden layers, 16 neurons, tanh activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 51.83673469387755%\n",
      "Training with 3 hidden layers, 16 neurons, tanh activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 52.6530612244898%\n",
      "Training with 3 hidden layers, 16 neurons, tanh activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 52.142857142857146%\n",
      "Training with 3 hidden layers, 16 neurons, softmax activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 55.204081632653065%\n",
      "Training with 3 hidden layers, 16 neurons, softmax activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 55.0%\n",
      "Training with 3 hidden layers, 16 neurons, softmax activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 55.51020408163265%\n",
      "Training with 3 hidden layers, 16 neurons, softmax activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 50.61224489795919%\n",
      "Training with 3 hidden layers, 16 neurons, softmax activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 16 neurons, softmax activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 16 neurons, softmax activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 29.693877551020407%\n",
      "Training with 3 hidden layers, 16 neurons, softmax activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 19.591836734693878%\n",
      "Training with 3 hidden layers, 16 neurons, softmax activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 16 neurons, softmax activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 56.42857142857143%\n",
      "Training with 3 hidden layers, 16 neurons, softmax activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 56.224489795918366%\n",
      "Training with 3 hidden layers, 16 neurons, softmax activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 56.83673469387755%\n",
      "Training with 3 hidden layers, 16 neurons, softmax activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 51.83673469387755%\n",
      "Training with 3 hidden layers, 16 neurons, softmax activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 51.224489795918366%\n",
      "Training with 3 hidden layers, 16 neurons, softmax activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 51.224489795918366%\n",
      "Training with 3 hidden layers, 16 neurons, softmax activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 29.693877551020407%\n",
      "Training with 3 hidden layers, 16 neurons, softmax activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 16 neurons, softmax activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 16 neurons, softmax activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 55.91836734693877%\n",
      "Training with 3 hidden layers, 16 neurons, softmax activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 55.40816326530612%\n",
      "Training with 3 hidden layers, 16 neurons, softmax activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 56.93877551020408%\n",
      "Training with 3 hidden layers, 16 neurons, softmax activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 53.06122448979592%\n",
      "Training with 3 hidden layers, 16 neurons, softmax activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 51.734693877551024%\n",
      "Training with 3 hidden layers, 16 neurons, softmax activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 52.55102040816327%\n",
      "Training with 3 hidden layers, 16 neurons, softmax activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 16 neurons, softmax activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 16 neurons, softmax activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 32 neurons, relu activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 57.142857142857146%\n",
      "Training with 3 hidden layers, 32 neurons, relu activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 54.183673469387756%\n",
      "Training with 3 hidden layers, 32 neurons, relu activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 55.51020408163265%\n",
      "Training with 3 hidden layers, 32 neurons, relu activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 56.02040816326531%\n",
      "Training with 3 hidden layers, 32 neurons, relu activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 57.04081632653061%\n",
      "Training with 3 hidden layers, 32 neurons, relu activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 54.285714285714285%\n",
      "Training with 3 hidden layers, 32 neurons, relu activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 53.57142857142857%\n",
      "Training with 3 hidden layers, 32 neurons, relu activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 52.857142857142854%\n",
      "Training with 3 hidden layers, 32 neurons, relu activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 52.142857142857146%\n",
      "Training with 3 hidden layers, 32 neurons, relu activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 57.857142857142854%\n",
      "Training with 3 hidden layers, 32 neurons, relu activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 55.816326530612244%\n",
      "Training with 3 hidden layers, 32 neurons, relu activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 57.95918367346939%\n",
      "Training with 3 hidden layers, 32 neurons, relu activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 56.12244897959184%\n",
      "Training with 3 hidden layers, 32 neurons, relu activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 56.53061224489796%\n",
      "Training with 3 hidden layers, 32 neurons, relu activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 55.204081632653065%\n",
      "Training with 3 hidden layers, 32 neurons, relu activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 52.142857142857146%\n",
      "Training with 3 hidden layers, 32 neurons, relu activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 53.46938775510204%\n",
      "Training with 3 hidden layers, 32 neurons, relu activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 54.38775510204081%\n",
      "Training with 3 hidden layers, 32 neurons, relu activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 56.224489795918366%\n",
      "Training with 3 hidden layers, 32 neurons, relu activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 57.3469387755102%\n",
      "Training with 3 hidden layers, 32 neurons, relu activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 60.10204081632653%\n",
      "Training with 3 hidden layers, 32 neurons, relu activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 56.326530612244895%\n",
      "Training with 3 hidden layers, 32 neurons, relu activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 57.244897959183675%\n",
      "Training with 3 hidden layers, 32 neurons, relu activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 57.44897959183673%\n",
      "Training with 3 hidden layers, 32 neurons, relu activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 55.61224489795919%\n",
      "Training with 3 hidden layers, 32 neurons, relu activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 55.30612244897959%\n",
      "Training with 3 hidden layers, 32 neurons, relu activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 54.795918367346935%\n",
      "Training with 3 hidden layers, 32 neurons, sigmoid activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 54.795918367346935%\n",
      "Training with 3 hidden layers, 32 neurons, sigmoid activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 54.183673469387756%\n",
      "Training with 3 hidden layers, 32 neurons, sigmoid activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 52.6530612244898%\n",
      "Training with 3 hidden layers, 32 neurons, sigmoid activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 52.142857142857146%\n",
      "Training with 3 hidden layers, 32 neurons, sigmoid activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 51.63265306122449%\n",
      "Training with 3 hidden layers, 32 neurons, sigmoid activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 52.3469387755102%\n",
      "Training with 3 hidden layers, 32 neurons, sigmoid activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 32 neurons, sigmoid activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 32 neurons, sigmoid activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 32 neurons, sigmoid activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 55.816326530612244%\n",
      "Training with 3 hidden layers, 32 neurons, sigmoid activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 56.224489795918366%\n",
      "Training with 3 hidden layers, 32 neurons, sigmoid activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 56.63265306122449%\n",
      "Training with 3 hidden layers, 32 neurons, sigmoid activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 53.673469387755105%\n",
      "Training with 3 hidden layers, 32 neurons, sigmoid activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 52.755102040816325%\n",
      "Training with 3 hidden layers, 32 neurons, sigmoid activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 52.857142857142854%\n",
      "Training with 3 hidden layers, 32 neurons, sigmoid activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 32 neurons, sigmoid activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 32 neurons, sigmoid activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 32 neurons, sigmoid activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 56.42857142857143%\n",
      "Training with 3 hidden layers, 32 neurons, sigmoid activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 58.06122448979592%\n",
      "Training with 3 hidden layers, 32 neurons, sigmoid activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 56.326530612244895%\n",
      "Training with 3 hidden layers, 32 neurons, sigmoid activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 54.59183673469388%\n",
      "Training with 3 hidden layers, 32 neurons, sigmoid activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 54.795918367346935%\n",
      "Training with 3 hidden layers, 32 neurons, sigmoid activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 54.183673469387756%\n",
      "Training with 3 hidden layers, 32 neurons, sigmoid activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 49.69387755102041%\n",
      "Training with 3 hidden layers, 32 neurons, sigmoid activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 49.89795918367347%\n",
      "Training with 3 hidden layers, 32 neurons, sigmoid activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 32 neurons, tanh activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 58.265306122448976%\n",
      "Training with 3 hidden layers, 32 neurons, tanh activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 56.12244897959184%\n",
      "Training with 3 hidden layers, 32 neurons, tanh activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 57.857142857142854%\n",
      "Training with 3 hidden layers, 32 neurons, tanh activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 54.89795918367347%\n",
      "Training with 3 hidden layers, 32 neurons, tanh activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 54.59183673469388%\n",
      "Training with 3 hidden layers, 32 neurons, tanh activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 55.204081632653065%\n",
      "Training with 3 hidden layers, 32 neurons, tanh activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 51.734693877551024%\n",
      "Training with 3 hidden layers, 32 neurons, tanh activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 51.93877551020408%\n",
      "Training with 3 hidden layers, 32 neurons, tanh activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 52.142857142857146%\n",
      "Training with 3 hidden layers, 32 neurons, tanh activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 57.6530612244898%\n",
      "Training with 3 hidden layers, 32 neurons, tanh activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 59.38775510204081%\n",
      "Training with 3 hidden layers, 32 neurons, tanh activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 57.6530612244898%\n",
      "Training with 3 hidden layers, 32 neurons, tanh activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 56.53061224489796%\n",
      "Training with 3 hidden layers, 32 neurons, tanh activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 55.91836734693877%\n",
      "Training with 3 hidden layers, 32 neurons, tanh activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 55.61224489795919%\n",
      "Training with 3 hidden layers, 32 neurons, tanh activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 52.3469387755102%\n",
      "Training with 3 hidden layers, 32 neurons, tanh activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 52.3469387755102%\n",
      "Training with 3 hidden layers, 32 neurons, tanh activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 52.3469387755102%\n",
      "Training with 3 hidden layers, 32 neurons, tanh activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 58.16326530612245%\n",
      "Training with 3 hidden layers, 32 neurons, tanh activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 59.69387755102041%\n",
      "Training with 3 hidden layers, 32 neurons, tanh activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 59.183673469387756%\n",
      "Training with 3 hidden layers, 32 neurons, tanh activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 55.61224489795919%\n",
      "Training with 3 hidden layers, 32 neurons, tanh activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 57.04081632653061%\n",
      "Training with 3 hidden layers, 32 neurons, tanh activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 56.326530612244895%\n",
      "Training with 3 hidden layers, 32 neurons, tanh activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 53.775510204081634%\n",
      "Training with 3 hidden layers, 32 neurons, tanh activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 53.265306122448976%\n",
      "Training with 3 hidden layers, 32 neurons, tanh activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 52.55102040816327%\n",
      "Training with 3 hidden layers, 32 neurons, softmax activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 54.89795918367347%\n",
      "Training with 3 hidden layers, 32 neurons, softmax activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 55.51020408163265%\n",
      "Training with 3 hidden layers, 32 neurons, softmax activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 55.61224489795919%\n",
      "Training with 3 hidden layers, 32 neurons, softmax activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 32 neurons, softmax activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 50.51020408163265%\n",
      "Training with 3 hidden layers, 32 neurons, softmax activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 49.48979591836735%\n",
      "Training with 3 hidden layers, 32 neurons, softmax activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 32 neurons, softmax activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 29.693877551020407%\n",
      "Training with 3 hidden layers, 32 neurons, softmax activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 29.693877551020407%\n",
      "Training with 3 hidden layers, 32 neurons, softmax activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 58.36734693877551%\n",
      "Training with 3 hidden layers, 32 neurons, softmax activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 57.3469387755102%\n",
      "Training with 3 hidden layers, 32 neurons, softmax activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 54.38775510204081%\n",
      "Training with 3 hidden layers, 32 neurons, softmax activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 48.46938775510204%\n",
      "Training with 3 hidden layers, 32 neurons, softmax activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 49.285714285714285%\n",
      "Training with 3 hidden layers, 32 neurons, softmax activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 50.91836734693877%\n",
      "Training with 3 hidden layers, 32 neurons, softmax activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 32 neurons, softmax activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 29.693877551020407%\n",
      "Training with 3 hidden layers, 32 neurons, softmax activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 32 neurons, softmax activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 56.734693877551024%\n",
      "Training with 3 hidden layers, 32 neurons, softmax activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 56.326530612244895%\n",
      "Training with 3 hidden layers, 32 neurons, softmax activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 55.61224489795919%\n",
      "Training with 3 hidden layers, 32 neurons, softmax activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 50.40816326530612%\n",
      "Training with 3 hidden layers, 32 neurons, softmax activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 52.55102040816327%\n",
      "Training with 3 hidden layers, 32 neurons, softmax activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 53.97959183673469%\n",
      "Training with 3 hidden layers, 32 neurons, softmax activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 32 neurons, softmax activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 32 neurons, softmax activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 64 neurons, relu activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 56.42857142857143%\n",
      "Training with 3 hidden layers, 64 neurons, relu activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 58.06122448979592%\n",
      "Training with 3 hidden layers, 64 neurons, relu activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 59.183673469387756%\n",
      "Training with 3 hidden layers, 64 neurons, relu activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 55.51020408163265%\n",
      "Training with 3 hidden layers, 64 neurons, relu activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 56.53061224489796%\n",
      "Training with 3 hidden layers, 64 neurons, relu activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 56.53061224489796%\n",
      "Training with 3 hidden layers, 64 neurons, relu activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 53.36734693877551%\n",
      "Training with 3 hidden layers, 64 neurons, relu activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 54.59183673469388%\n",
      "Training with 3 hidden layers, 64 neurons, relu activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 53.06122448979592%\n",
      "Training with 3 hidden layers, 64 neurons, relu activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 62.6530612244898%\n",
      "Training with 3 hidden layers, 64 neurons, relu activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 60.10204081632653%\n",
      "Training with 3 hidden layers, 64 neurons, relu activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 61.12244897959184%\n",
      "Training with 3 hidden layers, 64 neurons, relu activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 56.12244897959184%\n",
      "Training with 3 hidden layers, 64 neurons, relu activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 57.95918367346939%\n",
      "Training with 3 hidden layers, 64 neurons, relu activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 57.755102040816325%\n",
      "Training with 3 hidden layers, 64 neurons, relu activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 55.0%\n",
      "Training with 3 hidden layers, 64 neurons, relu activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 54.38775510204081%\n",
      "Training with 3 hidden layers, 64 neurons, relu activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 55.40816326530612%\n",
      "Training with 3 hidden layers, 64 neurons, relu activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 59.89795918367347%\n",
      "Training with 3 hidden layers, 64 neurons, relu activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 61.734693877551024%\n",
      "Training with 3 hidden layers, 64 neurons, relu activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 62.244897959183675%\n",
      "Training with 3 hidden layers, 64 neurons, relu activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 60.204081632653065%\n",
      "Training with 3 hidden layers, 64 neurons, relu activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 59.183673469387756%\n",
      "Training with 3 hidden layers, 64 neurons, relu activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 57.857142857142854%\n",
      "Training with 3 hidden layers, 64 neurons, relu activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 56.53061224489796%\n",
      "Training with 3 hidden layers, 64 neurons, relu activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 56.42857142857143%\n",
      "Training with 3 hidden layers, 64 neurons, relu activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 55.204081632653065%\n",
      "Training with 3 hidden layers, 64 neurons, sigmoid activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 56.63265306122449%\n",
      "Training with 3 hidden layers, 64 neurons, sigmoid activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 54.59183673469388%\n",
      "Training with 3 hidden layers, 64 neurons, sigmoid activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 56.326530612244895%\n",
      "Training with 3 hidden layers, 64 neurons, sigmoid activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 51.12244897959184%\n",
      "Training with 3 hidden layers, 64 neurons, sigmoid activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 52.3469387755102%\n",
      "Training with 3 hidden layers, 64 neurons, sigmoid activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 51.93877551020408%\n",
      "Training with 3 hidden layers, 64 neurons, sigmoid activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 64 neurons, sigmoid activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 64 neurons, sigmoid activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 64 neurons, sigmoid activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 59.48979591836735%\n",
      "Training with 3 hidden layers, 64 neurons, sigmoid activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 57.142857142857146%\n",
      "Training with 3 hidden layers, 64 neurons, sigmoid activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 56.02040816326531%\n",
      "Training with 3 hidden layers, 64 neurons, sigmoid activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 54.38775510204081%\n",
      "Training with 3 hidden layers, 64 neurons, sigmoid activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 54.183673469387756%\n",
      "Training with 3 hidden layers, 64 neurons, sigmoid activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 54.69387755102041%\n",
      "Training with 3 hidden layers, 64 neurons, sigmoid activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 48.673469387755105%\n",
      "Training with 3 hidden layers, 64 neurons, sigmoid activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 46.02040816326531%\n",
      "Training with 3 hidden layers, 64 neurons, sigmoid activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 48.97959183673469%\n",
      "Training with 3 hidden layers, 64 neurons, sigmoid activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 63.57142857142857%\n",
      "Training with 3 hidden layers, 64 neurons, sigmoid activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 64.08163265306122%\n",
      "Training with 3 hidden layers, 64 neurons, sigmoid activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 61.93877551020408%\n",
      "Training with 3 hidden layers, 64 neurons, sigmoid activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 54.59183673469388%\n",
      "Training with 3 hidden layers, 64 neurons, sigmoid activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 55.204081632653065%\n",
      "Training with 3 hidden layers, 64 neurons, sigmoid activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 55.714285714285715%\n",
      "Training with 3 hidden layers, 64 neurons, sigmoid activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 51.224489795918366%\n",
      "Training with 3 hidden layers, 64 neurons, sigmoid activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 51.53061224489796%\n",
      "Training with 3 hidden layers, 64 neurons, sigmoid activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 51.42857142857143%\n",
      "Training with 3 hidden layers, 64 neurons, tanh activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 58.673469387755105%\n",
      "Training with 3 hidden layers, 64 neurons, tanh activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 58.36734693877551%\n",
      "Training with 3 hidden layers, 64 neurons, tanh activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 56.63265306122449%\n",
      "Training with 3 hidden layers, 64 neurons, tanh activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 55.714285714285715%\n",
      "Training with 3 hidden layers, 64 neurons, tanh activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 57.3469387755102%\n",
      "Training with 3 hidden layers, 64 neurons, tanh activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 55.816326530612244%\n",
      "Training with 3 hidden layers, 64 neurons, tanh activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 52.04081632653061%\n",
      "Training with 3 hidden layers, 64 neurons, tanh activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 52.6530612244898%\n",
      "Training with 3 hidden layers, 64 neurons, tanh activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 52.95918367346939%\n",
      "Training with 3 hidden layers, 64 neurons, tanh activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 61.93877551020408%\n",
      "Training with 3 hidden layers, 64 neurons, tanh activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 62.04081632653061%\n",
      "Training with 3 hidden layers, 64 neurons, tanh activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 61.63265306122449%\n",
      "Training with 3 hidden layers, 64 neurons, tanh activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 56.224489795918366%\n",
      "Training with 3 hidden layers, 64 neurons, tanh activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 57.244897959183675%\n",
      "Training with 3 hidden layers, 64 neurons, tanh activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 57.142857142857146%\n",
      "Training with 3 hidden layers, 64 neurons, tanh activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 53.57142857142857%\n",
      "Training with 3 hidden layers, 64 neurons, tanh activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 53.775510204081634%\n",
      "Training with 3 hidden layers, 64 neurons, tanh activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 52.857142857142854%\n",
      "Training with 3 hidden layers, 64 neurons, tanh activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 63.87755102040816%\n",
      "Training with 3 hidden layers, 64 neurons, tanh activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 62.3469387755102%\n",
      "Training with 3 hidden layers, 64 neurons, tanh activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 67.55102040816327%\n",
      "Training with 3 hidden layers, 64 neurons, tanh activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 60.204081632653065%\n",
      "Training with 3 hidden layers, 64 neurons, tanh activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 57.95918367346939%\n",
      "Training with 3 hidden layers, 64 neurons, tanh activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 59.795918367346935%\n",
      "Training with 3 hidden layers, 64 neurons, tanh activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 55.10204081632653%\n",
      "Training with 3 hidden layers, 64 neurons, tanh activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 54.285714285714285%\n",
      "Training with 3 hidden layers, 64 neurons, tanh activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 53.16326530612245%\n",
      "Training with 3 hidden layers, 64 neurons, softmax activation, 25 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 55.40816326530612%\n",
      "Training with 3 hidden layers, 64 neurons, softmax activation, 25 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 56.734693877551024%\n",
      "Training with 3 hidden layers, 64 neurons, softmax activation, 25 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 56.12244897959184%\n",
      "Training with 3 hidden layers, 64 neurons, softmax activation, 25 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 64 neurons, softmax activation, 25 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 64 neurons, softmax activation, 25 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 64 neurons, softmax activation, 25 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 64 neurons, softmax activation, 25 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 64 neurons, softmax activation, 25 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 64 neurons, softmax activation, 50 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 56.93877551020408%\n",
      "Training with 3 hidden layers, 64 neurons, softmax activation, 50 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 55.51020408163265%\n",
      "Training with 3 hidden layers, 64 neurons, softmax activation, 50 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 56.326530612244895%\n",
      "Training with 3 hidden layers, 64 neurons, softmax activation, 50 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 48.87755102040816%\n",
      "Training with 3 hidden layers, 64 neurons, softmax activation, 50 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 51.63265306122449%\n",
      "Training with 3 hidden layers, 64 neurons, softmax activation, 50 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 48.36734693877551%\n",
      "Training with 3 hidden layers, 64 neurons, softmax activation, 50 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 64 neurons, softmax activation, 50 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 64 neurons, softmax activation, 50 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 29.693877551020407%\n",
      "Training with 3 hidden layers, 64 neurons, softmax activation, 100 epochs, 0.01 learning rate, 32 batch size\n",
      "Final Accuracy: 55.40816326530612%\n",
      "Training with 3 hidden layers, 64 neurons, softmax activation, 100 epochs, 0.01 learning rate, 64 batch size\n",
      "Final Accuracy: 54.89795918367347%\n",
      "Training with 3 hidden layers, 64 neurons, softmax activation, 100 epochs, 0.01 learning rate, 128 batch size\n",
      "Final Accuracy: 55.91836734693877%\n",
      "Training with 3 hidden layers, 64 neurons, softmax activation, 100 epochs, 0.001 learning rate, 32 batch size\n",
      "Final Accuracy: 52.95918367346939%\n",
      "Training with 3 hidden layers, 64 neurons, softmax activation, 100 epochs, 0.001 learning rate, 64 batch size\n",
      "Final Accuracy: 52.857142857142854%\n",
      "Training with 3 hidden layers, 64 neurons, softmax activation, 100 epochs, 0.001 learning rate, 128 batch size\n",
      "Final Accuracy: 49.08163265306123%\n",
      "Training with 3 hidden layers, 64 neurons, softmax activation, 100 epochs, 0.0001 learning rate, 32 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 64 neurons, softmax activation, 100 epochs, 0.0001 learning rate, 64 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Training with 3 hidden layers, 64 neurons, softmax activation, 100 epochs, 0.0001 learning rate, 128 batch size\n",
      "Final Accuracy: 44.08163265306123%\n",
      "Best Hyperparameters: {'hidden_layers': 3, 'hidden_neurons': 64, 'activation_fn': 'tanh', 'epochs': 100, 'lr': 0.01, 'batch_size': 128}\n",
      "Best Accuracy: 67.55102040816327\n"
     ]
    }
   ],
   "source": [
    "# 4. Hyperparameter Tuning\n",
    "hidden_layers_options = [1, 2, 3]  # Jumlah hidden layers yang akan diuji\n",
    "hidden_neurons_options = [4, 8, 16, 32, 64]  # Jumlah neuron di setiap hidden layer\n",
    "activation_functions = ['relu', 'sigmoid', 'tanh', 'softmax']  # Fungsi aktivasi yang akan diuji\n",
    "epochs_options = [25, 50, 100]  # Jumlah epoch yang akan diuji\n",
    "learning_rates = [0.01, 0.001, 0.0001]  # Learning rates yang akan diuji\n",
    "batch_sizes = [32, 64, 128]  # Ukuran batch yang akan diuji\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "best_accuracy = 0  # Inisialisasi akurasi terbaik\n",
    "best_params = {}  # Menyimpan hyperparameter terbaik\n",
    "\n",
    "activation_results = {\n",
    "    'relu': None,\n",
    "    'sigmoid': None,\n",
    "    'tanh': None,\n",
    "    'softmax': None\n",
    "}\n",
    "\n",
    "# Loop untuk mencoba semua kombinasi hyperparameter\n",
    "for hidden_layers in hidden_layers_options:\n",
    "    for hidden_neurons in hidden_neurons_options:\n",
    "        for activation_fn in activation_functions:\n",
    "            for epochs in epochs_options:\n",
    "                for lr in learning_rates:\n",
    "                    for batch_size in batch_sizes:\n",
    "                        print(f\"Training with {hidden_layers} hidden layers, {hidden_neurons} neurons, {activation_fn} activation, {epochs} epochs, {lr} learning rate, {batch_size} batch size\")\n",
    "                        \n",
    "                        # Membuat model dan optimizer\n",
    "                        model = MLP(X_train.shape[1], hidden_layers, hidden_neurons, activation_fn)\n",
    "                        criterion = nn.CrossEntropyLoss()  # Fungsi loss untuk klasifikasi\n",
    "                        optimizer = optim.Adam(model.parameters(), lr=lr)  # Optimizer Adam dengan learning rate yang dipilih\n",
    "                        \n",
    "                        # Melatih model\n",
    "                        train_losses, test_accuracies = train_model(model, criterion, optimizer, epochs, train_loader, test_loader)\n",
    "                        \n",
    "                        # Evaluasi akurasi model pada akhir epoch\n",
    "                        final_accuracy = test_accuracies[-1]\n",
    "                        if final_accuracy > best_accuracy:  # Jika akurasi lebih baik dari sebelumnya\n",
    "                            best_accuracy = final_accuracy  # Simpan akurasi terbaik\n",
    "                            best_params = {\n",
    "                                'hidden_layers': hidden_layers,\n",
    "                                'hidden_neurons': hidden_neurons,\n",
    "                                'activation_fn': activation_fn,\n",
    "                                'epochs': epochs,\n",
    "                                'lr': lr,\n",
    "                                'batch_size': batch_size\n",
    "                            }\n",
    "\n",
    "                        # Menyimpan parameter terbaik per fungsi aktivasi\n",
    "                        if final_accuracy > (activation_results[activation_fn]['best_accuracy'] if activation_results[activation_fn] else 0):\n",
    "                            activation_results[activation_fn] = {\n",
    "                                'best_params': best_params,\n",
    "                                'best_accuracy': final_accuracy\n",
    "                            }\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)  # Menampilkan hyperparameter terbaik\n",
    "print(\"Best Accuracy:\", best_accuracy)  # Menampilkan akurasi terbaik\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Hyperparameters for each Activation Function:\n",
      "\n",
      "Activation Function: Relu\n",
      "Best Hyperparameters: {'hidden_layers': 2, 'hidden_neurons': 64, 'activation_fn': 'tanh', 'epochs': 100, 'lr': 0.01, 'batch_size': 32}\n",
      "Best Accuracy: 62.6530612244898\n",
      "\n",
      "Activation Function: Sigmoid\n",
      "Best Hyperparameters: {'hidden_layers': 3, 'hidden_neurons': 64, 'activation_fn': 'sigmoid', 'epochs': 100, 'lr': 0.01, 'batch_size': 64}\n",
      "Best Accuracy: 64.08163265306122\n",
      "\n",
      "Activation Function: Tanh\n",
      "Best Hyperparameters: {'hidden_layers': 3, 'hidden_neurons': 64, 'activation_fn': 'tanh', 'epochs': 100, 'lr': 0.01, 'batch_size': 128}\n",
      "Best Accuracy: 67.55102040816327\n",
      "\n",
      "Activation Function: Softmax\n",
      "Best Hyperparameters: {'hidden_layers': 2, 'hidden_neurons': 64, 'activation_fn': 'tanh', 'epochs': 100, 'lr': 0.01, 'batch_size': 32}\n",
      "Best Accuracy: 58.673469387755105\n"
     ]
    }
   ],
   "source": [
    "# 5. Menyusun Kesimpulan Berdasarkan Fungsi Aktivasi\n",
    "print(\"\\nBest Hyperparameters for each Activation Function:\")\n",
    "for activation_fn, result in activation_results.items():\n",
    "    print(f\"\\nActivation Function: {activation_fn.capitalize()}\")\n",
    "    print(f\"Best Hyperparameters: {result['best_params']}\")\n",
    "    print(f\"Best Accuracy: {result['best_accuracy']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
