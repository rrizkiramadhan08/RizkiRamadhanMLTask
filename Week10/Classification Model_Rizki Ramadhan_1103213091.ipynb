{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Mengimpor pustaka PyTorch dan lainnya untuk manipulasi data dan visualisasi\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split  # Untuk membagi data ke dalam set latih dan uji\n",
    "from sklearn.preprocessing import StandardScaler  # Untuk normalisasi data\n",
    "from sklearn.metrics import accuracy_score  # Untuk menghitung akurasi\n",
    "import matplotlib.pyplot as plt  # Untuk visualisasi hasil\n",
    "from torch.utils.data import DataLoader, TensorDataset  # Untuk membuat DataLoader\n",
    "from torch.autograd import Variable  # Untuk memungkinkan otomatisasi diferensiasi\n",
    "import time  # Untuk mengukur waktu eksekusi\n",
    "from fpdf import FPDF  # Untuk membuat laporan PDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Membaca dataset winequality-white.csv dengan delimiter ;\n",
    "df = pd.read_csv('winequality-white.csv', delimiter=';')\n",
    "\n",
    "# Pisahkan fitur (X) dan target (y)\n",
    "X = df.drop('quality', axis=1).values  # Semua kolom selain 'quality' sebagai fitur\n",
    "y = df['quality'].values  # Kolom 'quality' sebagai target\n",
    "\n",
    "# Normalisasi data fitur agar nilai berada dalam rentang yang sama\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)  # Fit dan transform data fitur\n",
    "\n",
    "# Membagi data menjadi set latih (80%) dan uji (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Mengubah data menjadi tensor PyTorch agar bisa digunakan dalam pelatihan\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Membuat dataset Tensor untuk DataLoader\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_data = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Membuat DataLoader untuk batch training dan testing\n",
    "train_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Mendefinisikan kelas model MLP (Multilayer Perceptron) untuk klasifikasi\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_layers, hidden_neurons, activation_fn):\n",
    "        super(MLP, self).__init__()\n",
    "        layers = []  # List untuk menyimpan layer-layer\n",
    "\n",
    "        prev_layer = input_dim  # Dimensi input adalah jumlah fitur\n",
    "\n",
    "        # Menambahkan hidden layers sesuai jumlah yang ditentukan\n",
    "        for _ in range(hidden_layers):\n",
    "            layers.append(nn.Linear(prev_layer, hidden_neurons))  # Menambahkan layer Linear\n",
    "            if activation_fn == 'relu':  # Jika fungsi aktivasi ReLU\n",
    "                layers.append(nn.ReLU())  # Menambahkan ReLU\n",
    "            elif activation_fn == 'sigmoid':  # Jika fungsi aktivasi Sigmoid\n",
    "                layers.append(nn.Sigmoid())  # Menambahkan Sigmoid\n",
    "            elif activation_fn == 'tanh':  # Jika fungsi aktivasi Tanh\n",
    "                layers.append(nn.Tanh())  # Menambahkan Tanh\n",
    "            elif activation_fn == 'softmax':  # Jika fungsi aktivasi Softmax\n",
    "                layers.ap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Fungsi untuk melatih dan mengevaluasi model\n",
    "def train_model(model, criterion, optimizer, epochs, train_loader, test_loader):\n",
    "    train_losses = []  # Menyimpan loss selama pelatihan\n",
    "    test_accuracies = []  # Menyimpan akurasi setiap epoch\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()  # Menyiapkan model untuk pelatihan\n",
    "        running_loss = 0.0  # Variabel untuk menghitung loss selama satu epoch\n",
    "\n",
    "        # Loop untuk setiap batch di train_loader\n",
    "        for inputs, labels in train_loader:\n",
    "            # Forward pass: menghitung output dari model\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)  # Menghitung loss\n",
    "\n",
    "            # Backward pass dan optimasi: memperbarui parameter model\n",
    "            optimizer.zero_grad()  # Mengatur gradient ke 0 sebelum backward pass\n",
    "            loss.backward()  # Menghitung gradien\n",
    "            optimizer.step()  # Mengupdate parameter model\n",
    "\n",
    "            running_loss += loss.item()  # Menambah loss per batch ke total loss\n",
    "        \n",
    "        # Menyimpan rata-rata loss untuk epoch ini\n",
    "        train_losses.append(running_loss / len(train_loader))\n",
    "\n",
    "        # Evaluasi model pada data uji\n",
    "        model.eval()  # Menyiapkan model untuk evaluasi\n",
    "        correct = 0  # Variabel untuk menghitung jumlah prediksi yang benar\n",
    "        total = 0  # Variabel untuk menghitung total data\n",
    "\n",
    "        with torch.no_grad():  # Menonaktifkan gradient calculation\n",
    "            for inputs, labels in test_loader:\n",
    "                outputs = model(inputs)  # Menghitung output model\n",
    "             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "hidden_layers_options = [1, 2, 3]\n",
    "hidden_neurons_options = [4, 8, 16, 32]\n",
    "activation_functions = ['linear','relu', 'sigmoid', 'tanh', 'softmax']\n",
    "epochs_options = [25, 50, 100]\n",
    "learning_rates = [0.01, 0.001, 0.0001]\n",
    "batch_sizes = [32, 64, 128]\n",
    "\n",
    "best_accuracy = 0\n",
    "best_params = {}\n",
    "\n",
    "# Looping untuk mengevaluasi semua kombinasi hyperparameter\n",
    "for hidden_layers in hidden_layers_options:\n",
    "    for hidden_neurons in hidden_neurons_options:\n",
    "        for activation_fn in activation_functions:\n",
    "            for epochs in epochs_options:\n",
    "                for lr in learning_rates:\n",
    "                    for batch_size in batch_sizes:\n",
    "                        print(f\"Training with {hidden_layers} hidden layers, {hidden_neurons} neurons, {activation_fn} activation, {epochs} epochs, {lr} learning rate, {batch_size} batch size\")\n",
    "                        \n",
    "                        # Membuat model dan optimizer\n",
    "                        model = MLP(X_train.shape[1], hidden_layers, hidden_neurons, activation_fn)\n",
    "                        criterion = nn.CrossEntropyLoss()\n",
    "                        optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "                        \n",
    "                        # Train model\n",
    "                        train_losses, test_accuracies = train_model(model, criterion, optimizer, epochs, train_loader, test_loader)\n",
    "                        \n",
    "                        # Evaluasi dan simpan hasil terbaik\n",
    "                        final_accuracy = test_accuracies[-1]\n",
    "                        if final_accuracy > best_accuracy:\n",
    "                            best_accuracy = final_accuracy\n",
    "                            best_params = {\n",
    "                                'hidden_layers': hidden_layers,\n",
    "                                'hidden_neurons': hidden_neurons,\n",
    "                                'activation_fn': activation_fn,\n",
    "                                'epochs': epochs,\n",
    "                                'lr': lr,\n",
    "                                'batch_size': batch_size\n",
    "                            }\n",
    "                        \n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Best Accuracy:\", best_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Fungsi untuk menyimpan hasil analisis dalam bentuk laporan PDF\n",
    "def save_analysis_report(best_params, best_accuracy):\n",
    "    pdf = FPDF()  # Memb\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
